{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#bem-vindoa-deep-learning-20251","title":"Bem-vindo(a) \u2014 Deep Learning (2025.1)","text":"<p>Autor: Caio Ortega Boa Turma: 2025.2 Reposit\u00f3rio: Este site re\u00fane todo o conte\u00fado produzido por Caio Ortega Boa na disciplina de Deep Learning \u2014 exerc\u00edcios, c\u00f3digos, an\u00e1lises, gr\u00e1ficos e anota\u00e7\u00f5es.</p>"},{"location":"#sobre-esta-pagina","title":"Sobre esta p\u00e1gina","text":"<p>Este \u00e9 o hub do projeto da mat\u00e9ria. Aqui voc\u00ea encontra: - vis\u00e3o geral do que foi feito; - links para notebooks/c\u00f3digos; - entregas da mat\u00e9ria;</p>"},{"location":"template/","title":"Template de Entrega","text":""},{"location":"template/#template-de-entrega","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"template/#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> <li>Maria Oliveira</li> <li>Grupo K<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"template/#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"template/#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"template/#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"template/#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"template/#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"classification/model/","title":"Introdu\u00e7\u00e3o","text":"In\u00a0[135]: Copied! <pre>from __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\n\nsns.set_theme(style='whitegrid', context='notebook')\npd.set_option('display.max_columns', 100)\npd.set_option('display.width', 120)\n</pre> from __future__ import annotations  from pathlib import Path from typing import Dict, List, Optional, Tuple  import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt from IPython.display import display  sns.set_theme(style='whitegrid', context='notebook') pd.set_option('display.max_columns', 100) pd.set_option('display.width', 120)  In\u00a0[136]: Copied! <pre># -----------------------------\n# Ativa\u00e7\u00f5es e derivadas\n# -----------------------------\ndef tanh(z: np.ndarray) -&gt; np.ndarray:\n    return np.tanh(z)\n\ndef dtanh_from_a(a: np.ndarray) -&gt; np.ndarray:\n    return 1.0 - a**2\n\ndef softmax(Z: np.ndarray, axis: int = 0) -&gt; np.ndarray:\n    \"\"\"\n    Z: (K, m) -&gt; aplica softmax por coluna (axis=0).\n    Retorna prob. por classe, colunas somam 1.\n    \"\"\"\n    Z_shift = Z - np.max(Z, axis=axis, keepdims=True)\n    e = np.exp(Z_shift)\n    return e / np.sum(e, axis=axis, keepdims=True)\n\ndef cross_entropy(y_true_oh: np.ndarray, y_prob: np.ndarray, eps: float = 1e-12) -&gt; float:\n    \"\"\"\n    y_true_oh: (m, K) one-hot\n    y_prob   : (m, K) probabilidades (softmax)\n    \"\"\"\n    y_prob = np.clip(y_prob, eps, 1.0 - eps)\n    return float(-np.mean(np.sum(y_true_oh * np.log(y_prob), axis=1)))\n\n\n# -----------------------------\n# M\u00e9tricas de avalia\u00e7\u00e3o\n# -----------------------------\n\ndef accuracy_score(y_true: np.ndarray, y_pred_labels: np.ndarray) -&gt; float:\n    return float(np.mean(y_true == y_pred_labels))\n\ndef precision_recall_f1(y_true, y_pred, labels=None):\n    \"\"\"Calcula precis\u00e3o, recall e F1 por classe do zero\"\"\"\n    if labels is None:\n        labels = np.unique(np.concatenate([y_true, y_pred]))\n    metrics = {}\n    for label in labels:\n        tp = np.sum((y_pred == label) &amp; (y_true == label))\n        fp = np.sum((y_pred == label) &amp; (y_true != label))\n        fn = np.sum((y_pred != label) &amp; (y_true == label))\n        precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0.0\n        recall    = tp / (tp + fn) if (tp + fn) &gt; 0 else 0.0\n        f1        = 2*precision*recall/(precision+recall) if (precision+recall) &gt; 0 else 0.0\n        metrics[label] = {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n    return metrics\n\ndef confusion_matrix_true(y_true, y_pred, labels=None):\n    if labels is None:\n        labels = np.unique(np.concatenate([y_true, y_pred]))\n    cm = pd.DataFrame(0, index=labels, columns=labels)\n    for yt, yp in zip(y_true, y_pred):\n        cm.loc[yt, yp] += 1\n    return cm\n\n\n# -----------------------------\n# Divis\u00e3o treino/valida\u00e7\u00e3o/teste\n# -----------------------------\n\ndef train_test_split(\n    X: np.ndarray,\n    y: np.ndarray,\n    test_size: float = 0.15,\n    val_size: float = 0.15,\n    random_state: int = 42,\n):\n    \"\"\"Divide os dados em conjuntos de treino, validacao e teste (70/15/15 por padrao).\"\"\"\n    if not (0.0 &lt; test_size &lt; 1.0) or not (0.0 &lt; val_size &lt; 1.0):\n        raise ValueError('test_size e val_size devem estar entre 0 e 1.')\n    if test_size + val_size &gt;= 1.0:\n        raise ValueError('A soma de test_size e val_size deve ser inferior a 1.')\n\n    rng = np.random.default_rng(random_state)\n    m = X.shape[0]\n    idx = rng.permutation(m)\n\n    m_test = max(1, int(round(test_size * m)))\n    m_val = max(1, int(round(val_size * m)))\n\n    total_requested = m_test + m_val\n    if total_requested &gt;= m:\n        m_test = max(1, int(np.floor(test_size * m)))\n        m_val = max(1, int(np.floor(val_size * m)))\n        total_requested = m_test + m_val\n        if total_requested &gt;= m:\n            raise ValueError('Nao ha exemplos suficientes para o particionamento desejado.')\n\n    test_idx = idx[:m_test]\n    val_idx = idx[m_test:m_test + m_val]\n    train_idx = idx[m_test + m_val:]\n\n    if train_idx.size == 0:\n        raise ValueError('Conjunto de treino vazio; ajuste test_size/val_size.')\n\n    return (\n        X[train_idx],\n        X[val_idx],\n        X[test_idx],\n        y[train_idx],\n        y[val_idx],\n        y[test_idx],\n    )\n\n# -----------------------------\n# Inicializa\u00e7\u00e3o do pesos\n# -----------------------------\n\ndef xavier_init(fan_in: int, fan_out: int, rng: np.random.Generator) -&gt; np.ndarray:\n    std = np.sqrt(2.0 / (fan_in + fan_out))\n    return rng.normal(0.0, std, size=(fan_out, fan_in))\n\n# -----------------------------\n# One Hot Encoding\n# -----------------------------\n\ndef one_hot(y: np.ndarray, K: int) -&gt; np.ndarray:\n    \"\"\"\n    y: (m,) com r\u00f3tulos inteiros [0..K-1]\n    retorna: (m, K) one-hot\n    \"\"\"\n    m = y.shape[0]\n    Y = np.zeros((m, K), dtype=float)\n    Y[np.arange(m), y.astype(int)] = 1.0\n    return Y\n</pre> # ----------------------------- # Ativa\u00e7\u00f5es e derivadas # ----------------------------- def tanh(z: np.ndarray) -&gt; np.ndarray:     return np.tanh(z)  def dtanh_from_a(a: np.ndarray) -&gt; np.ndarray:     return 1.0 - a**2  def softmax(Z: np.ndarray, axis: int = 0) -&gt; np.ndarray:     \"\"\"     Z: (K, m) -&gt; aplica softmax por coluna (axis=0).     Retorna prob. por classe, colunas somam 1.     \"\"\"     Z_shift = Z - np.max(Z, axis=axis, keepdims=True)     e = np.exp(Z_shift)     return e / np.sum(e, axis=axis, keepdims=True)  def cross_entropy(y_true_oh: np.ndarray, y_prob: np.ndarray, eps: float = 1e-12) -&gt; float:     \"\"\"     y_true_oh: (m, K) one-hot     y_prob   : (m, K) probabilidades (softmax)     \"\"\"     y_prob = np.clip(y_prob, eps, 1.0 - eps)     return float(-np.mean(np.sum(y_true_oh * np.log(y_prob), axis=1)))   # ----------------------------- # M\u00e9tricas de avalia\u00e7\u00e3o # -----------------------------  def accuracy_score(y_true: np.ndarray, y_pred_labels: np.ndarray) -&gt; float:     return float(np.mean(y_true == y_pred_labels))  def precision_recall_f1(y_true, y_pred, labels=None):     \"\"\"Calcula precis\u00e3o, recall e F1 por classe do zero\"\"\"     if labels is None:         labels = np.unique(np.concatenate([y_true, y_pred]))     metrics = {}     for label in labels:         tp = np.sum((y_pred == label) &amp; (y_true == label))         fp = np.sum((y_pred == label) &amp; (y_true != label))         fn = np.sum((y_pred != label) &amp; (y_true == label))         precision = tp / (tp + fp) if (tp + fp) &gt; 0 else 0.0         recall    = tp / (tp + fn) if (tp + fn) &gt; 0 else 0.0         f1        = 2*precision*recall/(precision+recall) if (precision+recall) &gt; 0 else 0.0         metrics[label] = {\"precision\": precision, \"recall\": recall, \"f1\": f1}     return metrics  def confusion_matrix_true(y_true, y_pred, labels=None):     if labels is None:         labels = np.unique(np.concatenate([y_true, y_pred]))     cm = pd.DataFrame(0, index=labels, columns=labels)     for yt, yp in zip(y_true, y_pred):         cm.loc[yt, yp] += 1     return cm   # ----------------------------- # Divis\u00e3o treino/valida\u00e7\u00e3o/teste # -----------------------------  def train_test_split(     X: np.ndarray,     y: np.ndarray,     test_size: float = 0.15,     val_size: float = 0.15,     random_state: int = 42, ):     \"\"\"Divide os dados em conjuntos de treino, validacao e teste (70/15/15 por padrao).\"\"\"     if not (0.0 &lt; test_size &lt; 1.0) or not (0.0 &lt; val_size &lt; 1.0):         raise ValueError('test_size e val_size devem estar entre 0 e 1.')     if test_size + val_size &gt;= 1.0:         raise ValueError('A soma de test_size e val_size deve ser inferior a 1.')      rng = np.random.default_rng(random_state)     m = X.shape[0]     idx = rng.permutation(m)      m_test = max(1, int(round(test_size * m)))     m_val = max(1, int(round(val_size * m)))      total_requested = m_test + m_val     if total_requested &gt;= m:         m_test = max(1, int(np.floor(test_size * m)))         m_val = max(1, int(np.floor(val_size * m)))         total_requested = m_test + m_val         if total_requested &gt;= m:             raise ValueError('Nao ha exemplos suficientes para o particionamento desejado.')      test_idx = idx[:m_test]     val_idx = idx[m_test:m_test + m_val]     train_idx = idx[m_test + m_val:]      if train_idx.size == 0:         raise ValueError('Conjunto de treino vazio; ajuste test_size/val_size.')      return (         X[train_idx],         X[val_idx],         X[test_idx],         y[train_idx],         y[val_idx],         y[test_idx],     )  # ----------------------------- # Inicializa\u00e7\u00e3o do pesos # -----------------------------  def xavier_init(fan_in: int, fan_out: int, rng: np.random.Generator) -&gt; np.ndarray:     std = np.sqrt(2.0 / (fan_in + fan_out))     return rng.normal(0.0, std, size=(fan_out, fan_in))  # ----------------------------- # One Hot Encoding # -----------------------------  def one_hot(y: np.ndarray, K: int) -&gt; np.ndarray:     \"\"\"     y: (m,) com r\u00f3tulos inteiros [0..K-1]     retorna: (m, K) one-hot     \"\"\"     m = y.shape[0]     Y = np.zeros((m, K), dtype=float)     Y[np.arange(m), y.astype(int)] = 1.0     return Y In\u00a0[137]: Copied! <pre>class MLP:\n    def __init__(\n        self,\n        input_dim: int,\n        hidden_layers: List[int] = [16, 16],\n        output_dim: int = 2,        \n        lr: float = 0.05,\n        max_epochs: int = 500,\n        batch_size: Optional[int] = None,\n        random_state: Optional[int] = 42,\n        l2: float = 0.0,\n        track_history: bool = True,\n    ):\n        self.input_dim = input_dim\n        self.hidden_layers = hidden_layers\n        self.output_dim = output_dim\n        self.lr = lr\n        self.max_epochs = max_epochs\n        self.batch_size = batch_size\n        self.random_state = random_state\n        self.l2 = l2\n        self.track_history = track_history\n\n        self.params_ = None\n        self.loss_history_: List[float] = []\n        self.acc_history_: List[float] = []\n\n    # ---------- initialization ----------\n    def _init_params(self, rng: np.random.Generator) -&gt; None:\n        layer_sizes = [self.input_dim] + self.hidden_layers + [self.output_dim]\n        W, b = [], []\n        for l in range(1, len(layer_sizes)):\n            fan_in = layer_sizes[l-1]\n            fan_out = layer_sizes[l]\n            W_l = xavier_init(fan_in, fan_out, rng)\n            b_l = np.zeros((fan_out, 1))\n            W.append(W_l)\n            b.append(b_l)\n        self.params_ = {\"W\": W, \"b\": b}\n\n    # ---------- forward ----------\n    def _forward(self, X: np.ndarray):\n        W, B = self.params_[\"W\"], self.params_[\"b\"]\n        A = X.T  \n        caches = [{\"A\": A}]  \n\n        # hidden layers\n        for l in range(len(self.hidden_layers)):\n            Z = W[l] @ A + B[l]\n            A = tanh(Z)\n            caches.append({\"Z\": Z, \"A\": A})\n\n        # output layer (softmax)\n        ZL = W[-1] @ A + B[-1]\n        P = softmax(ZL, axis=0)\n        caches.append({\"Z\": ZL, \"A\": P})\n        return caches, P.T\n\n    # ---------- backward ----------\n    def _backward(self, caches, y: np.ndarray):\n        W = self.params_[\"W\"]\n        L = len(W)\n        m = y.shape[0]\n\n        A0 = caches[0][\"A\"]\n        A_list = [A0] + [c[\"A\"] for c in caches[1:]]\n\n        Y = one_hot(y.reshape(-1), self.output_dim).T\n        P = A_list[-1]\n\n        dZ = (P - Y) / m\n        dW = [None] * L\n        dB = [None] * L\n\n        # \u00faltima camada\n        A_prev = A_list[-2]\n        dW[L-1] = dZ @ A_prev.T\n        dB[L-1] = np.sum(dZ, axis=1, keepdims=True)\n\n        # ocultas\n        for l in reversed(range(L-1)):\n            dA = W[l+1].T @ dZ\n            A_l = A_list[l+1]\n            dZ = dA * dtanh_from_a(A_l)\n\n            A_prev = A_list[l]\n            dW[l] = dZ @ A_prev.T\n            dB[l] = np.sum(dZ, axis=1, keepdims=True)\n\n        if self.l2:\n            reg_scale = self.l2 / m\n            for l in range(L):\n                dW[l] += reg_scale * W[l]\n\n        return dW, dB\n\n    # ---------- update ----------\n    def _update(self, dW, dB, lr: float) -&gt; None:\n        for l in range(len(self.params_[\"W\"])):\n            self.params_[\"W\"][l] -= lr * dW[l]\n            self.params_[\"b\"][l] -= lr * dB[l]\n\n    # ---------- fit ----------\n    def fit(self, X: np.ndarray, y: np.ndarray):\n        rng = np.random.default_rng(self.random_state)\n        self._init_params(rng)\n\n        m = X.shape[0]\n        batch_size = self.batch_size or m\n\n        for epoch in range(1, self.max_epochs + 1):\n            idx = rng.permutation(m)\n            X_shuf = X[idx]\n            y_shuf = y[idx]\n\n            for start in range(0, m, batch_size):\n                end = min(start + batch_size, m)\n                Xb = X_shuf[start:end]\n                yb = y_shuf[start:end]\n\n                caches, _ = self._forward(Xb)\n                dW, dB = self._backward(caches, yb)\n                self._update(dW, dB, self.lr)\n\n            if self.track_history:\n                P_full = self.predict_proba(X)\n                Y_full = one_hot(y, self.output_dim)\n                loss = cross_entropy(Y_full, P_full)\n                if self.l2:\n                    reg = (self.l2 / (2 * m)) * sum(np.sum(W ** 2) for W in self.params_[\"W\"])\n                    loss += reg\n                y_pred = np.argmax(P_full, axis=1)\n                acc = accuracy_score(y, y_pred)\n                self.loss_history_.append(loss)\n                self.acc_history_.append(acc)\n\n        return {\"epochs_run\": self.max_epochs}\n\n    def predict_proba(self, X: np.ndarray) -&gt; np.ndarray:\n        _, P = self._forward(X)\n        return P\n\n    def decision_function(self, X: np.ndarray) -&gt; np.ndarray:\n        W, B = self.params_[\"W\"], self.params_[\"b\"]\n        A = X.T\n        for l in range(len(self.hidden_layers)):\n            A = tanh(W[l] @ A + B[l])\n        ZL = W[-1] @ A + B[-1]\n        return ZL.T\n\n    def predict(self, X: np.ndarray) -&gt; np.ndarray:\n        P = self.predict_proba(X)\n        return np.argmax(P, axis=1)\n</pre> class MLP:     def __init__(         self,         input_dim: int,         hidden_layers: List[int] = [16, 16],         output_dim: int = 2,                 lr: float = 0.05,         max_epochs: int = 500,         batch_size: Optional[int] = None,         random_state: Optional[int] = 42,         l2: float = 0.0,         track_history: bool = True,     ):         self.input_dim = input_dim         self.hidden_layers = hidden_layers         self.output_dim = output_dim         self.lr = lr         self.max_epochs = max_epochs         self.batch_size = batch_size         self.random_state = random_state         self.l2 = l2         self.track_history = track_history          self.params_ = None         self.loss_history_: List[float] = []         self.acc_history_: List[float] = []      # ---------- initialization ----------     def _init_params(self, rng: np.random.Generator) -&gt; None:         layer_sizes = [self.input_dim] + self.hidden_layers + [self.output_dim]         W, b = [], []         for l in range(1, len(layer_sizes)):             fan_in = layer_sizes[l-1]             fan_out = layer_sizes[l]             W_l = xavier_init(fan_in, fan_out, rng)             b_l = np.zeros((fan_out, 1))             W.append(W_l)             b.append(b_l)         self.params_ = {\"W\": W, \"b\": b}      # ---------- forward ----------     def _forward(self, X: np.ndarray):         W, B = self.params_[\"W\"], self.params_[\"b\"]         A = X.T           caches = [{\"A\": A}]            # hidden layers         for l in range(len(self.hidden_layers)):             Z = W[l] @ A + B[l]             A = tanh(Z)             caches.append({\"Z\": Z, \"A\": A})          # output layer (softmax)         ZL = W[-1] @ A + B[-1]         P = softmax(ZL, axis=0)         caches.append({\"Z\": ZL, \"A\": P})         return caches, P.T      # ---------- backward ----------     def _backward(self, caches, y: np.ndarray):         W = self.params_[\"W\"]         L = len(W)         m = y.shape[0]          A0 = caches[0][\"A\"]         A_list = [A0] + [c[\"A\"] for c in caches[1:]]          Y = one_hot(y.reshape(-1), self.output_dim).T         P = A_list[-1]          dZ = (P - Y) / m         dW = [None] * L         dB = [None] * L          # \u00faltima camada         A_prev = A_list[-2]         dW[L-1] = dZ @ A_prev.T         dB[L-1] = np.sum(dZ, axis=1, keepdims=True)          # ocultas         for l in reversed(range(L-1)):             dA = W[l+1].T @ dZ             A_l = A_list[l+1]             dZ = dA * dtanh_from_a(A_l)              A_prev = A_list[l]             dW[l] = dZ @ A_prev.T             dB[l] = np.sum(dZ, axis=1, keepdims=True)          if self.l2:             reg_scale = self.l2 / m             for l in range(L):                 dW[l] += reg_scale * W[l]          return dW, dB      # ---------- update ----------     def _update(self, dW, dB, lr: float) -&gt; None:         for l in range(len(self.params_[\"W\"])):             self.params_[\"W\"][l] -= lr * dW[l]             self.params_[\"b\"][l] -= lr * dB[l]      # ---------- fit ----------     def fit(self, X: np.ndarray, y: np.ndarray):         rng = np.random.default_rng(self.random_state)         self._init_params(rng)          m = X.shape[0]         batch_size = self.batch_size or m          for epoch in range(1, self.max_epochs + 1):             idx = rng.permutation(m)             X_shuf = X[idx]             y_shuf = y[idx]              for start in range(0, m, batch_size):                 end = min(start + batch_size, m)                 Xb = X_shuf[start:end]                 yb = y_shuf[start:end]                  caches, _ = self._forward(Xb)                 dW, dB = self._backward(caches, yb)                 self._update(dW, dB, self.lr)              if self.track_history:                 P_full = self.predict_proba(X)                 Y_full = one_hot(y, self.output_dim)                 loss = cross_entropy(Y_full, P_full)                 if self.l2:                     reg = (self.l2 / (2 * m)) * sum(np.sum(W ** 2) for W in self.params_[\"W\"])                     loss += reg                 y_pred = np.argmax(P_full, axis=1)                 acc = accuracy_score(y, y_pred)                 self.loss_history_.append(loss)                 self.acc_history_.append(acc)          return {\"epochs_run\": self.max_epochs}      def predict_proba(self, X: np.ndarray) -&gt; np.ndarray:         _, P = self._forward(X)         return P      def decision_function(self, X: np.ndarray) -&gt; np.ndarray:         W, B = self.params_[\"W\"], self.params_[\"b\"]         A = X.T         for l in range(len(self.hidden_layers)):             A = tanh(W[l] @ A + B[l])         ZL = W[-1] @ A + B[-1]         return ZL.T      def predict(self, X: np.ndarray) -&gt; np.ndarray:         P = self.predict_proba(X)         return np.argmax(P, axis=1)   In\u00a0[138]: Copied! <pre>from __future__ import annotations\nfrom typing import Dict, List\nimport re\nimport numpy as np\nimport pandas as pd\n\nclass MainFeaturesPreprocessor:\n    \"\"\"Custom feature processor used to align training and inference data.\"\"\"\n    key_columns = ['lab_id', 'video_id']\n    keep_columns = ['mouse1_id', 'mouse2_id', 'mouse3_id', 'mouse4_id', 'body_parts_tracked', 'behaviors_labeled']\n    drop_columns = ['mouse1_condition', 'mouse2_condition', 'mouse3_condition']\n\n    def __init__(self):\n        self.numeric_stats: Dict[str, Dict[str, float]] = {}\n        self.categorical_levels: Dict[str, List[str]] = {}\n        self.categorical_mode: Dict[str, str] = {}        \n        self.feature_columns: List[str] = []\n        self.age_columns = {'mouse1_age', 'mouse2_age', 'mouse3_age', 'mouse4_age'}\n\n    @staticmethod\n    def _sanitize_token(value) -&gt; str:\n        token = str(value).strip().lower().replace(' ', '_')\n        cleaned = ''.join(ch if ch.isalnum() or ch == '_' else '_' for ch in token)\n        cleaned = cleaned.strip('_')\n        return cleaned or 'unknown'\n\n    @staticmethod\n    def _parse_age_to_float(series: pd.Series) -&gt; pd.Series:\n        def _parse_one(x) -&gt; float:\n            if pd.isna(x):\n                return np.nan\n            s = str(x)\n            nums = re.findall(r'(\\d+(?:\\.\\d+)?)', s)\n            if not nums:\n                return np.nan\n            vals = [float(n) for n in nums]\n            if len(vals) &gt;= 2:\n                return float((vals[0] + vals[1]) / 2.0)  \n            return float(vals[0])                       \n        return series.apply(_parse_one).astype(float)\n\n    def _fit_numeric(self, series: pd.Series, column: str) -&gt; None:\n        values = pd.to_numeric(series, errors='coerce')\n        valid = values.dropna()\n        if valid.empty:\n            self.numeric_stats[column] = {'fill': 0.0, 'min': 0.0, 'max': 0.0}\n            return\n        fill = float(valid.mean())\n        min_val = float(valid.min())\n        max_val = float(valid.max())\n        self.numeric_stats[column] = {'fill': fill, 'min': min_val, 'max': max_val}\n\n    def fit(self, df: pd.DataFrame) -&gt; None:\n        df_copy = df.copy()\n        for column in df_copy.columns:\n            if column in self.key_columns:\n                continue\n            if column in self.keep_columns:\n                continue\n            if column in self.drop_columns:\n                df_copy = df_copy.drop(columns=[column])\n                continue\n\n            series = df_copy[column]\n\n            if column in self.age_columns:\n                parsed_age = self._parse_age_to_float(series)\n                self._fit_numeric(parsed_age, column)\n                continue\n\n            if pd.api.types.is_numeric_dtype(series):\n                self._fit_numeric(series, column)\n            else:\n                numeric_candidate = pd.to_numeric(series, errors='coerce')\n                if numeric_candidate.notna().sum() &gt;= len(series) * 0.5:\n                    self._fit_numeric(numeric_candidate, column)\n                else:\n                    cats = series.dropna().astype(str)\n                    if cats.empty:\n                        levels = ['__missing__']\n                        mode_val = '__missing__'\n                    else:\n                        levels = sorted(cats.unique().tolist())\n                        mode_val = str(cats.mode().iloc[0])\n                    self.categorical_levels[column] = levels\n                    self.categorical_mode[column] = mode_val\n\n        feature_matrix = self._build_matrix(df_copy)\n        self.feature_columns = [c for c in feature_matrix.columns if c not in self.key_columns]\n\n    def _scale_numeric(self, series: pd.Series, stats: Dict[str, float]) -&gt; pd.Series:\n        values = pd.to_numeric(series, errors='coerce')\n        values = values.fillna(stats['fill'])\n        min_val = stats['min']\n        max_val = stats['max']\n        if np.isclose(max_val, min_val):\n            return pd.Series(0.0, index=series.index)\n        scaled = (values - min_val) / (max_val - min_val)\n        return 2.0 * scaled - 1.0\n\n    def _encode_categorical(self, series: pd.Series, column: str) -&gt; pd.DataFrame:\n        levels = self.categorical_levels[column]\n        mode_val = self.categorical_mode[column]\n\n        processed = series.astype(str).fillna(mode_val)\n        processed = processed.where(processed.isin(levels), mode_val)\n\n        encoded = {}\n        for level in levels:\n            col_name = f\"{column}_{self._sanitize_token(level)}\"\n            encoded[col_name] = (processed == level).astype(float)\n        return pd.DataFrame(encoded, index=series.index)\n\n    def _build_matrix(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        base_cols: Dict[str, pd.Series] = {}\n\n        for key in self.key_columns:\n            if key in df.columns:\n                base_cols[key] = df[key]\n            else:\n                base_cols[key] = pd.Series(np.nan, index=df.index, name=key)\n\n        for column, stats in self.numeric_stats.items():\n            if column in df.columns:\n                series = df[column]\n                if column in self.age_columns:\n                    series = self._parse_age_to_float(series)\n            else:\n                series = pd.Series(np.nan, index=df.index, name=column)\n            base_cols[column] = self._scale_numeric(series, stats)\n\n        matrix = pd.concat(base_cols, axis=1)\n\n        cat_frames = []\n        for column in self.categorical_levels:\n            if column in df.columns:\n                series = df[column]\n            else:\n                series = pd.Series(self.categorical_mode[column], index=df.index, name=column)\n            encoded = self._encode_categorical(series, column)\n            cat_frames.append(encoded)\n\n        if cat_frames:\n            matrix = pd.concat([matrix] + cat_frames, axis=1)\n\n        return matrix.copy()\n\n\n    def transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        if not self.numeric_stats and not self.categorical_levels:\n            raise RuntimeError('Preprocessor is not fitted.')\n\n        matrix = self._build_matrix(df.copy())\n\n        final_cols = self.key_columns + self.feature_columns\n        matrix = matrix.reindex(columns=final_cols, fill_value=0.0)\n\n        return matrix.copy()\n\n    def fit_transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n        self.fit(df)\n        return self.transform(df)\n\n    def __repr__(self) -&gt; str:\n        return (\n            f'TrackingFeaturePreprocessor(numeric={len(self.numeric_stats)}, '\n            f'categorical={len(self.categorical_levels)}, '\n            f'features={len(self.feature_columns)})'\n        )\n</pre> from __future__ import annotations from typing import Dict, List import re import numpy as np import pandas as pd  class MainFeaturesPreprocessor:     \"\"\"Custom feature processor used to align training and inference data.\"\"\"     key_columns = ['lab_id', 'video_id']     keep_columns = ['mouse1_id', 'mouse2_id', 'mouse3_id', 'mouse4_id', 'body_parts_tracked', 'behaviors_labeled']     drop_columns = ['mouse1_condition', 'mouse2_condition', 'mouse3_condition']      def __init__(self):         self.numeric_stats: Dict[str, Dict[str, float]] = {}         self.categorical_levels: Dict[str, List[str]] = {}         self.categorical_mode: Dict[str, str] = {}                 self.feature_columns: List[str] = []         self.age_columns = {'mouse1_age', 'mouse2_age', 'mouse3_age', 'mouse4_age'}      @staticmethod     def _sanitize_token(value) -&gt; str:         token = str(value).strip().lower().replace(' ', '_')         cleaned = ''.join(ch if ch.isalnum() or ch == '_' else '_' for ch in token)         cleaned = cleaned.strip('_')         return cleaned or 'unknown'      @staticmethod     def _parse_age_to_float(series: pd.Series) -&gt; pd.Series:         def _parse_one(x) -&gt; float:             if pd.isna(x):                 return np.nan             s = str(x)             nums = re.findall(r'(\\d+(?:\\.\\d+)?)', s)             if not nums:                 return np.nan             vals = [float(n) for n in nums]             if len(vals) &gt;= 2:                 return float((vals[0] + vals[1]) / 2.0)               return float(vals[0])                                return series.apply(_parse_one).astype(float)      def _fit_numeric(self, series: pd.Series, column: str) -&gt; None:         values = pd.to_numeric(series, errors='coerce')         valid = values.dropna()         if valid.empty:             self.numeric_stats[column] = {'fill': 0.0, 'min': 0.0, 'max': 0.0}             return         fill = float(valid.mean())         min_val = float(valid.min())         max_val = float(valid.max())         self.numeric_stats[column] = {'fill': fill, 'min': min_val, 'max': max_val}      def fit(self, df: pd.DataFrame) -&gt; None:         df_copy = df.copy()         for column in df_copy.columns:             if column in self.key_columns:                 continue             if column in self.keep_columns:                 continue             if column in self.drop_columns:                 df_copy = df_copy.drop(columns=[column])                 continue              series = df_copy[column]              if column in self.age_columns:                 parsed_age = self._parse_age_to_float(series)                 self._fit_numeric(parsed_age, column)                 continue              if pd.api.types.is_numeric_dtype(series):                 self._fit_numeric(series, column)             else:                 numeric_candidate = pd.to_numeric(series, errors='coerce')                 if numeric_candidate.notna().sum() &gt;= len(series) * 0.5:                     self._fit_numeric(numeric_candidate, column)                 else:                     cats = series.dropna().astype(str)                     if cats.empty:                         levels = ['__missing__']                         mode_val = '__missing__'                     else:                         levels = sorted(cats.unique().tolist())                         mode_val = str(cats.mode().iloc[0])                     self.categorical_levels[column] = levels                     self.categorical_mode[column] = mode_val          feature_matrix = self._build_matrix(df_copy)         self.feature_columns = [c for c in feature_matrix.columns if c not in self.key_columns]      def _scale_numeric(self, series: pd.Series, stats: Dict[str, float]) -&gt; pd.Series:         values = pd.to_numeric(series, errors='coerce')         values = values.fillna(stats['fill'])         min_val = stats['min']         max_val = stats['max']         if np.isclose(max_val, min_val):             return pd.Series(0.0, index=series.index)         scaled = (values - min_val) / (max_val - min_val)         return 2.0 * scaled - 1.0      def _encode_categorical(self, series: pd.Series, column: str) -&gt; pd.DataFrame:         levels = self.categorical_levels[column]         mode_val = self.categorical_mode[column]          processed = series.astype(str).fillna(mode_val)         processed = processed.where(processed.isin(levels), mode_val)          encoded = {}         for level in levels:             col_name = f\"{column}_{self._sanitize_token(level)}\"             encoded[col_name] = (processed == level).astype(float)         return pd.DataFrame(encoded, index=series.index)      def _build_matrix(self, df: pd.DataFrame) -&gt; pd.DataFrame:         base_cols: Dict[str, pd.Series] = {}          for key in self.key_columns:             if key in df.columns:                 base_cols[key] = df[key]             else:                 base_cols[key] = pd.Series(np.nan, index=df.index, name=key)          for column, stats in self.numeric_stats.items():             if column in df.columns:                 series = df[column]                 if column in self.age_columns:                     series = self._parse_age_to_float(series)             else:                 series = pd.Series(np.nan, index=df.index, name=column)             base_cols[column] = self._scale_numeric(series, stats)          matrix = pd.concat(base_cols, axis=1)          cat_frames = []         for column in self.categorical_levels:             if column in df.columns:                 series = df[column]             else:                 series = pd.Series(self.categorical_mode[column], index=df.index, name=column)             encoded = self._encode_categorical(series, column)             cat_frames.append(encoded)          if cat_frames:             matrix = pd.concat([matrix] + cat_frames, axis=1)          return matrix.copy()       def transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:         if not self.numeric_stats and not self.categorical_levels:             raise RuntimeError('Preprocessor is not fitted.')          matrix = self._build_matrix(df.copy())          final_cols = self.key_columns + self.feature_columns         matrix = matrix.reindex(columns=final_cols, fill_value=0.0)          return matrix.copy()      def fit_transform(self, df: pd.DataFrame) -&gt; pd.DataFrame:         self.fit(df)         return self.transform(df)      def __repr__(self) -&gt; str:         return (             f'TrackingFeaturePreprocessor(numeric={len(self.numeric_stats)}, '             f'categorical={len(self.categorical_levels)}, '             f'features={len(self.feature_columns)})'         )  In\u00a0[139]: Copied! <pre>def to_numpy_array(obj, dtype=None):\n    if isinstance(obj, np.ndarray):\n        arr = obj\n    elif hasattr(obj, 'to_numpy'):\n        arr = obj.to_numpy()\n    else:\n        arr = np.array(obj)\n    if dtype is not None:\n        arr = arr.astype(dtype, copy=False)\n    return arr\n\ndef train_mlp_classifier(X, y, hidden_layers, output_dim, *, lr=0.05, max_epochs=2000, batch_size=64, random_state=42, l2=0.0, track_history=True):\n    X_np = to_numpy_array(X, dtype=np.float64)\n    y_np = to_numpy_array(y, dtype=int)\n    model = MLP(\n        input_dim=X_np.shape[1],\n        hidden_layers=hidden_layers,\n        output_dim=output_dim,\n        lr=lr,\n        max_epochs=max_epochs,\n        batch_size=batch_size,\n        random_state=random_state,\n        l2=l2,\n        track_history=track_history,\n    )\n    model.fit(X_np, y_np)\n    return model\n</pre> def to_numpy_array(obj, dtype=None):     if isinstance(obj, np.ndarray):         arr = obj     elif hasattr(obj, 'to_numpy'):         arr = obj.to_numpy()     else:         arr = np.array(obj)     if dtype is not None:         arr = arr.astype(dtype, copy=False)     return arr  def train_mlp_classifier(X, y, hidden_layers, output_dim, *, lr=0.05, max_epochs=2000, batch_size=64, random_state=42, l2=0.0, track_history=True):     X_np = to_numpy_array(X, dtype=np.float64)     y_np = to_numpy_array(y, dtype=int)     model = MLP(         input_dim=X_np.shape[1],         hidden_layers=hidden_layers,         output_dim=output_dim,         lr=lr,         max_epochs=max_epochs,         batch_size=batch_size,         random_state=random_state,         l2=l2,         track_history=track_history,     )     model.fit(X_np, y_np)     return model  In\u00a0[\u00a0]: Copied! <pre>NOTEBOOK_ROOT = Path.cwd().resolve()\nDATASET_CANDIDATES = [\n    NOTEBOOK_ROOT / 'data' / 'raw' / 'MABe-mouse-behavior-detection',\n    NOTEBOOK_ROOT / 'Data' / 'raw' / 'MABe-mouse-behavior-detection',\n    NOTEBOOK_ROOT / 'ClassificationProject' / 'data' / 'raw' / 'MABe-mouse-behavior-detection',\n    NOTEBOOK_ROOT / 'ClassificationProject' / 'Data' / 'raw' / 'MABe-mouse-behavior-detection',\n    NOTEBOOK_ROOT.parent / 'data' / 'raw' / 'MABe-mouse-behavior-detection',\n    NOTEBOOK_ROOT.parent / 'Data' / 'raw' / 'MABe-mouse-behavior-detection',\n]\nfor cand in DATASET_CANDIDATES:\n    if (cand / 'train.csv').exists():\n        DATASET_DIR = cand\n        break\nelse:\n    raise FileNotFoundError('N\u00e3o foi possivel localizar o diret\u00f3rio com train.csv')\n\nANNOTATION_DIR = DATASET_DIR / 'train_annotation'\nTRACKING_DIR = DATASET_DIR / 'train_tracking'\nTRAIN_PATH = DATASET_DIR / 'train.csv'\nTEST_PATH = DATASET_DIR / 'test.csv'\n\ntrain = pd.read_csv(TRAIN_PATH)\ntest_meta = pd.read_csv(TEST_PATH)\n\nprint('Diret\u00f3rio dos dados:', DATASET_DIR)\nprint('train.csv -&gt;', train.shape)\ndisplay(train.head())\n</pre> NOTEBOOK_ROOT = Path.cwd().resolve() DATASET_CANDIDATES = [     NOTEBOOK_ROOT / 'data' / 'raw' / 'MABe-mouse-behavior-detection',     NOTEBOOK_ROOT / 'Data' / 'raw' / 'MABe-mouse-behavior-detection',     NOTEBOOK_ROOT / 'ClassificationProject' / 'data' / 'raw' / 'MABe-mouse-behavior-detection',     NOTEBOOK_ROOT / 'ClassificationProject' / 'Data' / 'raw' / 'MABe-mouse-behavior-detection',     NOTEBOOK_ROOT.parent / 'data' / 'raw' / 'MABe-mouse-behavior-detection',     NOTEBOOK_ROOT.parent / 'Data' / 'raw' / 'MABe-mouse-behavior-detection', ] for cand in DATASET_CANDIDATES:     if (cand / 'train.csv').exists():         DATASET_DIR = cand         break else:     raise FileNotFoundError('N\u00e3o foi possivel localizar o diret\u00f3rio com train.csv')  ANNOTATION_DIR = DATASET_DIR / 'train_annotation' TRACKING_DIR = DATASET_DIR / 'train_tracking' TRAIN_PATH = DATASET_DIR / 'train.csv' TEST_PATH = DATASET_DIR / 'test.csv'  train = pd.read_csv(TRAIN_PATH) test_meta = pd.read_csv(TEST_PATH)  print('Diret\u00f3rio dos dados:', DATASET_DIR) print('train.csv -&gt;', train.shape) display(train.head())  <pre>Diret\u00f3rio dos dados: C:\\Users\\cailu\\OneDrive\\Documentos\\Work\\Deep\\ClassificationProject\\data\\raw\\MABe-mouse-behavior-detection\ntrain.csv -&gt; (8790, 38)\n</pre> lab_id video_id mouse1_strain mouse1_color mouse1_sex mouse1_id mouse1_age mouse1_condition mouse2_strain mouse2_color mouse2_sex mouse2_id mouse2_age mouse2_condition mouse3_strain mouse3_color mouse3_sex mouse3_id mouse3_age mouse3_condition mouse4_strain mouse4_color mouse4_sex mouse4_id mouse4_age mouse4_condition frames_per_second video_duration_sec pix_per_cm_approx video_width_pix video_height_pix arena_width_cm arena_height_cm arena_shape arena_type body_parts_tracked behaviors_labeled tracking_method 0 AdaptableSnail 44566106 CD-1 (ICR) white male 10.0 8-12 weeks wireless device CD-1 (ICR) white male 24.0 8-12 weeks wireless device CD-1 (ICR) white male 38.0 8-12 weeks wireless device CD-1 (ICR) white male 51.0 8-12 weeks wireless device 30.0 615.6 16.0 1228 1068 60.0 60.0 square familiar [\"body_center\", \"ear_left\", \"ear_right\", \"head... [\"mouse1,mouse2,approach\", \"mouse1,mouse2,atta... DeepLabCut 1 AdaptableSnail 143861384 CD-1 (ICR) white male 3.0 8-12 weeks NaN CD-1 (ICR) white male 17.0 8-12 weeks NaN CD-1 (ICR) white male 31.0 8-12 weeks NaN CD-1 (ICR) white male 44.0 8-12 weeks NaN 25.0 3599.0 9.7 968 608 60.0 60.0 square familiar [\"body_center\", \"ear_left\", \"ear_right\", \"late... [\"mouse1,mouse2,approach\", \"mouse1,mouse2,atta... DeepLabCut 2 AdaptableSnail 209576908 CD-1 (ICR) white male 7.0 8-12 weeks NaN CD-1 (ICR) white male 21.0 8-12 weeks NaN CD-1 (ICR) white male 35.0 8-12 weeks NaN CD-1 (ICR) white male 48.0 8-12 weeks NaN 30.0 615.2 16.0 1266 1100 60.0 60.0 square familiar [\"body_center\", \"ear_left\", \"ear_right\", \"late... [\"mouse1,mouse2,approach\", \"mouse1,mouse2,atta... DeepLabCut 3 AdaptableSnail 278643799 CD-1 (ICR) white male 11.0 8-12 weeks wireless device CD-1 (ICR) white male 25.0 8-12 weeks wireless device CD-1 (ICR) white male 39.0 8-12 weeks wireless device NaN NaN NaN NaN NaN NaN 30.0 619.7 16.0 1224 1100 60.0 60.0 square familiar [\"body_center\", \"ear_left\", \"ear_right\", \"head... [\"mouse1,mouse2,approach\", \"mouse1,mouse2,atta... DeepLabCut 4 AdaptableSnail 351967631 CD-1 (ICR) white male 14.0 8-12 weeks NaN CD-1 (ICR) white male 28.0 8-12 weeks NaN CD-1 (ICR) white male 42.0 8-12 weeks NaN NaN NaN NaN NaN 8-12 weeks NaN 30.0 602.6 16.0 1204 1068 60.0 60.0 square familiar [\"body_center\", \"ear_left\", \"ear_right\", \"late... [\"mouse1,mouse2,approach\", \"mouse1,mouse2,atta... DeepLabCut In\u00a0[141]: Copied! <pre>def load_annotation_events(annotation_root: Path, metadata_df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Carrega todas as anota\u00e7\u00f5es (.parquet) listadas em metadata_df.\"\"\"\n    expected_columns = {'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'}\n    records = []\n    missing_files = []\n    for lab_id, video_id in metadata_df[['lab_id', 'video_id']].drop_duplicates().itertuples(index=False):\n        annotation_path = annotation_root / lab_id / f\"{video_id}.parquet\"\n        if not annotation_path.exists():\n            missing_files.append((lab_id, video_id))\n            continue\n        df = pd.read_parquet(annotation_path)\n        missing_cols = expected_columns.difference(df.columns)\n        if missing_cols:\n            raise ValueError(f'Arquivo {annotation_path} n\u00e3o cont\u00e9m colunas esperadas: {missing_cols}')\n        df = df.assign(lab_id=lab_id, video_id=video_id)\n        records.append(df)\n    if not records:\n        raise FileNotFoundError('Nenhum arquivo de anota\u00e7\u00e3o foi carregado.')\n    annotations = pd.concat(records, ignore_index=True)\n    if missing_files:\n        print(f'Aviso: {len(missing_files)} arquivos de anota\u00e7\u00e3o n\u00e3o foram encontrados.')\n    return annotations\n\ndef _scale_to_minus_one_plus_one(series: pd.Series) -&gt; pd.Series:\n    min_val = series.min()\n    max_val = series.max()\n    if pd.isna(min_val) or pd.isna(max_val) or np.isclose(min_val, max_val):\n        return pd.Series(0.0, index=series.index)\n    scaled = (series - min_val) / (max_val - min_val)\n    return scaled * 2.0 - 1.0\n\ndef preprocess_annotations(annotations_df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Remove colunas n\u00e3o utilizadas e normaliza frames por v\u00eddeo.\"\"\"\n    required_keys = {'lab_id', 'video_id', 'action', 'start_frame', 'stop_frame'}\n    missing_keys = required_keys.difference(annotations_df.columns)\n    if missing_keys:\n        raise ValueError(f'Colunas obrigat\u00f3rias ausentes: {missing_keys}')\n    processed = annotations_df.drop(columns=['agent_id', 'target_id'], errors='ignore').copy()\n    group_keys = ['lab_id', 'video_id']\n    processed['start_frame_raw'] = processed['start_frame']\n    processed['stop_frame_raw'] = processed['stop_frame']\n    processed['start_frame'] = (\n        processed.groupby(group_keys)['start_frame'].transform(_scale_to_minus_one_plus_one)\n    )\n    processed['stop_frame'] = (\n        processed.groupby(group_keys)['stop_frame'].transform(_scale_to_minus_one_plus_one)\n    )\n    processed['action'] = processed['action'].astype('category')\n    ordered_cols = ['lab_id', 'video_id', 'action', 'start_frame_raw', 'stop_frame_raw', 'start_frame', 'stop_frame']\n    remaining_cols = [c for c in processed.columns if c not in ordered_cols]\n    return processed[ordered_cols + remaining_cols]\n</pre> def load_annotation_events(annotation_root: Path, metadata_df: pd.DataFrame) -&gt; pd.DataFrame:     \"\"\"Carrega todas as anota\u00e7\u00f5es (.parquet) listadas em metadata_df.\"\"\"     expected_columns = {'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'}     records = []     missing_files = []     for lab_id, video_id in metadata_df[['lab_id', 'video_id']].drop_duplicates().itertuples(index=False):         annotation_path = annotation_root / lab_id / f\"{video_id}.parquet\"         if not annotation_path.exists():             missing_files.append((lab_id, video_id))             continue         df = pd.read_parquet(annotation_path)         missing_cols = expected_columns.difference(df.columns)         if missing_cols:             raise ValueError(f'Arquivo {annotation_path} n\u00e3o cont\u00e9m colunas esperadas: {missing_cols}')         df = df.assign(lab_id=lab_id, video_id=video_id)         records.append(df)     if not records:         raise FileNotFoundError('Nenhum arquivo de anota\u00e7\u00e3o foi carregado.')     annotations = pd.concat(records, ignore_index=True)     if missing_files:         print(f'Aviso: {len(missing_files)} arquivos de anota\u00e7\u00e3o n\u00e3o foram encontrados.')     return annotations  def _scale_to_minus_one_plus_one(series: pd.Series) -&gt; pd.Series:     min_val = series.min()     max_val = series.max()     if pd.isna(min_val) or pd.isna(max_val) or np.isclose(min_val, max_val):         return pd.Series(0.0, index=series.index)     scaled = (series - min_val) / (max_val - min_val)     return scaled * 2.0 - 1.0  def preprocess_annotations(annotations_df: pd.DataFrame) -&gt; pd.DataFrame:     \"\"\"Remove colunas n\u00e3o utilizadas e normaliza frames por v\u00eddeo.\"\"\"     required_keys = {'lab_id', 'video_id', 'action', 'start_frame', 'stop_frame'}     missing_keys = required_keys.difference(annotations_df.columns)     if missing_keys:         raise ValueError(f'Colunas obrigat\u00f3rias ausentes: {missing_keys}')     processed = annotations_df.drop(columns=['agent_id', 'target_id'], errors='ignore').copy()     group_keys = ['lab_id', 'video_id']     processed['start_frame_raw'] = processed['start_frame']     processed['stop_frame_raw'] = processed['stop_frame']     processed['start_frame'] = (         processed.groupby(group_keys)['start_frame'].transform(_scale_to_minus_one_plus_one)     )     processed['stop_frame'] = (         processed.groupby(group_keys)['stop_frame'].transform(_scale_to_minus_one_plus_one)     )     processed['action'] = processed['action'].astype('category')     ordered_cols = ['lab_id', 'video_id', 'action', 'start_frame_raw', 'stop_frame_raw', 'start_frame', 'stop_frame']     remaining_cols = [c for c in processed.columns if c not in ordered_cols]     return processed[ordered_cols + remaining_cols] In\u00a0[\u00a0]: Copied! <pre>def min_max_scale_to_unit_interval(series: pd.Series, min_val: float, max_val: float, *, target_min: float = -1.0, target_max: float = 1.0) -&gt; pd.Series:\n    if pd.isna(min_val) or pd.isna(max_val) or np.isclose(max_val, min_val):\n        return pd.Series(target_min, index=series.index, dtype=float)\n    scaled = (series - min_val) / (max_val - min_val)\n    scaled = scaled * (target_max - target_min) + target_min\n    return scaled\n\nfrom typing import Dict, Optional, Tuple, List\n\n_frame_movement_cache: Dict[Tuple[str, str, str], Optional[pd.DataFrame]] = {}\n\ndef _load_frame_movement_features(tracking_root: Path, lab_id: str, video_id) -&gt; Optional[pd.DataFrame]:\n    \"\"\"Retorna deslocamentos por frame para cada junta e agregados.\"\"\"\n    key = (str(tracking_root.resolve()), str(lab_id), str(video_id))\n    if key in _frame_movement_cache:\n        return _frame_movement_cache[key]\n    path = tracking_root / str(lab_id) / f\"{video_id}.parquet\"\n    if not path.exists():\n        _frame_movement_cache[key] = None\n        return None\n    df_track = pd.read_parquet(path)\n    required_cols = {'mouse_id', 'bodypart', 'video_frame', 'x', 'y'}\n    if df_track.empty or not required_cols.issubset(df_track.columns):\n        _frame_movement_cache[key] = None\n        return None\n    df_track = df_track.sort_values(['mouse_id', 'bodypart', 'video_frame'])\n    df_track[['dx', 'dy']] = df_track.groupby(['mouse_id', 'bodypart'])[['x', 'y']].diff()\n    df_track[['dx', 'dy']] = df_track[['dx', 'dy']].fillna(0.0)\n    df_track['distance'] = np.sqrt(df_track['dx']**2 + df_track['dy']**2)\n    frame_movement: Dict[str, pd.Series] = {}\n    overall = df_track.groupby('video_frame')['distance'].sum().astype(float)\n    frame_movement['movement_overall'] = overall\n    for mouse_id, df_mouse in df_track.groupby('mouse_id'):\n        try:\n            mouse_int = int(mouse_id)\n        except (TypeError, ValueError):\n            continue\n        key_mouse = f\"movement_mouse{mouse_int}\"\n        frame_movement[key_mouse] = df_mouse.groupby('video_frame')['distance'].sum().astype(float)\n        for bodypart, df_part in df_mouse.groupby('bodypart'):\n            part_key = MainFeaturesPreprocessor._sanitize_token(bodypart)\n            key_joint = f\"movement_mouse{mouse_int}_{part_key}\"\n            frame_movement[key_joint] = df_part.groupby('video_frame')['distance'].sum().astype(float)\n    movement_df = pd.DataFrame(frame_movement).sort_index().fillna(0.0)\n    _frame_movement_cache[key] = movement_df\n    return movement_df\n\ndef compute_segment_movement_totals(df: pd.DataFrame, tracking_root: Path, *, start_col: str = 'start_frame_raw', stop_col: str = 'stop_frame_raw') -&gt; pd.DataFrame:\n    \"\"\"Calcula a dist\u00e2ncia total percorrida por junta em cada segmento.\"\"\"\n    segment_data: Dict[int, pd.Series] = {}\n    all_columns: List[str] = []\n    for (lab_id, video_id), group in df.groupby(['lab_id', 'video_id']):\n        movement_df = _load_frame_movement_features(tracking_root, lab_id, video_id)\n        if movement_df is not None:\n            cols = list(movement_df.columns)\n            for col in cols:\n                if col not in all_columns:\n                    all_columns.append(col)\n            movement_df = movement_df.sort_index()\n        for idx, row in group.iterrows():\n            start = row.get(start_col)\n            stop = row.get(stop_col)\n            if movement_df is None or movement_df.empty or pd.isna(start) or pd.isna(stop):\n                continue\n            start_i = int(np.floor(start))\n            stop_i = int(np.floor(stop))\n            if stop_i &lt; start_i:\n                start_i, stop_i = stop_i, start_i\n            subset = movement_df.loc[start_i:stop_i]\n            if subset.empty:\n                continue\n            segment_data[idx] = subset.sum()\n    if not all_columns:\n        return pd.DataFrame(index=df.index)\n    result = pd.DataFrame(index=df.index, columns=all_columns, dtype=float)\n    for idx, series in segment_data.items():\n        result.loc[idx, series.index] = series.values\n    return result\n\ndef scale_segment_movement_columns(segment_df: pd.DataFrame, target_columns: List[str], stats_dict: Dict[str, Dict[str, float]]) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:\n    segment_df = segment_df.reindex(columns=target_columns)\n    raw_df = pd.DataFrame(index=segment_df.index, columns=target_columns, dtype=float)\n    scaled_df = pd.DataFrame(index=segment_df.index, columns=target_columns, dtype=float)\n    for col in target_columns:\n        series = segment_df[col]\n        stats = stats_dict.get(col, {})\n        fill_value = stats.get('fill', np.nan)\n        if pd.isna(fill_value):\n            fill_value = series.mean(skipna=True)\n        if pd.isna(fill_value):\n            fill_value = 0.0\n        filled = series.fillna(fill_value)\n        raw_df[col] = filled\n        min_val = stats.get('min', np.nan)\n        max_val = stats.get('max', np.nan)\n        if pd.isna(min_val) or pd.isna(max_val) or np.isclose(max_val, min_val):\n            min_val = filled.min(skipna=True)\n            max_val = filled.max(skipna=True)\n        if pd.isna(min_val) or pd.isna(max_val) or np.isclose(max_val, min_val):\n            scaled_df[col] = 0.0\n        else:\n            scaled = 2.0 * ((filled - min_val) / (max_val - min_val)) - 1.0\n            scaled_df[col] = scaled.clip(-1.0, 1.0)\n    return raw_df, scaled_df\n</pre> def min_max_scale_to_unit_interval(series: pd.Series, min_val: float, max_val: float, *, target_min: float = -1.0, target_max: float = 1.0) -&gt; pd.Series:     if pd.isna(min_val) or pd.isna(max_val) or np.isclose(max_val, min_val):         return pd.Series(target_min, index=series.index, dtype=float)     scaled = (series - min_val) / (max_val - min_val)     scaled = scaled * (target_max - target_min) + target_min     return scaled  from typing import Dict, Optional, Tuple, List  _frame_movement_cache: Dict[Tuple[str, str, str], Optional[pd.DataFrame]] = {}  def _load_frame_movement_features(tracking_root: Path, lab_id: str, video_id) -&gt; Optional[pd.DataFrame]:     \"\"\"Retorna deslocamentos por frame para cada junta e agregados.\"\"\"     key = (str(tracking_root.resolve()), str(lab_id), str(video_id))     if key in _frame_movement_cache:         return _frame_movement_cache[key]     path = tracking_root / str(lab_id) / f\"{video_id}.parquet\"     if not path.exists():         _frame_movement_cache[key] = None         return None     df_track = pd.read_parquet(path)     required_cols = {'mouse_id', 'bodypart', 'video_frame', 'x', 'y'}     if df_track.empty or not required_cols.issubset(df_track.columns):         _frame_movement_cache[key] = None         return None     df_track = df_track.sort_values(['mouse_id', 'bodypart', 'video_frame'])     df_track[['dx', 'dy']] = df_track.groupby(['mouse_id', 'bodypart'])[['x', 'y']].diff()     df_track[['dx', 'dy']] = df_track[['dx', 'dy']].fillna(0.0)     df_track['distance'] = np.sqrt(df_track['dx']**2 + df_track['dy']**2)     frame_movement: Dict[str, pd.Series] = {}     overall = df_track.groupby('video_frame')['distance'].sum().astype(float)     frame_movement['movement_overall'] = overall     for mouse_id, df_mouse in df_track.groupby('mouse_id'):         try:             mouse_int = int(mouse_id)         except (TypeError, ValueError):             continue         key_mouse = f\"movement_mouse{mouse_int}\"         frame_movement[key_mouse] = df_mouse.groupby('video_frame')['distance'].sum().astype(float)         for bodypart, df_part in df_mouse.groupby('bodypart'):             part_key = MainFeaturesPreprocessor._sanitize_token(bodypart)             key_joint = f\"movement_mouse{mouse_int}_{part_key}\"             frame_movement[key_joint] = df_part.groupby('video_frame')['distance'].sum().astype(float)     movement_df = pd.DataFrame(frame_movement).sort_index().fillna(0.0)     _frame_movement_cache[key] = movement_df     return movement_df  def compute_segment_movement_totals(df: pd.DataFrame, tracking_root: Path, *, start_col: str = 'start_frame_raw', stop_col: str = 'stop_frame_raw') -&gt; pd.DataFrame:     \"\"\"Calcula a dist\u00e2ncia total percorrida por junta em cada segmento.\"\"\"     segment_data: Dict[int, pd.Series] = {}     all_columns: List[str] = []     for (lab_id, video_id), group in df.groupby(['lab_id', 'video_id']):         movement_df = _load_frame_movement_features(tracking_root, lab_id, video_id)         if movement_df is not None:             cols = list(movement_df.columns)             for col in cols:                 if col not in all_columns:                     all_columns.append(col)             movement_df = movement_df.sort_index()         for idx, row in group.iterrows():             start = row.get(start_col)             stop = row.get(stop_col)             if movement_df is None or movement_df.empty or pd.isna(start) or pd.isna(stop):                 continue             start_i = int(np.floor(start))             stop_i = int(np.floor(stop))             if stop_i &lt; start_i:                 start_i, stop_i = stop_i, start_i             subset = movement_df.loc[start_i:stop_i]             if subset.empty:                 continue             segment_data[idx] = subset.sum()     if not all_columns:         return pd.DataFrame(index=df.index)     result = pd.DataFrame(index=df.index, columns=all_columns, dtype=float)     for idx, series in segment_data.items():         result.loc[idx, series.index] = series.values     return result  def scale_segment_movement_columns(segment_df: pd.DataFrame, target_columns: List[str], stats_dict: Dict[str, Dict[str, float]]) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:     segment_df = segment_df.reindex(columns=target_columns)     raw_df = pd.DataFrame(index=segment_df.index, columns=target_columns, dtype=float)     scaled_df = pd.DataFrame(index=segment_df.index, columns=target_columns, dtype=float)     for col in target_columns:         series = segment_df[col]         stats = stats_dict.get(col, {})         fill_value = stats.get('fill', np.nan)         if pd.isna(fill_value):             fill_value = series.mean(skipna=True)         if pd.isna(fill_value):             fill_value = 0.0         filled = series.fillna(fill_value)         raw_df[col] = filled         min_val = stats.get('min', np.nan)         max_val = stats.get('max', np.nan)         if pd.isna(min_val) or pd.isna(max_val) or np.isclose(max_val, min_val):             min_val = filled.min(skipna=True)             max_val = filled.max(skipna=True)         if pd.isna(min_val) or pd.isna(max_val) or np.isclose(max_val, min_val):             scaled_df[col] = 0.0         else:             scaled = 2.0 * ((filled - min_val) / (max_val - min_val)) - 1.0             scaled_df[col] = scaled.clip(-1.0, 1.0)     return raw_df, scaled_df  In\u00a0[143]: Copied! <pre>annotations_raw = load_annotation_events(ANNOTATION_DIR, train)\nannotations_processed = preprocess_annotations(annotations_raw)\nprint('Anota\u00e7\u00f5es carregadas:', annotations_raw.shape)\nprint('Anota\u00e7\u00f5es processadas:', annotations_processed.shape)\ndisplay(annotations_processed.head())\n</pre> annotations_raw = load_annotation_events(ANNOTATION_DIR, train) annotations_processed = preprocess_annotations(annotations_raw) print('Anota\u00e7\u00f5es carregadas:', annotations_raw.shape) print('Anota\u00e7\u00f5es processadas:', annotations_processed.shape) display(annotations_processed.head()) <pre>Aviso: 7927 arquivos de anota\u00e7\u00e3o n\u00e3o foram encontrados.\nAnota\u00e7\u00f5es carregadas: (84066, 7)\nAnota\u00e7\u00f5es processadas: (84066, 7)\n</pre> lab_id video_id action start_frame_raw stop_frame_raw start_frame stop_frame 0 AdaptableSnail 44566106 rear 4 139 -1.000000 -0.990498 1 AdaptableSnail 44566106 avoid 13 52 -0.999017 -1.000000 2 AdaptableSnail 44566106 rear 121 172 -0.987224 -0.986893 3 AdaptableSnail 44566106 rear 156 213 -0.983402 -0.982415 4 AdaptableSnail 44566106 rear 208 261 -0.977724 -0.977172 In\u00a0[144]: Copied! <pre>preprocessor = MainFeaturesPreprocessor()\n\ntrain_processed = preprocessor.fit_transform(train)\n\nprint('Shape das features de treino:', train_processed.shape)\ndisplay(train_processed.head())\n</pre> preprocessor = MainFeaturesPreprocessor()  train_processed = preprocessor.fit_transform(train)  print('Shape das features de treino:', train_processed.shape) display(train_processed.head()) <pre>Shape das features de treino: (8790, 65)\n</pre> lab_id video_id mouse1_age mouse2_age mouse3_age mouse4_age frames_per_second video_duration_sec pix_per_cm_approx video_width_pix video_height_pix arena_width_cm arena_height_cm mouse1_strain_129_svevtac mouse1_strain_btbr mouse1_strain_c57bl_6j mouse1_strain_c57bl_6j_x_ai148 mouse1_strain_c57bl_6n mouse1_strain_cd_1__icr mouse1_strain_cd1 mouse1_strain_cfw mouse1_color_black mouse1_color_black_and_tan mouse1_color_brown mouse1_color_white mouse1_sex_female mouse1_sex_male mouse2_strain_129_svevtac mouse2_strain_balb_c mouse2_strain_btbr mouse2_strain_c57bl_6j mouse2_strain_c57bl_6n mouse2_strain_cd_1__icr mouse2_strain_cd1 mouse2_strain_cfw mouse2_color_black mouse2_color_black_and_tan mouse2_color_brown mouse2_color_white mouse2_sex_female mouse2_sex_male mouse3_strain_btbr mouse3_strain_c57bl_6j mouse3_strain_cd_1__icr mouse3_color_black mouse3_color_black_and_tan mouse3_color_white mouse3_sex_male mouse4_strain_cd_1__icr mouse4_color_white mouse4_sex_male mouse4_condition_wireless_device arena_shape_circular arena_shape_rectangular arena_shape_split_rectangluar arena_shape_square arena_type_csds arena_type_divided_territories arena_type_familiar arena_type_neutral arena_type_resident_intruder tracking_method_deeplabcut tracking_method_mars tracking_method_sleap tracking_method_custom_hrnet 0 AdaptableSnail 44566106 -0.875 -0.636364 -1.0 0.0 -0.636430 -0.939683 -0.647059 0.061785 -0.061224 -0.11836 -0.111111 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 1 AdaptableSnail 143861384 -0.875 -0.636364 -1.0 0.0 -0.727322 -0.638055 -0.858824 -0.235698 -0.555317 -0.11836 -0.111111 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 2 AdaptableSnail 209576908 -0.875 -0.636364 -1.0 0.0 -0.636430 -0.939723 -0.647059 0.105263 -0.026853 -0.11836 -0.111111 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 3 AdaptableSnail 278643799 -0.875 -0.636364 -1.0 0.0 -0.636430 -0.939268 -0.647059 0.057208 -0.026853 -0.11836 -0.111111 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 4 AdaptableSnail 351967631 -0.875 -0.636364 -1.0 0.0 -0.636430 -0.940997 -0.647059 0.034325 -0.061224 -0.11836 -0.111111 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 0.0 0.0 In\u00a0[\u00a0]: Copied! <pre>TRACKING_MOVEMENT_COLUMNS: List[str] = []\nSEGMENT_TRACKING_FEATURE_COLUMNS: List[str] = []\nMETADATA_FEATURE_COLUMNS: List[str] = []\nSEGMENT_MOVEMENT_STATS: Dict[str, Dict[str, float]] = {}\n</pre> TRACKING_MOVEMENT_COLUMNS: List[str] = [] SEGMENT_TRACKING_FEATURE_COLUMNS: List[str] = [] METADATA_FEATURE_COLUMNS: List[str] = [] SEGMENT_MOVEMENT_STATS: Dict[str, Dict[str, float]] = {} In\u00a0[\u00a0]: Copied! <pre>actions_available = annotations_raw.dropna(subset=['action'])\naction_counts = actions_available['action'].value_counts().sort_values(ascending=False)\nplt.figure(figsize=(10, 4 + 0.2 * len(action_counts)))\nsns.barplot(x=action_counts.values, y=action_counts.index)\nplt.title('Distribui\u00e7\u00e3o das a\u00e7\u00f5es (annotations)')\nplt.xlabel('Ocorr\u00eancias')\nplt.ylabel('action')\nplt.show()\n\nagent_target_valid = annotations_raw.dropna(subset=['agent_id', 'target_id']).copy()\nagent_target_valid[['agent_id', 'target_id']] = agent_target_valid[['agent_id', 'target_id']].astype(int)\nagent_target_combo = (\n    agent_target_valid['agent_id'].astype(str) + '-' + agent_target_valid['target_id'].astype(str)\n)\ncombo_counts = agent_target_combo.value_counts().sort_values(ascending=False)\nplt.figure(figsize=(10, 4 + 0.2 * min(30, len(combo_counts))))\nsns.barplot(x=combo_counts.head(30).values, y=combo_counts.head(30).index)\nplt.title('Top 30 combina\u00e7\u00f5es agente-target')\nplt.xlabel('Ocorr\u00eancias')\nplt.ylabel('Agente -&gt; Alvo')\nplt.show()\n</pre> actions_available = annotations_raw.dropna(subset=['action']) action_counts = actions_available['action'].value_counts().sort_values(ascending=False) plt.figure(figsize=(10, 4 + 0.2 * len(action_counts))) sns.barplot(x=action_counts.values, y=action_counts.index) plt.title('Distribui\u00e7\u00e3o das a\u00e7\u00f5es (annotations)') plt.xlabel('Ocorr\u00eancias') plt.ylabel('action') plt.show()  agent_target_valid = annotations_raw.dropna(subset=['agent_id', 'target_id']).copy() agent_target_valid[['agent_id', 'target_id']] = agent_target_valid[['agent_id', 'target_id']].astype(int) agent_target_combo = (     agent_target_valid['agent_id'].astype(str) + '-' + agent_target_valid['target_id'].astype(str) ) combo_counts = agent_target_combo.value_counts().sort_values(ascending=False) plt.figure(figsize=(10, 4 + 0.2 * min(30, len(combo_counts)))) sns.barplot(x=combo_counts.head(30).values, y=combo_counts.head(30).index) plt.title('Top 30 combina\u00e7\u00f5es agente-target') plt.xlabel('Ocorr\u00eancias') plt.ylabel('Agente -&gt; Alvo') plt.show()  In\u00a0[147]: Copied! <pre>def plot_missing_ratios(df: pd.DataFrame, title: str, top_n: int = 25):\n    missing_ratio = df.isna().mean()\n    missing_ratio = missing_ratio[missing_ratio &gt; 0].sort_values(ascending=False)\n    if missing_ratio.empty:\n        print(f'Sem valores faltantes em {title}.')\n        return\n    subset = missing_ratio.head(top_n)\n    plt.figure(figsize=(10, max(3, len(subset) * 0.3)))\n    sns.barplot(x=subset.values, y=subset.index)\n    plt.title(f'Valores faltantes - {title}')\n    plt.xlabel('Propor\u00e7\u00e3o faltante')\n    plt.ylabel('Coluna')\n    plt.xlim(0, 1)\n    plt.show()\n\nplot_missing_ratios(train, 'train.csv (meta)')\n</pre> def plot_missing_ratios(df: pd.DataFrame, title: str, top_n: int = 25):     missing_ratio = df.isna().mean()     missing_ratio = missing_ratio[missing_ratio &gt; 0].sort_values(ascending=False)     if missing_ratio.empty:         print(f'Sem valores faltantes em {title}.')         return     subset = missing_ratio.head(top_n)     plt.figure(figsize=(10, max(3, len(subset) * 0.3)))     sns.barplot(x=subset.values, y=subset.index)     plt.title(f'Valores faltantes - {title}')     plt.xlabel('Propor\u00e7\u00e3o faltante')     plt.ylabel('Coluna')     plt.xlim(0, 1)     plt.show()  plot_missing_ratios(train, 'train.csv (meta)')  In\u00a0[\u00a0]: Copied! <pre>same_action_limit = 1000\nannotations_limited = []\nfor action, group in annotations_processed.groupby('action', observed=False):\n    if len(group) &gt; same_action_limit:\n        sampled = group.sample(n=same_action_limit, random_state=42)\n        annotations_limited.append(sampled)\n    else:\n        annotations_limited.append(group)\n\nannotations_processed = pd.concat(annotations_limited).reset_index(drop=True)\nprint(f'Anota\u00e7\u00f5es limitadas a {same_action_limit} por a\u00e7\u00e3o: {annotations_processed.shape}')\n</pre> same_action_limit = 1000 annotations_limited = [] for action, group in annotations_processed.groupby('action', observed=False):     if len(group) &gt; same_action_limit:         sampled = group.sample(n=same_action_limit, random_state=42)         annotations_limited.append(sampled)     else:         annotations_limited.append(group)  annotations_processed = pd.concat(annotations_limited).reset_index(drop=True) print(f'Anota\u00e7\u00f5es limitadas a {same_action_limit} por a\u00e7\u00e3o: {annotations_processed.shape}') <pre>Anota\u00e7\u00f5es limitadas a 1000 por a\u00e7\u00e3o: (19414, 7)\n</pre> In\u00a0[\u00a0]: Copied! <pre>actions_available = annotations_processed.dropna(subset=['action'])\naction_counts = actions_available['action'].value_counts().sort_values(ascending=False)\nplt.figure(figsize=(10, 4 + 0.2 * len(action_counts)))\nsns.barplot(x=action_counts.values, y=action_counts.index)\nplt.title('Distribui\u00e7\u00e3o das a\u00e7\u00f5es (annotations)')\nplt.xlabel('Ocorr\u00eancias')\nplt.ylabel('action')\nplt.show()\n</pre> actions_available = annotations_processed.dropna(subset=['action']) action_counts = actions_available['action'].value_counts().sort_values(ascending=False) plt.figure(figsize=(10, 4 + 0.2 * len(action_counts))) sns.barplot(x=action_counts.values, y=action_counts.index) plt.title('Distribui\u00e7\u00e3o das a\u00e7\u00f5es (annotations)') plt.xlabel('Ocorr\u00eancias') plt.ylabel('action') plt.show() In\u00a0[\u00a0]: Copied! <pre>global TRACKING_MOVEMENT_COLUMNS, SEGMENT_TRACKING_FEATURE_COLUMNS, SEGMENT_MOVEMENT_STATS\nsegment_movement_totals = compute_segment_movement_totals(annotations_processed, TRACKING_DIR)\nTRACKING_MOVEMENT_COLUMNS = sorted(segment_movement_totals.columns.tolist())\nSEGMENT_TRACKING_FEATURE_COLUMNS = [f'segment_total_scaled_{col}' for col in TRACKING_MOVEMENT_COLUMNS]\nSEGMENT_MOVEMENT_STATS = {}\nscaled_segment_frames = {}\nfor col in TRACKING_MOVEMENT_COLUMNS:\n    series = segment_movement_totals[col]\n    valid = series.dropna()\n    fill = float(valid.mean()) if not valid.empty else 0.0\n    min_val = float(valid.min()) if not valid.empty else 0.0\n    max_val = float(valid.max()) if not valid.empty else 0.0\n    SEGMENT_MOVEMENT_STATS[col] = {'fill': fill, 'min': min_val, 'max': max_val}\n    filled = series.fillna(fill)\n    scaled_segment_frames[col] = min_max_scale_to_unit_interval(filled, min_val, max_val)\nscaled_df = pd.DataFrame(scaled_segment_frames, index=segment_movement_totals.index)[TRACKING_MOVEMENT_COLUMNS]\nannotations_processed = annotations_processed.join(segment_movement_totals.add_prefix('segment_total_raw_'))\nannotations_processed = annotations_processed.join(scaled_df.add_prefix('segment_total_scaled_'))\npreview_cols = ['lab_id', 'video_id', 'start_frame_raw', 'stop_frame_raw']\npreview_cols += [f'segment_total_scaled_{col}' for col in TRACKING_MOVEMENT_COLUMNS[:5]]\ndisplay(annotations_processed[preview_cols].head())\n</pre> global TRACKING_MOVEMENT_COLUMNS, SEGMENT_TRACKING_FEATURE_COLUMNS, SEGMENT_MOVEMENT_STATS segment_movement_totals = compute_segment_movement_totals(annotations_processed, TRACKING_DIR) TRACKING_MOVEMENT_COLUMNS = sorted(segment_movement_totals.columns.tolist()) SEGMENT_TRACKING_FEATURE_COLUMNS = [f'segment_total_scaled_{col}' for col in TRACKING_MOVEMENT_COLUMNS] SEGMENT_MOVEMENT_STATS = {} scaled_segment_frames = {} for col in TRACKING_MOVEMENT_COLUMNS:     series = segment_movement_totals[col]     valid = series.dropna()     fill = float(valid.mean()) if not valid.empty else 0.0     min_val = float(valid.min()) if not valid.empty else 0.0     max_val = float(valid.max()) if not valid.empty else 0.0     SEGMENT_MOVEMENT_STATS[col] = {'fill': fill, 'min': min_val, 'max': max_val}     filled = series.fillna(fill)     scaled_segment_frames[col] = min_max_scale_to_unit_interval(filled, min_val, max_val) scaled_df = pd.DataFrame(scaled_segment_frames, index=segment_movement_totals.index)[TRACKING_MOVEMENT_COLUMNS] annotations_processed = annotations_processed.join(segment_movement_totals.add_prefix('segment_total_raw_')) annotations_processed = annotations_processed.join(scaled_df.add_prefix('segment_total_scaled_')) preview_cols = ['lab_id', 'video_id', 'start_frame_raw', 'stop_frame_raw'] preview_cols += [f'segment_total_scaled_{col}' for col in TRACKING_MOVEMENT_COLUMNS[:5]] display(annotations_processed[preview_cols].head())  lab_id video_id start_frame_raw stop_frame_raw segment_total_scaled_movement_mouse1 segment_total_scaled_movement_mouse1_body_center segment_total_scaled_movement_mouse1_ear_left segment_total_scaled_movement_mouse1_ear_right segment_total_scaled_movement_mouse1_head 0 ElegantMink 535058450 39645 39852 -0.974919 -0.982241 -0.949440 -0.941416 -0.976453 1 ElegantMink 535058450 40044 40137 -0.981658 -0.982241 -0.960101 -0.964239 -0.976453 2 ElegantMink 535058450 40474 40541 -0.992511 -0.982241 -0.984438 -0.984680 -0.976453 3 ElegantMink 551378303 17285 17359 -0.989337 -0.982241 -0.974997 -0.974261 -0.976453 4 ElegantMink 685480647 4981 5122 -0.989792 -0.982241 -0.969088 -0.966019 -0.976453 In\u00a0[151]: Copied! <pre>annotations_with_features = annotations_processed.merge(\n    train_processed,\n    on=['lab_id', 'video_id'],\n    how='left',\n    validate='many_to_one'\n)\nfeature_columns = [c for c in train_processed.columns if c not in ['lab_id', 'video_id']]\nmissing_feature_rows = annotations_with_features[feature_columns].isna().any(axis=1).sum() if feature_columns else 0\nprint('Dataset final de eventos + features:', annotations_with_features.shape)\nif missing_feature_rows:\n    print(f'Aviso: {missing_feature_rows} linhas est\u00e3o sem alguma feature de tracking ap\u00f3s o merge.')\nelse:\n    print('Todas as linhas contam com as features de tracking correspondentes.')\ndisplay(annotations_with_features.head())\n</pre> annotations_with_features = annotations_processed.merge(     train_processed,     on=['lab_id', 'video_id'],     how='left',     validate='many_to_one' ) feature_columns = [c for c in train_processed.columns if c not in ['lab_id', 'video_id']] missing_feature_rows = annotations_with_features[feature_columns].isna().any(axis=1).sum() if feature_columns else 0 print('Dataset final de eventos + features:', annotations_with_features.shape) if missing_feature_rows:     print(f'Aviso: {missing_feature_rows} linhas est\u00e3o sem alguma feature de tracking ap\u00f3s o merge.') else:     print('Todas as linhas contam com as features de tracking correspondentes.') display(annotations_with_features.head())  <pre>Dataset final de eventos + features: (19414, 252)\nTodas as linhas contam com as features de tracking correspondentes.\n</pre> lab_id video_id action start_frame_raw stop_frame_raw start_frame stop_frame segment_total_raw_movement_overall segment_total_raw_movement_mouse1 segment_total_raw_movement_mouse1_body_center segment_total_raw_movement_mouse1_ear_left segment_total_raw_movement_mouse1_ear_right segment_total_raw_movement_mouse1_headpiece_bottombackleft segment_total_raw_movement_mouse1_headpiece_bottombackright segment_total_raw_movement_mouse1_headpiece_bottomfrontleft segment_total_raw_movement_mouse1_headpiece_bottomfrontright segment_total_raw_movement_mouse1_headpiece_topbackleft segment_total_raw_movement_mouse1_headpiece_topbackright segment_total_raw_movement_mouse1_headpiece_topfrontleft segment_total_raw_movement_mouse1_headpiece_topfrontright segment_total_raw_movement_mouse1_lateral_left segment_total_raw_movement_mouse1_lateral_right segment_total_raw_movement_mouse1_neck segment_total_raw_movement_mouse1_nose segment_total_raw_movement_mouse1_tail_base segment_total_raw_movement_mouse1_tail_midpoint segment_total_raw_movement_mouse1_tail_tip segment_total_raw_movement_mouse2 segment_total_raw_movement_mouse2_body_center segment_total_raw_movement_mouse2_ear_left segment_total_raw_movement_mouse2_ear_right segment_total_raw_movement_mouse2_headpiece_bottombackleft segment_total_raw_movement_mouse2_headpiece_bottombackright segment_total_raw_movement_mouse2_headpiece_bottomfrontleft segment_total_raw_movement_mouse2_headpiece_bottomfrontright segment_total_raw_movement_mouse2_headpiece_topbackleft segment_total_raw_movement_mouse2_headpiece_topbackright segment_total_raw_movement_mouse2_headpiece_topfrontleft segment_total_raw_movement_mouse2_headpiece_topfrontright segment_total_raw_movement_mouse2_lateral_left segment_total_raw_movement_mouse2_lateral_right segment_total_raw_movement_mouse2_neck segment_total_raw_movement_mouse2_nose segment_total_raw_movement_mouse2_tail_base segment_total_raw_movement_mouse2_tail_midpoint segment_total_raw_movement_mouse2_tail_tip segment_total_raw_movement_mouse3 segment_total_raw_movement_mouse3_body_center segment_total_raw_movement_mouse3_ear_left segment_total_raw_movement_mouse3_ear_right ... mouse1_strain_c57bl_6j mouse1_strain_c57bl_6j_x_ai148 mouse1_strain_c57bl_6n mouse1_strain_cd_1__icr mouse1_strain_cd1 mouse1_strain_cfw mouse1_color_black mouse1_color_black_and_tan mouse1_color_brown mouse1_color_white mouse1_sex_female mouse1_sex_male mouse2_strain_129_svevtac mouse2_strain_balb_c mouse2_strain_btbr mouse2_strain_c57bl_6j mouse2_strain_c57bl_6n mouse2_strain_cd_1__icr mouse2_strain_cd1 mouse2_strain_cfw mouse2_color_black mouse2_color_black_and_tan mouse2_color_brown mouse2_color_white mouse2_sex_female mouse2_sex_male mouse3_strain_btbr mouse3_strain_c57bl_6j mouse3_strain_cd_1__icr mouse3_color_black mouse3_color_black_and_tan mouse3_color_white mouse3_sex_male mouse4_strain_cd_1__icr mouse4_color_white mouse4_sex_male mouse4_condition_wireless_device arena_shape_circular arena_shape_rectangular arena_shape_split_rectangluar arena_shape_square arena_type_csds arena_type_divided_territories arena_type_familiar arena_type_neutral arena_type_resident_intruder tracking_method_deeplabcut tracking_method_mars tracking_method_sleap tracking_method_custom_hrnet 0 ElegantMink 535058450 allogroom 39645 39852 0.492141 0.496635 17989.650651 7370.210125 NaN 933.979944 1080.127658 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 1052.058897 889.825497 1100.308806 NaN NaN 10619.440380 NaN 1497.375330 1587.650563 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 1462.700957 1810.613754 1486.437784 NaN NaN NaN NaN NaN NaN ... 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1 ElegantMink 535058450 allogroom 40044 40137 0.507958 0.507917 11411.508750 5389.880918 NaN 737.050532 659.327455 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 693.275211 694.950474 955.956143 NaN NaN 6021.627804 NaN 965.482169 860.706306 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 897.032907 976.991296 772.056954 NaN NaN NaN NaN NaN NaN ... 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 2 ElegantMink 535058450 allogroom 40474 40541 0.525004 0.523909 5271.261001 2200.580619 NaN 287.479137 282.458786 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 281.458461 288.532276 354.006872 NaN NaN 3070.680404 NaN 497.500983 527.033573 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 496.341674 466.570213 344.315980 NaN NaN NaN NaN NaN NaN ... 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 3 ElegantMink 551378303 allogroom 17285 17359 -0.232844 -0.246127 4687.871861 3133.433072 NaN 461.869503 474.547071 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 452.422745 371.549803 464.871006 NaN NaN 1554.438787 NaN 304.686083 283.255853 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 297.266891 250.309017 48.054798 NaN NaN NaN NaN NaN NaN ... 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 4 ElegantMink 685480647 allogroom 4981 5122 -0.873986 -0.869800 4546.347442 2999.584009 NaN 571.022773 626.510685 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 509.534471 786.749329 135.371371 NaN NaN 1546.763416 NaN 288.371341 199.945227 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 235.953803 594.827108 15.457600 NaN NaN NaN NaN NaN NaN ... 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 <p>5 rows \u00d7 252 columns</p> In\u00a0[\u00a0]: Copied! <pre>global METADATA_FEATURE_COLUMNS, SEGMENT_TRACKING_FEATURE_COLUMNS\nannotations_model_df = annotations_with_features.copy()\nannotations_model_df['action_id'] = annotations_model_df['action'].cat.codes\nsegment_feature_columns = SEGMENT_TRACKING_FEATURE_COLUMNS if SEGMENT_TRACKING_FEATURE_COLUMNS else [c for c in annotations_model_df.columns if c.startswith('segment_total_scaled_')]\nbase_excluded = set(['action', 'action_id', 'lab_id', 'video_id', 'start_frame_raw', 'stop_frame_raw'])\nmetadata_feature_columns = [\n    c for c in annotations_model_df.columns\n    if c not in base_excluded\n    and c not in segment_feature_columns\n    and annotations_model_df[c].dtype.kind in 'fc'\n    and not c.startswith('segment_total_raw_')\n]\nMETADATA_FEATURE_COLUMNS = metadata_feature_columns\nSEGMENT_TRACKING_FEATURE_COLUMNS = segment_feature_columns\nfeature_columns_ordered = ['start_frame', 'stop_frame'] + metadata_feature_columns + segment_feature_columns\nseen = set()\nmlp_feature_columns = [x for x in feature_columns_ordered if not (x in seen or seen.add(x))]\nannotations_model_df = annotations_model_df.drop(columns=['lab_id', 'video_id', 'start_frame_raw', 'stop_frame_raw'], errors='ignore')\nmissing_cols = [col for col in mlp_feature_columns if col not in annotations_model_df.columns]\nif missing_cols:\n    raise KeyError(f'Colunas esperadas ausentes no dataset de treino: {missing_cols}')\nif annotations_model_df[mlp_feature_columns].isna().any().any():\n    raise ValueError('Existem valores faltantes nas features utilizadas pelo MLP.')\nX_full = annotations_model_df[mlp_feature_columns].to_numpy(dtype=np.float64)\ny_full = annotations_model_df['action_id'].to_numpy(dtype=int)\naction_categories = annotations_model_df['action'].cat.categories\naction_id_to_label = {idx: label for idx, label in enumerate(action_categories)}\nnum_classes = len(action_categories)\nprint('Dimens\u00e3o do dataset para treinamento:', X_full.shape, '-&gt;', num_classes, 'classes')\nX_train, X_val, X_test, y_train, y_val, y_test = train_test_split(\n    X_full, y_full, test_size=0.15, val_size=0.15, random_state=42\n)\nprint('Split -&gt; treino:', X_train.shape[0], 'val:', X_val.shape[0], 'teste:', X_test.shape[0])\ndisplay(annotations_model_df[mlp_feature_columns].head())\n</pre> global METADATA_FEATURE_COLUMNS, SEGMENT_TRACKING_FEATURE_COLUMNS annotations_model_df = annotations_with_features.copy() annotations_model_df['action_id'] = annotations_model_df['action'].cat.codes segment_feature_columns = SEGMENT_TRACKING_FEATURE_COLUMNS if SEGMENT_TRACKING_FEATURE_COLUMNS else [c for c in annotations_model_df.columns if c.startswith('segment_total_scaled_')] base_excluded = set(['action', 'action_id', 'lab_id', 'video_id', 'start_frame_raw', 'stop_frame_raw']) metadata_feature_columns = [     c for c in annotations_model_df.columns     if c not in base_excluded     and c not in segment_feature_columns     and annotations_model_df[c].dtype.kind in 'fc'     and not c.startswith('segment_total_raw_') ] METADATA_FEATURE_COLUMNS = metadata_feature_columns SEGMENT_TRACKING_FEATURE_COLUMNS = segment_feature_columns feature_columns_ordered = ['start_frame', 'stop_frame'] + metadata_feature_columns + segment_feature_columns seen = set() mlp_feature_columns = [x for x in feature_columns_ordered if not (x in seen or seen.add(x))] annotations_model_df = annotations_model_df.drop(columns=['lab_id', 'video_id', 'start_frame_raw', 'stop_frame_raw'], errors='ignore') missing_cols = [col for col in mlp_feature_columns if col not in annotations_model_df.columns] if missing_cols:     raise KeyError(f'Colunas esperadas ausentes no dataset de treino: {missing_cols}') if annotations_model_df[mlp_feature_columns].isna().any().any():     raise ValueError('Existem valores faltantes nas features utilizadas pelo MLP.') X_full = annotations_model_df[mlp_feature_columns].to_numpy(dtype=np.float64) y_full = annotations_model_df['action_id'].to_numpy(dtype=int) action_categories = annotations_model_df['action'].cat.categories action_id_to_label = {idx: label for idx, label in enumerate(action_categories)} num_classes = len(action_categories) print('Dimens\u00e3o do dataset para treinamento:', X_full.shape, '-&gt;', num_classes, 'classes') X_train, X_val, X_test, y_train, y_val, y_test = train_test_split(     X_full, y_full, test_size=0.15, val_size=0.15, random_state=42 ) print('Split -&gt; treino:', X_train.shape[0], 'val:', X_val.shape[0], 'teste:', X_test.shape[0]) display(annotations_model_df[mlp_feature_columns].head())  <pre>Dimens\u00e3o do dataset para treinamento: (19414, 156) -&gt; 37 classes\nSplit -&gt; treino: 13590 val: 2912 teste: 2912\n</pre> start_frame stop_frame mouse1_age mouse2_age mouse3_age mouse4_age frames_per_second video_duration_sec pix_per_cm_approx video_width_pix video_height_pix arena_width_cm arena_height_cm mouse1_strain_129_svevtac mouse1_strain_btbr mouse1_strain_c57bl_6j mouse1_strain_c57bl_6j_x_ai148 mouse1_strain_c57bl_6n mouse1_strain_cd_1__icr mouse1_strain_cd1 mouse1_strain_cfw mouse1_color_black mouse1_color_black_and_tan mouse1_color_brown mouse1_color_white mouse1_sex_female mouse1_sex_male mouse2_strain_129_svevtac mouse2_strain_balb_c mouse2_strain_btbr mouse2_strain_c57bl_6j mouse2_strain_c57bl_6n mouse2_strain_cd_1__icr mouse2_strain_cd1 mouse2_strain_cfw mouse2_color_black mouse2_color_black_and_tan mouse2_color_brown mouse2_color_white mouse2_sex_female mouse2_sex_male mouse3_strain_btbr mouse3_strain_c57bl_6j mouse3_strain_cd_1__icr mouse3_color_black mouse3_color_black_and_tan mouse3_color_white mouse3_sex_male mouse4_strain_cd_1__icr mouse4_color_white ... segment_total_scaled_movement_mouse2_lateral_left segment_total_scaled_movement_mouse2_lateral_right segment_total_scaled_movement_mouse2_neck segment_total_scaled_movement_mouse2_nose segment_total_scaled_movement_mouse2_spine_1 segment_total_scaled_movement_mouse2_spine_2 segment_total_scaled_movement_mouse2_tail_base segment_total_scaled_movement_mouse2_tail_middle_1 segment_total_scaled_movement_mouse2_tail_middle_2 segment_total_scaled_movement_mouse2_tail_midpoint segment_total_scaled_movement_mouse2_tail_tip segment_total_scaled_movement_mouse3 segment_total_scaled_movement_mouse3_body_center segment_total_scaled_movement_mouse3_ear_left segment_total_scaled_movement_mouse3_ear_right segment_total_scaled_movement_mouse3_headpiece_bottombackleft segment_total_scaled_movement_mouse3_headpiece_bottombackright segment_total_scaled_movement_mouse3_headpiece_bottomfrontleft segment_total_scaled_movement_mouse3_headpiece_bottomfrontright segment_total_scaled_movement_mouse3_headpiece_topbackleft segment_total_scaled_movement_mouse3_headpiece_topbackright segment_total_scaled_movement_mouse3_headpiece_topfrontleft segment_total_scaled_movement_mouse3_headpiece_topfrontright segment_total_scaled_movement_mouse3_lateral_left segment_total_scaled_movement_mouse3_lateral_right segment_total_scaled_movement_mouse3_neck segment_total_scaled_movement_mouse3_nose segment_total_scaled_movement_mouse3_tail_base segment_total_scaled_movement_mouse3_tail_midpoint segment_total_scaled_movement_mouse3_tail_tip segment_total_scaled_movement_mouse4 segment_total_scaled_movement_mouse4_body_center segment_total_scaled_movement_mouse4_ear_left segment_total_scaled_movement_mouse4_ear_right segment_total_scaled_movement_mouse4_headpiece_bottombackleft segment_total_scaled_movement_mouse4_headpiece_bottombackright segment_total_scaled_movement_mouse4_headpiece_bottomfrontleft segment_total_scaled_movement_mouse4_headpiece_bottomfrontright segment_total_scaled_movement_mouse4_headpiece_topbackleft segment_total_scaled_movement_mouse4_headpiece_topbackright segment_total_scaled_movement_mouse4_headpiece_topfrontleft segment_total_scaled_movement_mouse4_headpiece_topfrontright segment_total_scaled_movement_mouse4_lateral_left segment_total_scaled_movement_mouse4_lateral_right segment_total_scaled_movement_mouse4_neck segment_total_scaled_movement_mouse4_nose segment_total_scaled_movement_mouse4_tail_base segment_total_scaled_movement_mouse4_tail_midpoint segment_total_scaled_movement_mouse4_tail_tip segment_total_scaled_movement_overall 0 0.492141 0.496635 -0.553824 -0.278499 0.99572 0.0 -0.63643 -0.819250 -0.573109 -0.519451 -0.692803 -0.621622 -0.814815 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 ... -0.980949 -0.980968 -0.937309 -0.968846 -0.933752 -0.93327 -0.964322 -0.930019 -0.946102 -0.940143 -0.986003 -0.87719 -0.822183 -0.896376 -0.869865 -0.833133 -0.739612 -0.777605 -0.754131 -0.735291 -0.745586 -0.788591 -0.747842 -0.886626 -0.944329 -0.922447 -0.970571 -0.935139 -0.965867 -0.954037 -0.925535 -0.977967 -0.900108 -0.930113 -0.886354 -0.841561 -0.879851 -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.970109 1 0.507958 0.507917 -0.553824 -0.278499 0.99572 0.0 -0.63643 -0.819250 -0.573109 -0.519451 -0.692803 -0.621622 -0.814815 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 ... -0.980949 -0.980968 -0.961553 -0.983189 -0.933752 -0.93327 -0.981469 -0.930019 -0.946102 -0.940143 -0.986003 -0.87719 -0.822183 -0.896376 -0.869865 -0.833133 -0.739612 -0.777605 -0.754131 -0.735291 -0.745586 -0.788591 -0.747842 -0.886626 -0.944329 -0.922447 -0.970571 -0.935139 -0.965867 -0.954037 -0.925535 -0.977967 -0.900108 -0.930113 -0.886354 -0.841561 -0.879851 -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.981039 2 0.525004 0.523909 -0.553824 -0.278499 0.99572 0.0 -0.63643 -0.819250 -0.573109 -0.519451 -0.692803 -0.621622 -0.814815 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 ... -0.980949 -0.980968 -0.978727 -0.991972 -0.933752 -0.93327 -0.991736 -0.930019 -0.946102 -0.940143 -0.986003 -0.87719 -0.822183 -0.896376 -0.869865 -0.833133 -0.739612 -0.777605 -0.754131 -0.735291 -0.745586 -0.788591 -0.747842 -0.886626 -0.944329 -0.922447 -0.970571 -0.935139 -0.965867 -0.954037 -0.925535 -0.977967 -0.900108 -0.930113 -0.886354 -0.841561 -0.879851 -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.991241 3 -0.232844 -0.246127 -0.553824 -0.278499 0.99572 0.0 -0.63643 -0.819098 -0.552941 -0.519451 -0.692803 -0.621622 -0.814815 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 ... -0.980949 -0.980968 -0.987259 -0.995693 -0.933752 -0.93327 -0.998847 -0.930019 -0.946102 -0.940143 -0.986003 -0.87719 -0.822183 -0.896376 -0.869865 -0.833133 -0.739612 -0.777605 -0.754131 -0.735291 -0.745586 -0.788591 -0.747842 -0.886626 -0.944329 -0.922447 -0.970571 -0.935139 -0.965867 -0.954037 -0.925535 -0.977967 -0.900108 -0.930113 -0.886354 -0.841561 -0.879851 -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.992211 4 -0.873986 -0.869800 -0.553824 -0.278499 0.99572 0.0 -0.63643 -0.819240 -0.573109 -0.519451 -0.692803 -0.621622 -0.814815 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 ... -0.980949 -0.980968 -0.989887 -0.989765 -0.933752 -0.93327 -0.999629 -0.930019 -0.946102 -0.940143 -0.986003 -0.87719 -0.822183 -0.896376 -0.869865 -0.833133 -0.739612 -0.777605 -0.754131 -0.735291 -0.745586 -0.788591 -0.747842 -0.886626 -0.944329 -0.922447 -0.970571 -0.935139 -0.965867 -0.954037 -0.925535 -0.977967 -0.900108 -0.930113 -0.886354 -0.841561 -0.879851 -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.992446 <p>5 rows \u00d7 156 columns</p> In\u00a0[\u00a0]: Copied! <pre>hidden_layers = [128, 64, 32]\nmlp_action_model = train_mlp_classifier(\n    X_train, y_train,\n    hidden_layers=hidden_layers,\n    output_dim=num_classes,\n    lr=0.02,\n    max_epochs=3000,\n    batch_size=1024,\n    random_state=42,\n    l2=1e-4,\n    track_history=True,\n)\ny_train_pred = mlp_action_model.predict(X_train)\ny_test_pred = mlp_action_model.predict(X_test)\ntrain_acc = accuracy_score(y_train, y_train_pred)\ntest_acc = accuracy_score(y_test, y_test_pred)\nprint(f'Acur\u00e1cia -&gt; treino: {train_acc:.3f} | teste: {test_acc:.3f}')\nmetrics_by_class = precision_recall_f1(y_test, y_test_pred, labels=np.arange(num_classes))\nmetrics_df = (\n    pd.DataFrame(metrics_by_class).T\n    .rename_axis('action_id')\n    .reset_index()\n)\nmetrics_df['action'] = metrics_df['action_id'].map(lambda idx: action_categories[idx])\ndisplay(metrics_df[['action', 'precision', 'recall', 'f1']])\ncm = confusion_matrix_true(y_test, y_test_pred, labels=np.arange(num_classes))\ncm.index = [action_categories[idx] for idx in cm.index]\ncm.columns = [action_categories[idx] for idx in cm.columns]\ndisplay(cm)\n</pre> hidden_layers = [128, 64, 32] mlp_action_model = train_mlp_classifier(     X_train, y_train,     hidden_layers=hidden_layers,     output_dim=num_classes,     lr=0.02,     max_epochs=3000,     batch_size=1024,     random_state=42,     l2=1e-4,     track_history=True, ) y_train_pred = mlp_action_model.predict(X_train) y_test_pred = mlp_action_model.predict(X_test) train_acc = accuracy_score(y_train, y_train_pred) test_acc = accuracy_score(y_test, y_test_pred) print(f'Acur\u00e1cia -&gt; treino: {train_acc:.3f} | teste: {test_acc:.3f}') metrics_by_class = precision_recall_f1(y_test, y_test_pred, labels=np.arange(num_classes)) metrics_df = (     pd.DataFrame(metrics_by_class).T     .rename_axis('action_id')     .reset_index() ) metrics_df['action'] = metrics_df['action_id'].map(lambda idx: action_categories[idx]) display(metrics_df[['action', 'precision', 'recall', 'f1']]) cm = confusion_matrix_true(y_test, y_test_pred, labels=np.arange(num_classes)) cm.index = [action_categories[idx] for idx in cm.index] cm.columns = [action_categories[idx] for idx in cm.columns] display(cm)  <pre>Acur\u00e1cia -&gt; treino: 0.429 | teste: 0.431\n</pre> action precision recall f1 0 allogroom 0.000000 0.000000 0.000000 1 approach 0.600000 0.019481 0.037736 2 attack 0.545946 0.631250 0.585507 3 attemptmount 0.451613 0.411765 0.430769 4 avoid 0.382353 0.173333 0.238532 5 biteobject 0.000000 0.000000 0.000000 6 chase 0.476636 0.713287 0.571429 7 chaseattack 0.000000 0.000000 0.000000 8 climb 0.232114 0.895706 0.368687 9 defend 0.588608 0.577640 0.583072 10 dig 0.253731 0.359155 0.297376 11 disengage 0.370370 0.526316 0.434783 12 dominance 0.931034 1.000000 0.964286 13 dominancegroom 0.315789 0.857143 0.461538 14 dominancemount 0.333333 0.542373 0.412903 15 ejaculate 0.000000 0.000000 0.000000 16 escape 0.000000 0.000000 0.000000 17 exploreobject 0.000000 0.000000 0.000000 18 flinch 0.000000 0.000000 0.000000 19 follow 1.000000 0.185185 0.312500 20 freeze 0.500000 0.062500 0.111111 21 genitalgroom 0.000000 0.000000 0.000000 22 huddle 0.933333 0.304348 0.459016 23 intromit 0.739130 0.618182 0.673267 24 mount 0.405738 0.626582 0.492537 25 rear 0.377358 0.503145 0.431267 26 reciprocalsniff 0.687179 0.992593 0.812121 27 rest 0.714286 0.294118 0.416667 28 run 0.000000 0.000000 0.000000 29 selfgroom 0.369231 0.149068 0.212389 30 shepherd 1.000000 1.000000 1.000000 31 sniff 0.478261 0.160584 0.240437 32 sniffbody 0.429658 0.733766 0.541966 33 sniffface 0.000000 0.000000 0.000000 34 sniffgenital 0.545455 0.142857 0.226415 35 submit 0.000000 0.000000 0.000000 36 tussle 0.000000 0.000000 0.000000 allogroom approach attack attemptmount avoid biteobject chase chaseattack climb defend dig disengage dominance dominancegroom dominancemount ejaculate escape exploreobject flinch follow freeze genitalgroom huddle intromit mount rear reciprocalsniff rest run selfgroom shepherd sniff sniffbody sniffface sniffgenital submit tussle allogroom 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 approach 0 3 2 0 0 0 0 0 40 2 24 17 0 0 3 0 0 0 0 0 0 0 0 0 7 25 0 0 0 9 0 0 21 0 1 0 0 attack 0 0 101 0 0 0 31 2 7 1 2 2 4 0 4 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 4 1 0 0 0 0 attemptmount 0 0 0 14 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 5 1 0 0 0 0 0 0 12 0 0 0 0 avoid 0 1 0 0 13 0 21 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 40 0 0 0 0 0 0 0 0 0 0 0 biteobject 0 0 0 0 0 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 chase 0 0 0 0 7 0 102 0 18 4 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 4 1 0 0 0 0 6 0 0 0 0 0 chaseattack 0 0 0 0 5 0 16 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 climb 0 0 0 0 0 0 3 0 146 0 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 0 0 0 0 0 0 0 0 defend 0 0 2 0 0 0 0 0 59 93 4 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 dig 0 0 0 0 0 0 2 0 72 0 51 0 0 5 0 0 0 0 0 0 0 0 0 0 0 11 0 1 0 0 0 0 0 0 0 0 0 disengage 0 0 0 0 0 0 0 0 0 0 0 20 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 18 0 0 0 0 0 0 0 dominance 0 0 0 0 0 0 0 0 0 0 0 0 54 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 dominancegroom 0 0 0 0 0 0 0 0 0 0 1 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 dominancemount 0 0 19 0 0 0 0 0 0 0 0 0 0 0 32 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 4 0 0 ejaculate 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 escape 0 0 1 0 0 0 26 0 49 37 9 0 0 5 0 0 0 0 0 0 0 0 0 0 0 5 1 0 0 0 0 0 0 0 1 0 0 exploreobject 0 0 0 0 0 0 0 0 11 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 flinch 0 0 0 0 0 0 0 0 24 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 follow 0 0 0 0 0 0 1 0 21 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 freeze 0 0 0 0 0 0 0 0 0 15 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 genitalgroom 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 6 0 0 0 0 0 0 0 2 0 0 0 0 huddle 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 14 0 0 0 32 0 0 0 0 0 0 0 0 0 0 intromit 0 0 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 68 30 1 0 0 0 2 0 0 2 0 0 0 0 mount 0 0 15 6 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 17 99 0 0 0 0 4 0 1 7 0 3 0 0 rear 0 1 0 0 8 0 0 0 31 4 23 3 0 0 0 0 0 0 0 0 0 0 0 1 3 80 0 0 0 4 0 0 0 0 1 0 0 reciprocalsniff 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 134 0 0 0 0 0 0 0 0 0 0 rest 0 0 0 0 0 0 0 0 0 0 24 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 10 0 0 0 0 0 0 0 0 0 run 0 0 0 0 0 0 0 0 0 0 12 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0 selfgroom 0 0 0 0 0 0 1 0 69 0 29 12 0 1 0 0 0 0 0 0 0 0 0 0 6 18 0 1 0 24 0 0 0 0 0 0 0 shepherd 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 26 0 0 0 0 0 0 sniff 0 0 20 4 0 0 4 0 6 1 4 0 0 0 20 0 0 0 0 0 0 0 0 4 22 6 1 0 0 3 0 22 10 0 10 0 0 sniffbody 0 0 8 0 0 0 0 0 0 0 0 0 0 0 13 0 0 0 0 0 0 0 0 0 15 0 4 0 0 0 0 1 113 0 0 0 0 sniffface 0 0 6 0 0 0 0 0 55 0 0 0 0 0 5 0 0 0 0 0 0 0 0 0 10 0 0 0 0 0 0 1 61 0 0 0 0 sniffgenital 0 0 11 0 0 0 3 0 2 1 4 0 0 2 13 0 1 0 0 0 0 0 0 0 38 5 22 0 0 1 0 10 31 0 24 0 0 submit 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0 tussle 0 0 0 0 0 0 3 0 12 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 In\u00a0[154]: Copied! <pre>y_val_pred = mlp_action_model.predict(X_val)\nval_acc = accuracy_score(y_val, y_val_pred)\nprint(f'Acur\u00e1cia no conjunto de valida\u00e7\u00e3o: {val_acc:.3f}')\nval_metrics_by_class = precision_recall_f1(y_val, y_val_pred, labels=np.arange(num_classes))\nval_metrics_df = (\n    pd.DataFrame(val_metrics_by_class).T\n    .rename_axis('action_id')\n    .reset_index()\n)\nval_metrics_df['action'] = val_metrics_df['action_id'].map(lambda idx: action_categories[idx])\ndisplay(val_metrics_df[['action', 'precision', 'recall', 'f1']])\n</pre> y_val_pred = mlp_action_model.predict(X_val) val_acc = accuracy_score(y_val, y_val_pred) print(f'Acur\u00e1cia no conjunto de valida\u00e7\u00e3o: {val_acc:.3f}') val_metrics_by_class = precision_recall_f1(y_val, y_val_pred, labels=np.arange(num_classes)) val_metrics_df = (     pd.DataFrame(val_metrics_by_class).T     .rename_axis('action_id')     .reset_index() ) val_metrics_df['action'] = val_metrics_df['action_id'].map(lambda idx: action_categories[idx]) display(val_metrics_df[['action', 'precision', 'recall', 'f1']]) <pre>Acur\u00e1cia no conjunto de valida\u00e7\u00e3o: 0.421\n</pre> action precision recall f1 0 allogroom 0.000000 0.000000 0.000000 1 approach 0.250000 0.007042 0.013699 2 attack 0.519774 0.575000 0.545994 3 attemptmount 0.526316 0.333333 0.408163 4 avoid 0.583333 0.333333 0.424242 5 biteobject 0.000000 0.000000 0.000000 6 chase 0.560976 0.684524 0.616622 7 chaseattack 1.000000 0.100000 0.181818 8 climb 0.184862 0.920290 0.307879 9 defend 0.543750 0.564935 0.554140 10 dig 0.221591 0.291045 0.251613 11 disengage 0.465116 0.526316 0.493827 12 dominance 0.944444 1.000000 0.971429 13 dominancegroom 0.250000 0.333333 0.285714 14 dominancemount 0.202247 0.367347 0.260870 15 ejaculate 0.000000 0.000000 0.000000 16 escape 0.500000 0.007407 0.014599 17 exploreobject 0.000000 0.000000 0.000000 18 flinch 0.000000 0.000000 0.000000 19 follow 1.000000 0.150000 0.260870 20 freeze 0.000000 0.000000 0.000000 21 genitalgroom 0.000000 0.000000 0.000000 22 huddle 1.000000 0.355556 0.524590 23 intromit 0.786408 0.692308 0.736364 24 mount 0.377953 0.676056 0.484848 25 rear 0.370370 0.434783 0.400000 26 reciprocalsniff 0.748768 0.980645 0.849162 27 rest 0.666667 0.312500 0.425532 28 run 0.000000 0.000000 0.000000 29 selfgroom 0.409091 0.210938 0.278351 30 shepherd 1.000000 1.000000 1.000000 31 sniff 0.547170 0.187097 0.278846 32 sniffbody 0.386973 0.673333 0.491484 33 sniffface 0.000000 0.000000 0.000000 34 sniffgenital 0.435897 0.111111 0.177083 35 submit 0.500000 0.058824 0.105263 36 tussle 0.000000 0.000000 0.000000 In\u00a0[155]: Copied! <pre>accuracy = mlp_action_model.acc_history_\nloss = mlp_action_model.loss_history_\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\nax[0].plot(range(1, len(loss) + 1), loss, label='Loss', color='blue')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\nax[0].set_title('Training Loss over Epochs')\nax[0].grid(True)\nax[0].legend()\nax[1].plot(range(1, len(accuracy) + 1), accuracy, label='Accuracy', color='green')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Accuracy')\nax[1].set_title('Training Accuracy over Epochs')\nax[1].grid(True)\nax[1].legend()\nplt.tight_layout()\nplt.show()\n</pre> accuracy = mlp_action_model.acc_history_ loss = mlp_action_model.loss_history_  fig, ax = plt.subplots(1, 2, figsize=(12, 4)) ax[0].plot(range(1, len(loss) + 1), loss, label='Loss', color='blue') ax[0].set_xlabel('Epoch') ax[0].set_ylabel('Loss') ax[0].set_title('Training Loss over Epochs') ax[0].grid(True) ax[0].legend() ax[1].plot(range(1, len(accuracy) + 1), accuracy, label='Accuracy', color='green') ax[1].set_xlabel('Epoch') ax[1].set_ylabel('Accuracy') ax[1].set_title('Training Accuracy over Epochs') ax[1].grid(True) ax[1].legend() plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre>agent_target_cols = annotations_raw[['lab_id', 'video_id', 'agent_id', 'target_id', 'start_frame', 'stop_frame']].rename(\n    columns={'start_frame': 'start_frame_raw', 'stop_frame': 'stop_frame_raw'}\n)\nannotations_pairs_processed = annotations_processed.merge(\n    agent_target_cols,\n    on=['lab_id', 'video_id', 'start_frame_raw', 'stop_frame_raw'],\n    how='left'\n)\nannotations_pairs_processed['agent_id'] = annotations_pairs_processed['agent_id'].astype('Int64')\nannotations_pairs_processed['target_id'] = annotations_pairs_processed['target_id'].astype('Int64')\nmissing_mask = annotations_pairs_processed['agent_id'].isna() | annotations_pairs_processed['target_id'].isna()\nagent_str = annotations_pairs_processed['agent_id'].fillna(-1).astype(int).astype(str)\ntarget_str = annotations_pairs_processed['target_id'].fillna(-1).astype(int).astype(str)\nannotations_pairs_processed['agent_and_target'] = agent_str + target_str\nannotations_pairs_processed.loc[missing_mask, 'agent_and_target'] = 'missing'\nannotations_pairs_processed['agent_and_target'] = annotations_pairs_processed['agent_and_target'].astype('category')\nordered_cols_pairs = [\n    'lab_id',\n    'video_id',\n    'agent_id',\n    'target_id',\n    'agent_and_target',\n    'action',\n    'start_frame_raw',\n    'stop_frame_raw',\n    'start_frame',\n    'stop_frame'\n]\nremaining_pairs = [c for c in annotations_pairs_processed.columns if c not in ordered_cols_pairs]\nannotations_pairs_processed = annotations_pairs_processed[ordered_cols_pairs + remaining_pairs]\nprint('Anota\u00e7\u00f5es com agent_and_target:', annotations_pairs_processed.shape)\ndisplay(annotations_pairs_processed.head())\n</pre> agent_target_cols = annotations_raw[['lab_id', 'video_id', 'agent_id', 'target_id', 'start_frame', 'stop_frame']].rename(     columns={'start_frame': 'start_frame_raw', 'stop_frame': 'stop_frame_raw'} ) annotations_pairs_processed = annotations_processed.merge(     agent_target_cols,     on=['lab_id', 'video_id', 'start_frame_raw', 'stop_frame_raw'],     how='left' ) annotations_pairs_processed['agent_id'] = annotations_pairs_processed['agent_id'].astype('Int64') annotations_pairs_processed['target_id'] = annotations_pairs_processed['target_id'].astype('Int64') missing_mask = annotations_pairs_processed['agent_id'].isna() | annotations_pairs_processed['target_id'].isna() agent_str = annotations_pairs_processed['agent_id'].fillna(-1).astype(int).astype(str) target_str = annotations_pairs_processed['target_id'].fillna(-1).astype(int).astype(str) annotations_pairs_processed['agent_and_target'] = agent_str + target_str annotations_pairs_processed.loc[missing_mask, 'agent_and_target'] = 'missing' annotations_pairs_processed['agent_and_target'] = annotations_pairs_processed['agent_and_target'].astype('category') ordered_cols_pairs = [     'lab_id',     'video_id',     'agent_id',     'target_id',     'agent_and_target',     'action',     'start_frame_raw',     'stop_frame_raw',     'start_frame',     'stop_frame' ] remaining_pairs = [c for c in annotations_pairs_processed.columns if c not in ordered_cols_pairs] annotations_pairs_processed = annotations_pairs_processed[ordered_cols_pairs + remaining_pairs] print('Anota\u00e7\u00f5es com agent_and_target:', annotations_pairs_processed.shape) display(annotations_pairs_processed.head())  <pre>Anota\u00e7\u00f5es com agent_and_target: (20778, 192)\n</pre> lab_id video_id agent_id target_id agent_and_target action start_frame_raw stop_frame_raw start_frame stop_frame segment_total_raw_movement_overall segment_total_raw_movement_mouse1 segment_total_raw_movement_mouse1_body_center segment_total_raw_movement_mouse1_ear_left segment_total_raw_movement_mouse1_ear_right segment_total_raw_movement_mouse1_headpiece_bottombackleft segment_total_raw_movement_mouse1_headpiece_bottombackright segment_total_raw_movement_mouse1_headpiece_bottomfrontleft segment_total_raw_movement_mouse1_headpiece_bottomfrontright segment_total_raw_movement_mouse1_headpiece_topbackleft segment_total_raw_movement_mouse1_headpiece_topbackright segment_total_raw_movement_mouse1_headpiece_topfrontleft segment_total_raw_movement_mouse1_headpiece_topfrontright segment_total_raw_movement_mouse1_lateral_left segment_total_raw_movement_mouse1_lateral_right segment_total_raw_movement_mouse1_neck segment_total_raw_movement_mouse1_nose segment_total_raw_movement_mouse1_tail_base segment_total_raw_movement_mouse1_tail_midpoint segment_total_raw_movement_mouse1_tail_tip segment_total_raw_movement_mouse2 segment_total_raw_movement_mouse2_body_center segment_total_raw_movement_mouse2_ear_left segment_total_raw_movement_mouse2_ear_right segment_total_raw_movement_mouse2_headpiece_bottombackleft segment_total_raw_movement_mouse2_headpiece_bottombackright segment_total_raw_movement_mouse2_headpiece_bottomfrontleft segment_total_raw_movement_mouse2_headpiece_bottomfrontright segment_total_raw_movement_mouse2_headpiece_topbackleft segment_total_raw_movement_mouse2_headpiece_topbackright segment_total_raw_movement_mouse2_headpiece_topfrontleft segment_total_raw_movement_mouse2_headpiece_topfrontright segment_total_raw_movement_mouse2_lateral_left segment_total_raw_movement_mouse2_lateral_right segment_total_raw_movement_mouse2_neck segment_total_raw_movement_mouse2_nose segment_total_raw_movement_mouse2_tail_base segment_total_raw_movement_mouse2_tail_midpoint segment_total_raw_movement_mouse2_tail_tip segment_total_raw_movement_mouse3 ... segment_total_scaled_movement_mouse2_lateral_left segment_total_scaled_movement_mouse2_lateral_right segment_total_scaled_movement_mouse2_neck segment_total_scaled_movement_mouse2_nose segment_total_scaled_movement_mouse2_spine_1 segment_total_scaled_movement_mouse2_spine_2 segment_total_scaled_movement_mouse2_tail_base segment_total_scaled_movement_mouse2_tail_middle_1 segment_total_scaled_movement_mouse2_tail_middle_2 segment_total_scaled_movement_mouse2_tail_midpoint segment_total_scaled_movement_mouse2_tail_tip segment_total_scaled_movement_mouse3 segment_total_scaled_movement_mouse3_body_center segment_total_scaled_movement_mouse3_ear_left segment_total_scaled_movement_mouse3_ear_right segment_total_scaled_movement_mouse3_headpiece_bottombackleft segment_total_scaled_movement_mouse3_headpiece_bottombackright segment_total_scaled_movement_mouse3_headpiece_bottomfrontleft segment_total_scaled_movement_mouse3_headpiece_bottomfrontright segment_total_scaled_movement_mouse3_headpiece_topbackleft segment_total_scaled_movement_mouse3_headpiece_topbackright segment_total_scaled_movement_mouse3_headpiece_topfrontleft segment_total_scaled_movement_mouse3_headpiece_topfrontright segment_total_scaled_movement_mouse3_lateral_left segment_total_scaled_movement_mouse3_lateral_right segment_total_scaled_movement_mouse3_neck segment_total_scaled_movement_mouse3_nose segment_total_scaled_movement_mouse3_tail_base segment_total_scaled_movement_mouse3_tail_midpoint segment_total_scaled_movement_mouse3_tail_tip segment_total_scaled_movement_mouse4 segment_total_scaled_movement_mouse4_body_center segment_total_scaled_movement_mouse4_ear_left segment_total_scaled_movement_mouse4_ear_right segment_total_scaled_movement_mouse4_headpiece_bottombackleft segment_total_scaled_movement_mouse4_headpiece_bottombackright segment_total_scaled_movement_mouse4_headpiece_bottomfrontleft segment_total_scaled_movement_mouse4_headpiece_bottomfrontright segment_total_scaled_movement_mouse4_headpiece_topbackleft segment_total_scaled_movement_mouse4_headpiece_topbackright segment_total_scaled_movement_mouse4_headpiece_topfrontleft segment_total_scaled_movement_mouse4_headpiece_topfrontright segment_total_scaled_movement_mouse4_lateral_left segment_total_scaled_movement_mouse4_lateral_right segment_total_scaled_movement_mouse4_neck segment_total_scaled_movement_mouse4_nose segment_total_scaled_movement_mouse4_tail_base segment_total_scaled_movement_mouse4_tail_midpoint segment_total_scaled_movement_mouse4_tail_tip segment_total_scaled_movement_overall 0 ElegantMink 535058450 1 2 12 allogroom 39645 39852 0.492141 0.496635 17989.650651 7370.210125 NaN 933.979944 1080.127658 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 1052.058897 889.825497 1100.308806 NaN NaN 10619.440380 NaN 1497.375330 1587.650563 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 1462.700957 1810.613754 1486.437784 NaN NaN NaN ... -0.980949 -0.980968 -0.937309 -0.968846 -0.933752 -0.93327 -0.964322 -0.930019 -0.946102 -0.940143 -0.986003 -0.87719 -0.822183 -0.896376 -0.869865 -0.833133 -0.739612 -0.777605 -0.754131 -0.735291 -0.745586 -0.788591 -0.747842 -0.886626 -0.944329 -0.922447 -0.970571 -0.935139 -0.965867 -0.954037 -0.925535 -0.977967 -0.900108 -0.930113 -0.886354 -0.841561 -0.879851 -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.970109 1 ElegantMink 535058450 1 2 12 allogroom 40044 40137 0.507958 0.507917 11411.508750 5389.880918 NaN 737.050532 659.327455 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 693.275211 694.950474 955.956143 NaN NaN 6021.627804 NaN 965.482169 860.706306 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 897.032907 976.991296 772.056954 NaN NaN NaN ... -0.980949 -0.980968 -0.961553 -0.983189 -0.933752 -0.93327 -0.981469 -0.930019 -0.946102 -0.940143 -0.986003 -0.87719 -0.822183 -0.896376 -0.869865 -0.833133 -0.739612 -0.777605 -0.754131 -0.735291 -0.745586 -0.788591 -0.747842 -0.886626 -0.944329 -0.922447 -0.970571 -0.935139 -0.965867 -0.954037 -0.925535 -0.977967 -0.900108 -0.930113 -0.886354 -0.841561 -0.879851 -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.981039 2 ElegantMink 535058450 1 2 12 allogroom 40474 40541 0.525004 0.523909 5271.261001 2200.580619 NaN 287.479137 282.458786 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 281.458461 288.532276 354.006872 NaN NaN 3070.680404 NaN 497.500983 527.033573 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 496.341674 466.570213 344.315980 NaN NaN NaN ... -0.980949 -0.980968 -0.978727 -0.991972 -0.933752 -0.93327 -0.991736 -0.930019 -0.946102 -0.940143 -0.986003 -0.87719 -0.822183 -0.896376 -0.869865 -0.833133 -0.739612 -0.777605 -0.754131 -0.735291 -0.745586 -0.788591 -0.747842 -0.886626 -0.944329 -0.922447 -0.970571 -0.935139 -0.965867 -0.954037 -0.925535 -0.977967 -0.900108 -0.930113 -0.886354 -0.841561 -0.879851 -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.991241 3 ElegantMink 551378303 1 2 12 allogroom 17285 17359 -0.232844 -0.246127 4687.871861 3133.433072 NaN 461.869503 474.547071 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 452.422745 371.549803 464.871006 NaN NaN 1554.438787 NaN 304.686083 283.255853 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 297.266891 250.309017 48.054798 NaN NaN NaN ... -0.980949 -0.980968 -0.987259 -0.995693 -0.933752 -0.93327 -0.998847 -0.930019 -0.946102 -0.940143 -0.986003 -0.87719 -0.822183 -0.896376 -0.869865 -0.833133 -0.739612 -0.777605 -0.754131 -0.735291 -0.745586 -0.788591 -0.747842 -0.886626 -0.944329 -0.922447 -0.970571 -0.935139 -0.965867 -0.954037 -0.925535 -0.977967 -0.900108 -0.930113 -0.886354 -0.841561 -0.879851 -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.992211 4 ElegantMink 685480647 1 2 12 allogroom 4981 5122 -0.873986 -0.869800 4546.347442 2999.584009 NaN 571.022773 626.510685 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 509.534471 786.749329 135.371371 NaN NaN 1546.763416 NaN 288.371341 199.945227 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 235.953803 594.827108 15.457600 NaN NaN NaN ... -0.980949 -0.980968 -0.989887 -0.989765 -0.933752 -0.93327 -0.999629 -0.930019 -0.946102 -0.940143 -0.986003 -0.87719 -0.822183 -0.896376 -0.869865 -0.833133 -0.739612 -0.777605 -0.754131 -0.735291 -0.745586 -0.788591 -0.747842 -0.886626 -0.944329 -0.922447 -0.970571 -0.935139 -0.965867 -0.954037 -0.925535 -0.977967 -0.900108 -0.930113 -0.886354 -0.841561 -0.879851 -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.992446 <p>5 rows \u00d7 192 columns</p> In\u00a0[\u00a0]: Copied! <pre>annotations_pairs_with_features = annotations_pairs_processed.merge(\n    train_processed,\n    on=['lab_id', 'video_id'],\n    how='left',\n    validate='many_to_one'\n)\nfeature_columns_pairs = [c for c in train_processed.columns if c not in ['lab_id', 'video_id']]\nmissing_pairs = annotations_pairs_with_features[feature_columns_pairs].isna().any(axis=1).sum() if feature_columns_pairs else 0\nif missing_pairs:\n    print(f'Aviso: {missing_pairs} linhas est\u00e3o sem alguma feature de tracking.')\nelse:\n    print('Todas as linhas possuem features de tracking ap\u00f3s o merge.')\naction_one_hot = pd.get_dummies(annotations_pairs_with_features['action'], prefix='action')\naction_feature_columns = action_one_hot.columns.tolist()\nannotations_pairs_with_features = pd.concat([annotations_pairs_with_features, action_one_hot], axis=1)\nprint('Shape do dataset com one-hot de action:', annotations_pairs_with_features.shape)\ndisplay(annotations_pairs_with_features.head())\n</pre> annotations_pairs_with_features = annotations_pairs_processed.merge(     train_processed,     on=['lab_id', 'video_id'],     how='left',     validate='many_to_one' ) feature_columns_pairs = [c for c in train_processed.columns if c not in ['lab_id', 'video_id']] missing_pairs = annotations_pairs_with_features[feature_columns_pairs].isna().any(axis=1).sum() if feature_columns_pairs else 0 if missing_pairs:     print(f'Aviso: {missing_pairs} linhas est\u00e3o sem alguma feature de tracking.') else:     print('Todas as linhas possuem features de tracking ap\u00f3s o merge.') action_one_hot = pd.get_dummies(annotations_pairs_with_features['action'], prefix='action') action_feature_columns = action_one_hot.columns.tolist() annotations_pairs_with_features = pd.concat([annotations_pairs_with_features, action_one_hot], axis=1) print('Shape do dataset com one-hot de action:', annotations_pairs_with_features.shape) display(annotations_pairs_with_features.head())  <pre>Todas as linhas possuem features de tracking ap\u00f3s o merge.\nShape do dataset com one-hot de action: (20778, 292)\n</pre> lab_id video_id agent_id target_id agent_and_target action start_frame_raw stop_frame_raw start_frame stop_frame segment_total_raw_movement_overall segment_total_raw_movement_mouse1 segment_total_raw_movement_mouse1_body_center segment_total_raw_movement_mouse1_ear_left segment_total_raw_movement_mouse1_ear_right segment_total_raw_movement_mouse1_headpiece_bottombackleft segment_total_raw_movement_mouse1_headpiece_bottombackright segment_total_raw_movement_mouse1_headpiece_bottomfrontleft segment_total_raw_movement_mouse1_headpiece_bottomfrontright segment_total_raw_movement_mouse1_headpiece_topbackleft segment_total_raw_movement_mouse1_headpiece_topbackright segment_total_raw_movement_mouse1_headpiece_topfrontleft segment_total_raw_movement_mouse1_headpiece_topfrontright segment_total_raw_movement_mouse1_lateral_left segment_total_raw_movement_mouse1_lateral_right segment_total_raw_movement_mouse1_neck segment_total_raw_movement_mouse1_nose segment_total_raw_movement_mouse1_tail_base segment_total_raw_movement_mouse1_tail_midpoint segment_total_raw_movement_mouse1_tail_tip segment_total_raw_movement_mouse2 segment_total_raw_movement_mouse2_body_center segment_total_raw_movement_mouse2_ear_left segment_total_raw_movement_mouse2_ear_right segment_total_raw_movement_mouse2_headpiece_bottombackleft segment_total_raw_movement_mouse2_headpiece_bottombackright segment_total_raw_movement_mouse2_headpiece_bottomfrontleft segment_total_raw_movement_mouse2_headpiece_bottomfrontright segment_total_raw_movement_mouse2_headpiece_topbackleft segment_total_raw_movement_mouse2_headpiece_topbackright segment_total_raw_movement_mouse2_headpiece_topfrontleft segment_total_raw_movement_mouse2_headpiece_topfrontright segment_total_raw_movement_mouse2_lateral_left segment_total_raw_movement_mouse2_lateral_right segment_total_raw_movement_mouse2_neck segment_total_raw_movement_mouse2_nose segment_total_raw_movement_mouse2_tail_base segment_total_raw_movement_mouse2_tail_midpoint segment_total_raw_movement_mouse2_tail_tip segment_total_raw_movement_mouse3 ... arena_shape_circular arena_shape_rectangular arena_shape_split_rectangluar arena_shape_square arena_type_csds arena_type_divided_territories arena_type_familiar arena_type_neutral arena_type_resident_intruder tracking_method_deeplabcut tracking_method_mars tracking_method_sleap tracking_method_custom_hrnet action_allogroom action_approach action_attack action_attemptmount action_avoid action_biteobject action_chase action_chaseattack action_climb action_defend action_dig action_disengage action_dominance action_dominancegroom action_dominancemount action_ejaculate action_escape action_exploreobject action_flinch action_follow action_freeze action_genitalgroom action_huddle action_intromit action_mount action_rear action_reciprocalsniff action_rest action_run action_selfgroom action_shepherd action_sniff action_sniffbody action_sniffface action_sniffgenital action_submit action_tussle 0 ElegantMink 535058450 1 2 12 allogroom 39645 39852 0.492141 0.496635 17989.650651 7370.210125 NaN 933.979944 1080.127658 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 1052.058897 889.825497 1100.308806 NaN NaN 10619.440380 NaN 1497.375330 1587.650563 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 1462.700957 1810.613754 1486.437784 NaN NaN NaN ... 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False 1 ElegantMink 535058450 1 2 12 allogroom 40044 40137 0.507958 0.507917 11411.508750 5389.880918 NaN 737.050532 659.327455 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 693.275211 694.950474 955.956143 NaN NaN 6021.627804 NaN 965.482169 860.706306 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 897.032907 976.991296 772.056954 NaN NaN NaN ... 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False 2 ElegantMink 535058450 1 2 12 allogroom 40474 40541 0.525004 0.523909 5271.261001 2200.580619 NaN 287.479137 282.458786 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 281.458461 288.532276 354.006872 NaN NaN 3070.680404 NaN 497.500983 527.033573 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 496.341674 466.570213 344.315980 NaN NaN NaN ... 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False 3 ElegantMink 551378303 1 2 12 allogroom 17285 17359 -0.232844 -0.246127 4687.871861 3133.433072 NaN 461.869503 474.547071 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 452.422745 371.549803 464.871006 NaN NaN 1554.438787 NaN 304.686083 283.255853 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 297.266891 250.309017 48.054798 NaN NaN NaN ... 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False 4 ElegantMink 685480647 1 2 12 allogroom 4981 5122 -0.873986 -0.869800 4546.347442 2999.584009 NaN 571.022773 626.510685 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 509.534471 786.749329 135.371371 NaN NaN 1546.763416 NaN 288.371341 199.945227 NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN 235.953803 594.827108 15.457600 NaN NaN NaN ... 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False <p>5 rows \u00d7 292 columns</p> In\u00a0[\u00a0]: Copied! <pre>annotations_agent_target_model_df = annotations_pairs_with_features.copy()\nannotations_agent_target_model_df['agent_and_target'] = annotations_agent_target_model_df['agent_and_target'].astype('category')\nannotations_agent_target_model_df['agent_target_id'] = annotations_agent_target_model_df['agent_and_target'].cat.codes\nsegment_feature_columns = SEGMENT_TRACKING_FEATURE_COLUMNS if SEGMENT_TRACKING_FEATURE_COLUMNS else [c for c in annotations_agent_target_model_df.columns if c.startswith('segment_total_scaled_')]\nmetadata_feature_columns = METADATA_FEATURE_COLUMNS if METADATA_FEATURE_COLUMNS else [\n    c for c in annotations_agent_target_model_df.columns\n    if c not in ['agent_and_target', 'agent_target_id', 'action', 'lab_id', 'video_id', 'start_frame_raw', 'stop_frame_raw']\n    and not c.startswith('segment_total_scaled_')\n    and not c.startswith('segment_total_raw_')\n    and not c.startswith('action_')\n    and annotations_agent_target_model_df[c].dtype.kind in 'fc'\n]\naction_feature_columns = [c for c in annotations_agent_target_model_df.columns if c.startswith('action_')]\nfeature_columns_ordered = ['start_frame', 'stop_frame'] + metadata_feature_columns + segment_feature_columns + action_feature_columns\nseen = set()\nmlp_pair_feature_columns = [x for x in feature_columns_ordered if x not in ['agent_id', 'target_id'] and not (x in seen or seen.add(x))]\nannotations_agent_target_model_df = annotations_agent_target_model_df.drop(columns=['lab_id', 'video_id', 'start_frame_raw', 'stop_frame_raw'], errors='ignore')\nmissing_cols = [col for col in mlp_pair_feature_columns if col not in annotations_agent_target_model_df.columns]\nif missing_cols:\n    raise KeyError(f'Colunas esperadas ausentes para o modelo agent_and_target: {missing_cols}')\nif annotations_agent_target_model_df[mlp_pair_feature_columns].isna().any().any():\n    raise ValueError('Existem valores faltantes nas features para o modelo agent_and_target.')\nX_pairs = annotations_agent_target_model_df[mlp_pair_feature_columns].to_numpy(dtype=np.float64)\ny_pairs = annotations_agent_target_model_df['agent_target_id'].to_numpy(dtype=int)\nagent_target_categories = annotations_agent_target_model_df['agent_and_target'].cat.categories\nagent_target_id_to_label = {idx: label for idx, label in enumerate(agent_target_categories)}\nnum_agent_target_classes = len(agent_target_categories)\nprint('Dataset para agent_and_target:', X_pairs.shape, '-&gt;', num_agent_target_classes, 'classes')\nX_pairs_train, X_pairs_val, X_pairs_test, y_pairs_train, y_pairs_val, y_pairs_test = train_test_split(\n    X_pairs, y_pairs, test_size=0.15, val_size=0.15, random_state=42\n)\nprint('Split -&gt; treino:', X_pairs_train.shape[0], 'val:', X_pairs_val.shape[0], 'teste:', X_pairs_test.shape[0])\ndisplay(annotations_agent_target_model_df[mlp_pair_feature_columns].head())\n</pre> annotations_agent_target_model_df = annotations_pairs_with_features.copy() annotations_agent_target_model_df['agent_and_target'] = annotations_agent_target_model_df['agent_and_target'].astype('category') annotations_agent_target_model_df['agent_target_id'] = annotations_agent_target_model_df['agent_and_target'].cat.codes segment_feature_columns = SEGMENT_TRACKING_FEATURE_COLUMNS if SEGMENT_TRACKING_FEATURE_COLUMNS else [c for c in annotations_agent_target_model_df.columns if c.startswith('segment_total_scaled_')] metadata_feature_columns = METADATA_FEATURE_COLUMNS if METADATA_FEATURE_COLUMNS else [     c for c in annotations_agent_target_model_df.columns     if c not in ['agent_and_target', 'agent_target_id', 'action', 'lab_id', 'video_id', 'start_frame_raw', 'stop_frame_raw']     and not c.startswith('segment_total_scaled_')     and not c.startswith('segment_total_raw_')     and not c.startswith('action_')     and annotations_agent_target_model_df[c].dtype.kind in 'fc' ] action_feature_columns = [c for c in annotations_agent_target_model_df.columns if c.startswith('action_')] feature_columns_ordered = ['start_frame', 'stop_frame'] + metadata_feature_columns + segment_feature_columns + action_feature_columns seen = set() mlp_pair_feature_columns = [x for x in feature_columns_ordered if x not in ['agent_id', 'target_id'] and not (x in seen or seen.add(x))] annotations_agent_target_model_df = annotations_agent_target_model_df.drop(columns=['lab_id', 'video_id', 'start_frame_raw', 'stop_frame_raw'], errors='ignore') missing_cols = [col for col in mlp_pair_feature_columns if col not in annotations_agent_target_model_df.columns] if missing_cols:     raise KeyError(f'Colunas esperadas ausentes para o modelo agent_and_target: {missing_cols}') if annotations_agent_target_model_df[mlp_pair_feature_columns].isna().any().any():     raise ValueError('Existem valores faltantes nas features para o modelo agent_and_target.') X_pairs = annotations_agent_target_model_df[mlp_pair_feature_columns].to_numpy(dtype=np.float64) y_pairs = annotations_agent_target_model_df['agent_target_id'].to_numpy(dtype=int) agent_target_categories = annotations_agent_target_model_df['agent_and_target'].cat.categories agent_target_id_to_label = {idx: label for idx, label in enumerate(agent_target_categories)} num_agent_target_classes = len(agent_target_categories) print('Dataset para agent_and_target:', X_pairs.shape, '-&gt;', num_agent_target_classes, 'classes') X_pairs_train, X_pairs_val, X_pairs_test, y_pairs_train, y_pairs_val, y_pairs_test = train_test_split(     X_pairs, y_pairs, test_size=0.15, val_size=0.15, random_state=42 ) print('Split -&gt; treino:', X_pairs_train.shape[0], 'val:', X_pairs_val.shape[0], 'teste:', X_pairs_test.shape[0]) display(annotations_agent_target_model_df[mlp_pair_feature_columns].head())  <pre>Dataset para agent_and_target: (20778, 193) -&gt; 16 classes\nSplit -&gt; treino: 14544 val: 3117 teste: 3117\n</pre> start_frame stop_frame mouse1_age mouse2_age mouse3_age mouse4_age frames_per_second video_duration_sec pix_per_cm_approx video_width_pix video_height_pix arena_width_cm arena_height_cm mouse1_strain_129_svevtac mouse1_strain_btbr mouse1_strain_c57bl_6j mouse1_strain_c57bl_6j_x_ai148 mouse1_strain_c57bl_6n mouse1_strain_cd_1__icr mouse1_strain_cd1 mouse1_strain_cfw mouse1_color_black mouse1_color_black_and_tan mouse1_color_brown mouse1_color_white mouse1_sex_female mouse1_sex_male mouse2_strain_129_svevtac mouse2_strain_balb_c mouse2_strain_btbr mouse2_strain_c57bl_6j mouse2_strain_c57bl_6n mouse2_strain_cd_1__icr mouse2_strain_cd1 mouse2_strain_cfw mouse2_color_black mouse2_color_black_and_tan mouse2_color_brown mouse2_color_white mouse2_sex_female mouse2_sex_male mouse3_strain_btbr mouse3_strain_c57bl_6j mouse3_strain_cd_1__icr mouse3_color_black mouse3_color_black_and_tan mouse3_color_white mouse3_sex_male mouse4_strain_cd_1__icr mouse4_color_white ... segment_total_scaled_movement_mouse4_headpiece_bottomfrontright segment_total_scaled_movement_mouse4_headpiece_topbackleft segment_total_scaled_movement_mouse4_headpiece_topbackright segment_total_scaled_movement_mouse4_headpiece_topfrontleft segment_total_scaled_movement_mouse4_headpiece_topfrontright segment_total_scaled_movement_mouse4_lateral_left segment_total_scaled_movement_mouse4_lateral_right segment_total_scaled_movement_mouse4_neck segment_total_scaled_movement_mouse4_nose segment_total_scaled_movement_mouse4_tail_base segment_total_scaled_movement_mouse4_tail_midpoint segment_total_scaled_movement_mouse4_tail_tip segment_total_scaled_movement_overall action_allogroom action_approach action_attack action_attemptmount action_avoid action_biteobject action_chase action_chaseattack action_climb action_defend action_dig action_disengage action_dominance action_dominancegroom action_dominancemount action_ejaculate action_escape action_exploreobject action_flinch action_follow action_freeze action_genitalgroom action_huddle action_intromit action_mount action_rear action_reciprocalsniff action_rest action_run action_selfgroom action_shepherd action_sniff action_sniffbody action_sniffface action_sniffgenital action_submit action_tussle 0 0.492141 0.496635 -0.553824 -0.278499 0.99572 0.0 -0.63643 -0.819250 -0.573109 -0.519451 -0.692803 -0.621622 -0.814815 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 ... -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.970109 True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False 1 0.507958 0.507917 -0.553824 -0.278499 0.99572 0.0 -0.63643 -0.819250 -0.573109 -0.519451 -0.692803 -0.621622 -0.814815 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 ... -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.981039 True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False 2 0.525004 0.523909 -0.553824 -0.278499 0.99572 0.0 -0.63643 -0.819250 -0.573109 -0.519451 -0.692803 -0.621622 -0.814815 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 ... -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.991241 True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False 3 -0.232844 -0.246127 -0.553824 -0.278499 0.99572 0.0 -0.63643 -0.819098 -0.552941 -0.519451 -0.692803 -0.621622 -0.814815 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 ... -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.992211 True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False 4 -0.873986 -0.869800 -0.553824 -0.278499 0.99572 0.0 -0.63643 -0.819240 -0.573109 -0.519451 -0.692803 -0.621622 -0.814815 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 1.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 1.0 1.0 1.0 ... -0.855984 -0.873709 -0.890065 -0.869137 -0.903273 -0.973761 -0.929656 -0.929868 -0.959457 -0.887129 -0.920277 -0.93454 -0.992446 True False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False False <p>5 rows \u00d7 193 columns</p> In\u00a0[159]: Copied! <pre>hidden_layers_pairs = [128, 64, 32]\nmlp_agent_target_model = train_mlp_classifier(\n    X_pairs_train, y_pairs_train,\n    hidden_layers=hidden_layers_pairs,\n    output_dim=num_agent_target_classes,\n    lr=0.02,\n    max_epochs=3000,\n    batch_size=1024,\n    random_state=42,\n    l2=1e-4,\n    track_history=True,\n)\ny_pairs_train_pred = mlp_agent_target_model.predict(X_pairs_train)\ny_pairs_test_pred = mlp_agent_target_model.predict(X_pairs_test)\ntrain_acc_pairs = accuracy_score(y_pairs_train, y_pairs_train_pred)\ntest_acc_pairs = accuracy_score(y_pairs_test, y_pairs_test_pred)\nmetrics_pairs = precision_recall_f1(y_pairs_test, y_pairs_test_pred, labels=np.arange(num_agent_target_classes))\nmetrics_pairs_df = pd.DataFrame(metrics_pairs).T.rename_axis('agent_target_id').reset_index()\nmetrics_pairs_df['agent_and_target'] = metrics_pairs_df['agent_target_id'].map(agent_target_id_to_label)\ndisplay(metrics_pairs_df[['agent_and_target', 'precision', 'recall', 'f1']])\ncm_pairs = confusion_matrix_true(y_pairs_test, y_pairs_test_pred, labels=np.arange(num_agent_target_classes))\ncm_pairs.index = [agent_target_id_to_label[idx] for idx in cm_pairs.index]\ncm_pairs.columns = [agent_target_id_to_label[idx] for idx in cm_pairs.columns]\ndisplay(cm_pairs)\n</pre> hidden_layers_pairs = [128, 64, 32] mlp_agent_target_model = train_mlp_classifier(     X_pairs_train, y_pairs_train,     hidden_layers=hidden_layers_pairs,     output_dim=num_agent_target_classes,     lr=0.02,     max_epochs=3000,     batch_size=1024,     random_state=42,     l2=1e-4,     track_history=True, ) y_pairs_train_pred = mlp_agent_target_model.predict(X_pairs_train) y_pairs_test_pred = mlp_agent_target_model.predict(X_pairs_test) train_acc_pairs = accuracy_score(y_pairs_train, y_pairs_train_pred) test_acc_pairs = accuracy_score(y_pairs_test, y_pairs_test_pred) metrics_pairs = precision_recall_f1(y_pairs_test, y_pairs_test_pred, labels=np.arange(num_agent_target_classes)) metrics_pairs_df = pd.DataFrame(metrics_pairs).T.rename_axis('agent_target_id').reset_index() metrics_pairs_df['agent_and_target'] = metrics_pairs_df['agent_target_id'].map(agent_target_id_to_label) display(metrics_pairs_df[['agent_and_target', 'precision', 'recall', 'f1']]) cm_pairs = confusion_matrix_true(y_pairs_test, y_pairs_test_pred, labels=np.arange(num_agent_target_classes)) cm_pairs.index = [agent_target_id_to_label[idx] for idx in cm_pairs.index] cm_pairs.columns = [agent_target_id_to_label[idx] for idx in cm_pairs.columns] display(cm_pairs)  agent_and_target precision recall f1 0 11 0.839080 0.373402 0.516814 1 12 0.949775 0.784035 0.858983 2 13 0.666667 0.153846 0.250000 3 14 0.148148 0.470588 0.225352 4 21 0.571118 0.897611 0.698076 5 22 0.535135 0.911043 0.674234 6 23 0.000000 0.000000 0.000000 7 24 0.333333 0.238095 0.277778 8 31 0.142857 0.076923 0.100000 9 32 0.153846 0.111111 0.129032 10 33 0.166667 0.133333 0.148148 11 34 0.000000 0.000000 0.000000 12 41 0.166667 0.068966 0.097561 13 42 0.000000 0.000000 0.000000 14 43 0.000000 0.000000 0.000000 15 44 1.000000 0.090909 0.166667 11 12 13 14 21 22 23 24 31 32 33 34 41 42 43 44 11 146 0 0 0 2 239 0 0 0 0 4 0 0 0 0 0 12 0 1267 0 2 347 0 0 0 0 0 0 0 0 0 0 0 13 0 0 2 5 2 0 1 1 0 0 0 0 2 0 0 0 14 0 4 0 8 2 0 0 0 1 0 0 0 2 0 0 0 21 1 55 0 1 526 0 1 2 0 0 0 0 0 0 0 0 22 27 0 0 0 0 297 0 0 0 0 2 0 0 0 0 0 23 0 0 0 2 14 0 0 1 0 1 0 0 0 0 0 0 24 0 0 0 2 12 0 0 5 2 0 0 0 0 0 0 0 31 0 1 0 1 5 0 2 0 1 2 0 1 0 0 0 0 32 0 2 0 3 3 0 3 0 2 2 0 1 1 1 0 0 33 0 0 0 0 0 13 0 0 0 0 2 0 0 0 0 0 34 0 1 0 4 1 0 0 0 0 3 0 0 0 0 0 0 41 0 2 1 9 4 0 0 3 0 3 0 0 2 4 1 0 42 0 0 0 5 1 0 1 2 1 1 0 0 1 0 0 0 43 0 2 0 12 2 0 0 1 0 1 0 0 4 0 0 0 44 0 0 0 0 0 6 0 0 0 0 4 0 0 0 0 1 In\u00a0[167]: Copied! <pre>y_pairs_val_pred = mlp_agent_target_model.predict(X_pairs_val)\nval_acc = accuracy_score(y_pairs_val, y_pairs_val_pred)\nprint(f'Acur\u00e1cia no conjunto de valida\u00e7\u00e3o (agent_and_target): {val_acc:.3f}')\nmetrics_pairs = precision_recall_f1(y_pairs_val, y_pairs_val_pred, labels=np.arange(num_agent_target_classes))\nmetrics_pairs_df = pd.DataFrame(metrics_pairs).T.rename_axis('agent_target_id').reset_index()\nmetrics_pairs_df['agent_and_target'] = metrics_pairs_df['agent_target_id'].map(agent_target_id_to_label)\ndisplay(metrics_pairs_df[['agent_and_target', 'precision', 'recall', 'f1']])\n</pre> y_pairs_val_pred = mlp_agent_target_model.predict(X_pairs_val) val_acc = accuracy_score(y_pairs_val, y_pairs_val_pred) print(f'Acur\u00e1cia no conjunto de valida\u00e7\u00e3o (agent_and_target): {val_acc:.3f}') metrics_pairs = precision_recall_f1(y_pairs_val, y_pairs_val_pred, labels=np.arange(num_agent_target_classes)) metrics_pairs_df = pd.DataFrame(metrics_pairs).T.rename_axis('agent_target_id').reset_index() metrics_pairs_df['agent_and_target'] = metrics_pairs_df['agent_target_id'].map(agent_target_id_to_label) display(metrics_pairs_df[['agent_and_target', 'precision', 'recall', 'f1']]) <pre>Acur\u00e1cia no conjunto de valida\u00e7\u00e3o (agent_and_target): 0.740\n</pre> agent_and_target precision recall f1 0 11 0.869822 0.386842 0.535519 1 12 0.953125 0.788308 0.862917 2 13 0.000000 0.000000 0.000000 3 14 0.282609 0.590909 0.382353 4 21 0.580752 0.895904 0.704698 5 22 0.560847 0.927114 0.698901 6 23 0.000000 0.000000 0.000000 7 24 0.428571 0.400000 0.413793 8 31 0.230769 0.157895 0.187500 9 32 0.222222 0.125000 0.160000 10 33 0.181818 0.142857 0.160000 11 34 0.500000 0.111111 0.181818 12 41 0.277778 0.200000 0.232558 13 42 0.200000 0.100000 0.133333 14 43 1.000000 0.071429 0.133333 15 44 0.500000 0.083333 0.142857 In\u00a0[161]: Copied! <pre>accuracy = mlp_agent_target_model.acc_history_\nloss = mlp_agent_target_model.loss_history_\n\nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\nax[0].plot(range(1, len(loss) + 1), loss, label='Loss', color='blue')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\nax[0].set_title('Training Loss over Epochs')\nax[0].grid(True)\nax[0].legend()\nax[1].plot(range(1, len(accuracy) + 1), accuracy, label='Accuracy', color='green')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Accuracy')\nax[1].set_title('Training Accuracy over Epochs')\nax[1].grid(True)\nax[1].legend()\nplt.tight_layout()\nplt.show()\n</pre> accuracy = mlp_agent_target_model.acc_history_ loss = mlp_agent_target_model.loss_history_  fig, ax = plt.subplots(1, 2, figsize=(12, 4)) ax[0].plot(range(1, len(loss) + 1), loss, label='Loss', color='blue') ax[0].set_xlabel('Epoch') ax[0].set_ylabel('Loss') ax[0].set_title('Training Loss over Epochs') ax[0].grid(True) ax[0].legend() ax[1].plot(range(1, len(accuracy) + 1), accuracy, label='Accuracy', color='green') ax[1].set_xlabel('Epoch') ax[1].set_ylabel('Accuracy') ax[1].set_title('Training Accuracy over Epochs') ax[1].grid(True) ax[1].legend() plt.tight_layout() plt.show() In\u00a0[162]: Copied! <pre>TEST_TRACKING_DIR = DATASET_DIR / 'test_tracking'\n\ntest_tracking_features = preprocessor.transform(test_meta)\n\nprint('Shape das features de teste:', test_tracking_features.shape)\nmissing_after_transform = test_tracking_features.isna().any(axis=1).sum()\nif missing_after_transform:\n    print(f'Aviso: {missing_after_transform} videos com valores faltantes apos a transformacao.')\nelse:\n    print('Sem valores faltantes nas features de teste apos a transformacao.')\n</pre> TEST_TRACKING_DIR = DATASET_DIR / 'test_tracking'  test_tracking_features = preprocessor.transform(test_meta)  print('Shape das features de teste:', test_tracking_features.shape) missing_after_transform = test_tracking_features.isna().any(axis=1).sum() if missing_after_transform:     print(f'Aviso: {missing_after_transform} videos com valores faltantes apos a transformacao.') else:     print('Sem valores faltantes nas features de teste apos a transformacao.')  <pre>Shape das features de teste: (1, 65)\nSem valores faltantes nas features de teste apos a transformacao.\n</pre> In\u00a0[163]: Copied! <pre>FRAME_WINDOW = 10\n\nvideo_info_cols = ['lab_id', 'video_id', 'frames_per_second', 'video_duration_sec']\nif 'total_frames' in test_meta.columns:\n    video_info_cols.append('total_frames')\ntest_video_info = (\n    test_meta[video_info_cols]\n    .drop_duplicates(subset=['lab_id', 'video_id'])\n    .copy()\n)\n\ndef _estimate_total_frames(row):\n    total = row.get('total_frames') if 'total_frames' in row else np.nan\n    if pd.notna(total) and total &gt; 0:\n        return int(max(1, round(total)))\n    fps = row.get('frames_per_second', np.nan)\n    duration = row.get('video_duration_sec', np.nan)\n    if pd.notna(fps) and pd.notna(duration):\n        estimate = fps * duration\n        if pd.notna(estimate) and estimate &gt; 0:\n            return int(max(1, round(estimate)))\n    return 1\n\ntest_video_info['total_frames_est'] = test_video_info.apply(_estimate_total_frames, axis=1)\ntest_video_info['max_frame_idx'] = (test_video_info['total_frames_est'] - 1).clip(lower=0).astype(int)\n\nsegments = []\nfor _, row in test_video_info.iterrows():\n    lab_id = row['lab_id']\n    video_id = row['video_id']\n    max_frame = int(row['max_frame_idx'])\n    start = 0\n    stop = min(start + FRAME_WINDOW, max_frame)\n    segments.append({'lab_id': lab_id, 'video_id': video_id, 'start_frame': int(start), 'stop_frame': int(stop)})\n    start = stop + 1\n    while start &lt;= max_frame:\n        stop = min(start + FRAME_WINDOW - 1, max_frame)\n        segments.append({'lab_id': lab_id, 'video_id': video_id, 'start_frame': int(start), 'stop_frame': int(stop)})\n        start = stop + 1\n\nsubmission_segments = pd.DataFrame(segments)\nsubmission_segments['start_scaled'] = submission_segments.groupby(['lab_id', 'video_id'])['start_frame'].transform(_scale_to_minus_one_plus_one)\nsubmission_segments['stop_scaled'] = submission_segments.groupby(['lab_id', 'video_id'])['stop_frame'].transform(_scale_to_minus_one_plus_one)\n\nsegment_movement_test = compute_segment_movement_totals(\n    submission_segments,\n    TEST_TRACKING_DIR,\n    start_col='start_frame',\n    stop_col='stop_frame'\n)\nscaled_segment_test = {}\nfor col in TRACKING_MOVEMENT_COLUMNS:\n    series = segment_movement_test.get(col, pd.Series(np.nan, index=submission_segments.index, dtype=float))\n    stats = SEGMENT_MOVEMENT_STATS.get(col, {'fill': 0.0, 'min': 0.0, 'max': 0.0})\n    filled = series.fillna(stats.get('fill', 0.0))\n    scaled_segment_test[col] = min_max_scale_to_unit_interval(filled, stats.get('min', 0.0), stats.get('max', 0.0))\nscaled_segment_test_df = pd.DataFrame(scaled_segment_test, index=submission_segments.index)\nscaled_segment_test_df = scaled_segment_test_df.reindex(columns=TRACKING_MOVEMENT_COLUMNS, fill_value=0.0)\nsubmission_segments = submission_segments.join(segment_movement_test.add_prefix('segment_total_raw_'))\nsubmission_segments = submission_segments.join(scaled_segment_test_df.add_prefix('segment_total_scaled_'))\n\nsegments_with_features = submission_segments.merge(\n    test_tracking_features,\n    on=['lab_id', 'video_id'],\n    how='left',\n    validate='many_to_one',\n)\n\nsegment_feature_columns = SEGMENT_TRACKING_FEATURE_COLUMNS if SEGMENT_TRACKING_FEATURE_COLUMNS else [c for c in segments_with_features.columns if c.startswith('segment_total_scaled_')]\nmetadata_feature_columns = METADATA_FEATURE_COLUMNS if METADATA_FEATURE_COLUMNS else [\n    c for c in segments_with_features.columns\n    if c not in segment_feature_columns\n    and c not in ['lab_id', 'video_id', 'start_frame', 'stop_frame']\n    and segments_with_features[c].dtype.kind in 'fc'\n    and not c.startswith('segment_total_raw_')\n]\naction_input_df = pd.concat(\n    [\n        submission_segments[['start_scaled', 'stop_scaled']].rename(columns={'start_scaled': 'start_frame', 'stop_scaled': 'stop_frame'}),\n        segments_with_features[metadata_feature_columns],\n        segments_with_features[segment_feature_columns],\n    ],\n    axis=1,\n)\naction_input_df = action_input_df.loc[:, ~action_input_df.columns.duplicated()]\naction_input_df = action_input_df.reindex(columns=mlp_feature_columns, fill_value=0.0)\nX_action_infer = action_input_df.to_numpy(dtype=np.float64)\n\naction_pred_ids = mlp_action_model.predict(X_action_infer)\npred_actions = [action_id_to_label[int(idx)] for idx in action_pred_ids]\npred_actions_cat = pd.Categorical(pred_actions, categories=action_categories)\naction_one_hot_columns = [col for col in mlp_pair_feature_columns if col.startswith('action_')]\naction_one_hot_pred = pd.get_dummies(pred_actions_cat, prefix='action').reindex(columns=action_one_hot_columns, fill_value=0.0)\n\npair_input_df = pd.concat(\n    [\n        submission_segments[['start_scaled', 'stop_scaled']].rename(columns={'start_scaled': 'start_frame', 'stop_scaled': 'stop_frame'}),\n        segments_with_features[metadata_feature_columns],\n        segments_with_features[segment_feature_columns],\n        action_one_hot_pred,\n    ],\n    axis=1,\n)\npair_input_df = pair_input_df.loc[:, ~pair_input_df.columns.duplicated()]\npair_input_df = pair_input_df.reindex(columns=mlp_pair_feature_columns, fill_value=0.0)\nX_pair_infer = pair_input_df.to_numpy(dtype=np.float64)\n\nagent_target_pred_ids = mlp_agent_target_model.predict(X_pair_infer)\npred_agent_target_labels = [agent_target_id_to_label[int(idx)] for idx in agent_target_pred_ids]\n\nagent_ids = []\ntarget_ids = []\nfor label in pred_agent_target_labels:\n    if label in {'missing', '__missing__'}:\n        agent_ids.append('mouse0')\n        target_ids.append('mouse0')\n        continue\n    digits = [int(ch) for ch in str(label) if ch.isdigit()]\n    if len(digits) &gt;= 2:\n        agent_ids.append(f'mouse{digits[0]}')\n        target_ids.append(f'mouse{digits[1]}')\n    else:\n        agent_ids.append('mouse0')\n        target_ids.append('mouse0')\n\nsubmission_df = submission_segments[['video_id', 'start_frame', 'stop_frame']].copy()\nsubmission_df['action'] = pred_actions\nsubmission_df['agent_id'] = agent_ids\nsubmission_df['target_id'] = target_ids\n\nsubmission_df = submission_df.sort_values(['video_id', 'start_frame']).reset_index(drop=True)\nmerged_rows = []\nfor row in submission_df.itertuples(index=False):\n    if not merged_rows:\n        merged_rows.append({\n            'video_id': row.video_id,\n            'start_frame': int(row.start_frame),\n            'stop_frame': int(row.stop_frame),\n            'action': row.action,\n            'agent_id': row.agent_id,\n            'target_id': row.target_id,\n        })\n        continue\n    last = merged_rows[-1]\n    if (\n        row.video_id == last['video_id']\n        and row.action == last['action']\n        and str(row.agent_id) == str(last['agent_id'])\n        and str(row.target_id) == str(last['target_id'])\n        and int(row.start_frame) &lt;= last['stop_frame'] + 1\n    ):\n        last['stop_frame'] = max(last['stop_frame'], int(row.stop_frame))\n    else:\n        merged_rows.append({\n            'video_id': row.video_id,\n            'start_frame': int(row.start_frame),\n            'stop_frame': int(row.stop_frame),\n            'action': row.action,\n            'agent_id': row.agent_id,\n            'target_id': row.target_id,\n        })\nsubmission_df = pd.DataFrame(merged_rows)\nsubmission_df['row_id'] = np.arange(len(submission_df), dtype=int)\nsubmission_df = submission_df[['row_id', 'video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']]\n\nprint('Dataset de submissao gerado com', len(submission_df), 'linhas.')\ndisplay(submission_df.head(50))\nsubmission_df.to_csv('submission.csv', index=False)\n</pre> FRAME_WINDOW = 10  video_info_cols = ['lab_id', 'video_id', 'frames_per_second', 'video_duration_sec'] if 'total_frames' in test_meta.columns:     video_info_cols.append('total_frames') test_video_info = (     test_meta[video_info_cols]     .drop_duplicates(subset=['lab_id', 'video_id'])     .copy() )  def _estimate_total_frames(row):     total = row.get('total_frames') if 'total_frames' in row else np.nan     if pd.notna(total) and total &gt; 0:         return int(max(1, round(total)))     fps = row.get('frames_per_second', np.nan)     duration = row.get('video_duration_sec', np.nan)     if pd.notna(fps) and pd.notna(duration):         estimate = fps * duration         if pd.notna(estimate) and estimate &gt; 0:             return int(max(1, round(estimate)))     return 1  test_video_info['total_frames_est'] = test_video_info.apply(_estimate_total_frames, axis=1) test_video_info['max_frame_idx'] = (test_video_info['total_frames_est'] - 1).clip(lower=0).astype(int)  segments = [] for _, row in test_video_info.iterrows():     lab_id = row['lab_id']     video_id = row['video_id']     max_frame = int(row['max_frame_idx'])     start = 0     stop = min(start + FRAME_WINDOW, max_frame)     segments.append({'lab_id': lab_id, 'video_id': video_id, 'start_frame': int(start), 'stop_frame': int(stop)})     start = stop + 1     while start &lt;= max_frame:         stop = min(start + FRAME_WINDOW - 1, max_frame)         segments.append({'lab_id': lab_id, 'video_id': video_id, 'start_frame': int(start), 'stop_frame': int(stop)})         start = stop + 1  submission_segments = pd.DataFrame(segments) submission_segments['start_scaled'] = submission_segments.groupby(['lab_id', 'video_id'])['start_frame'].transform(_scale_to_minus_one_plus_one) submission_segments['stop_scaled'] = submission_segments.groupby(['lab_id', 'video_id'])['stop_frame'].transform(_scale_to_minus_one_plus_one)  segment_movement_test = compute_segment_movement_totals(     submission_segments,     TEST_TRACKING_DIR,     start_col='start_frame',     stop_col='stop_frame' ) scaled_segment_test = {} for col in TRACKING_MOVEMENT_COLUMNS:     series = segment_movement_test.get(col, pd.Series(np.nan, index=submission_segments.index, dtype=float))     stats = SEGMENT_MOVEMENT_STATS.get(col, {'fill': 0.0, 'min': 0.0, 'max': 0.0})     filled = series.fillna(stats.get('fill', 0.0))     scaled_segment_test[col] = min_max_scale_to_unit_interval(filled, stats.get('min', 0.0), stats.get('max', 0.0)) scaled_segment_test_df = pd.DataFrame(scaled_segment_test, index=submission_segments.index) scaled_segment_test_df = scaled_segment_test_df.reindex(columns=TRACKING_MOVEMENT_COLUMNS, fill_value=0.0) submission_segments = submission_segments.join(segment_movement_test.add_prefix('segment_total_raw_')) submission_segments = submission_segments.join(scaled_segment_test_df.add_prefix('segment_total_scaled_'))  segments_with_features = submission_segments.merge(     test_tracking_features,     on=['lab_id', 'video_id'],     how='left',     validate='many_to_one', )  segment_feature_columns = SEGMENT_TRACKING_FEATURE_COLUMNS if SEGMENT_TRACKING_FEATURE_COLUMNS else [c for c in segments_with_features.columns if c.startswith('segment_total_scaled_')] metadata_feature_columns = METADATA_FEATURE_COLUMNS if METADATA_FEATURE_COLUMNS else [     c for c in segments_with_features.columns     if c not in segment_feature_columns     and c not in ['lab_id', 'video_id', 'start_frame', 'stop_frame']     and segments_with_features[c].dtype.kind in 'fc'     and not c.startswith('segment_total_raw_') ] action_input_df = pd.concat(     [         submission_segments[['start_scaled', 'stop_scaled']].rename(columns={'start_scaled': 'start_frame', 'stop_scaled': 'stop_frame'}),         segments_with_features[metadata_feature_columns],         segments_with_features[segment_feature_columns],     ],     axis=1, ) action_input_df = action_input_df.loc[:, ~action_input_df.columns.duplicated()] action_input_df = action_input_df.reindex(columns=mlp_feature_columns, fill_value=0.0) X_action_infer = action_input_df.to_numpy(dtype=np.float64)  action_pred_ids = mlp_action_model.predict(X_action_infer) pred_actions = [action_id_to_label[int(idx)] for idx in action_pred_ids] pred_actions_cat = pd.Categorical(pred_actions, categories=action_categories) action_one_hot_columns = [col for col in mlp_pair_feature_columns if col.startswith('action_')] action_one_hot_pred = pd.get_dummies(pred_actions_cat, prefix='action').reindex(columns=action_one_hot_columns, fill_value=0.0)  pair_input_df = pd.concat(     [         submission_segments[['start_scaled', 'stop_scaled']].rename(columns={'start_scaled': 'start_frame', 'stop_scaled': 'stop_frame'}),         segments_with_features[metadata_feature_columns],         segments_with_features[segment_feature_columns],         action_one_hot_pred,     ],     axis=1, ) pair_input_df = pair_input_df.loc[:, ~pair_input_df.columns.duplicated()] pair_input_df = pair_input_df.reindex(columns=mlp_pair_feature_columns, fill_value=0.0) X_pair_infer = pair_input_df.to_numpy(dtype=np.float64)  agent_target_pred_ids = mlp_agent_target_model.predict(X_pair_infer) pred_agent_target_labels = [agent_target_id_to_label[int(idx)] for idx in agent_target_pred_ids]  agent_ids = [] target_ids = [] for label in pred_agent_target_labels:     if label in {'missing', '__missing__'}:         agent_ids.append('mouse0')         target_ids.append('mouse0')         continue     digits = [int(ch) for ch in str(label) if ch.isdigit()]     if len(digits) &gt;= 2:         agent_ids.append(f'mouse{digits[0]}')         target_ids.append(f'mouse{digits[1]}')     else:         agent_ids.append('mouse0')         target_ids.append('mouse0')  submission_df = submission_segments[['video_id', 'start_frame', 'stop_frame']].copy() submission_df['action'] = pred_actions submission_df['agent_id'] = agent_ids submission_df['target_id'] = target_ids  submission_df = submission_df.sort_values(['video_id', 'start_frame']).reset_index(drop=True) merged_rows = [] for row in submission_df.itertuples(index=False):     if not merged_rows:         merged_rows.append({             'video_id': row.video_id,             'start_frame': int(row.start_frame),             'stop_frame': int(row.stop_frame),             'action': row.action,             'agent_id': row.agent_id,             'target_id': row.target_id,         })         continue     last = merged_rows[-1]     if (         row.video_id == last['video_id']         and row.action == last['action']         and str(row.agent_id) == str(last['agent_id'])         and str(row.target_id) == str(last['target_id'])         and int(row.start_frame) &lt;= last['stop_frame'] + 1     ):         last['stop_frame'] = max(last['stop_frame'], int(row.stop_frame))     else:         merged_rows.append({             'video_id': row.video_id,             'start_frame': int(row.start_frame),             'stop_frame': int(row.stop_frame),             'action': row.action,             'agent_id': row.agent_id,             'target_id': row.target_id,         }) submission_df = pd.DataFrame(merged_rows) submission_df['row_id'] = np.arange(len(submission_df), dtype=int) submission_df = submission_df[['row_id', 'video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']]  print('Dataset de submissao gerado com', len(submission_df), 'linhas.') display(submission_df.head(50)) submission_df.to_csv('submission.csv', index=False)  <pre>Dataset de submissao gerado com 462 linhas.\n</pre> row_id video_id agent_id target_id action start_frame stop_frame 0 0 438887472 mouse2 mouse2 rear 0 920 1 1 438887472 mouse2 mouse3 approach 921 930 2 2 438887472 mouse3 mouse3 rear 931 940 3 3 438887472 mouse2 mouse2 rear 941 1180 4 4 438887472 mouse3 mouse3 rear 1181 1190 5 5 438887472 mouse2 mouse2 rear 1191 1380 6 6 438887472 mouse3 mouse3 rear 1381 1390 7 7 438887472 mouse2 mouse2 rear 1391 1460 8 8 438887472 mouse3 mouse3 rear 1461 1470 9 9 438887472 mouse2 mouse2 rear 1471 1780 10 10 438887472 mouse2 mouse3 approach 1781 1790 11 11 438887472 mouse2 mouse2 rear 1791 1890 12 12 438887472 mouse3 mouse3 rear 1891 1900 13 13 438887472 mouse2 mouse2 rear 1901 2040 14 14 438887472 mouse3 mouse3 rear 2041 2050 15 15 438887472 mouse2 mouse2 rear 2051 2420 16 16 438887472 mouse2 mouse1 approach 2421 2430 17 17 438887472 mouse2 mouse2 rear 2431 3310 18 18 438887472 mouse2 mouse3 approach 3311 3320 19 19 438887472 mouse2 mouse2 rear 3321 3380 20 20 438887472 mouse3 mouse3 rear 3381 3390 21 21 438887472 mouse2 mouse2 rear 3391 3910 22 22 438887472 mouse3 mouse3 rear 3911 3920 23 23 438887472 mouse2 mouse2 rear 3921 4100 24 24 438887472 mouse3 mouse3 rear 4101 4110 25 25 438887472 mouse2 mouse2 rear 4111 4140 26 26 438887472 mouse3 mouse3 rear 4141 4160 27 27 438887472 mouse2 mouse2 rear 4161 4210 28 28 438887472 mouse3 mouse3 rear 4211 4220 29 29 438887472 mouse2 mouse2 rear 4221 4230 30 30 438887472 mouse3 mouse3 rear 4231 4250 31 31 438887472 mouse2 mouse2 rear 4251 4300 32 32 438887472 mouse3 mouse3 rear 4301 4310 33 33 438887472 mouse2 mouse2 rear 4311 4340 34 34 438887472 mouse3 mouse3 rear 4341 4390 35 35 438887472 mouse2 mouse2 rear 4391 4430 36 36 438887472 mouse3 mouse3 rear 4431 4450 37 37 438887472 mouse2 mouse2 rear 4451 4550 38 38 438887472 mouse3 mouse3 rear 4551 4580 39 39 438887472 mouse2 mouse2 rear 4581 4610 40 40 438887472 mouse3 mouse3 rear 4611 4620 41 41 438887472 mouse2 mouse2 rear 4621 4810 42 42 438887472 mouse3 mouse3 rear 4811 4820 43 43 438887472 mouse2 mouse2 rear 4821 5180 44 44 438887472 mouse3 mouse3 rear 5181 5190 45 45 438887472 mouse2 mouse2 rear 5191 5280 46 46 438887472 mouse3 mouse3 rear 5281 5290 47 47 438887472 mouse2 mouse2 rear 5291 5380 48 48 438887472 mouse3 mouse3 rear 5381 5400 49 49 438887472 mouse2 mouse2 rear 5401 5410"},{"location":"classification/model/#introducao","title":"Introdu\u00e7\u00e3o\u00b6","text":"<p>O presente projeto tem como objetivo aplicar t\u00e9cnicas de Deep Learning para resolver um problema de classifica\u00e7\u00e3o multiclasse utilizando redes neurais artificiais. O dataset escolhido, oriundo do MABe Challenge \u2013 Social Action Recognition in Mice, cont\u00e9m informa\u00e7\u00f5es de v\u00eddeos de camundongos e respectivas anota\u00e7\u00f5es de comportamento. O foco \u00e9 prever quais a\u00e7\u00f5es foram realizadas em um v\u00eddoe espec\u00edfico, al\u00e9m de determinar o intervalo de frames e ids dos camundongos envolvidos na a\u00e7\u00e3o.</p>"},{"location":"classification/model/#grupo","title":"Grupo\u00b6","text":"<p>Caio Ortega Boa , Pedro Toledo Piza Civita, Gabriel Hermida de Melo Mendonca</p>"},{"location":"classification/model/#descricao-do-dataset-mabe-calms21-mouse-behavior-detection","title":"Descri\u00e7\u00e3o do Dataset: MABe / CalMS21 \u2014 Mouse Behavior Detection\u00b6","text":"<p>A competi\u00e7\u00e3o utilizada como fonte deste projeto \u00e9 MABe \u2014 Mouse Behavior Detection publicada no Kaggle: https://www.kaggle.com/competitions/MABe-mouse-behavior-detection/data</p> <p>A base de dados \u00e9 derivada do dataset CalMS21 (Caltech Mouse Social Interactions 2021), utilizado no desafio MABe de reconhecimento de comportamentos sociais entre camundongos.</p>"},{"location":"classification/model/#principais-caracteristicas","title":"Principais caracter\u00edsticas\u00b6","text":"Item Descri\u00e7\u00e3o Tipo de problema Classifica\u00e7\u00e3o multiclasse / frame-level behavior detection Dom\u00ednio Comportamento social de camundongos a partir de dados de pose estimada Formato dos dados Sequ\u00eancias (v\u00eddeos) compostas por frames, onde cada frame cont\u00e9m:  - Coordenadas 2D de 7 keypoints para cada um dos dois animais (residente e intruso)  - Anota\u00e7\u00f5es de comportamento (quando dispon\u00edveis) Escala / amplitude Mais de 6 milh\u00f5es de frames n\u00e3o anotados (dados de pose apenas), e mais de 1 milh\u00e3o de frames anotados para comportamentos sociais. - Considerando apenas o dataset de train, esse possui um shape de 8790, 38. Licen\u00e7a / distribui\u00e7\u00e3o O CalMS21 \u00e9 distribu\u00eddo sob Creative Commons Attribution-NonCommercial-ShareAlike (CC-BY-NC-SA)."},{"location":"classification/model/#justificativa-para-escolha-deste-dataset","title":"Justificativa para escolha deste dataset\u00b6","text":"<ul> <li>Complexidade suficiente: o dataset oferece um desafio realista, com muitas amostras e m\u00faltiplas classes, superando o m\u00ednimo exigido (\u2265 1.000 amostras e \u2265 5 features).</li> <li>Originalidade: n\u00e3o \u00e9 uma base trivial ou j\u00e1 trivialmente explorada em cursos.</li> <li>Tipo de Dados: as possibilidades de predi\u00e7\u00e3o nesse dataset fragmentado despertaram interese em sua escolha.</li> </ul>"},{"location":"classification/model/#explicacao-do-dataset","title":"Explica\u00e7\u00e3o do Dataset\u00b6","text":""},{"location":"classification/model/#dataset-base","title":"Dataset Base\u00b6","text":"<ul> <li><p>Identifica\u00e7\u00e3o</p> <ul> <li><code>lab_id</code> (categ\u00f3rica) \u2014 identificador do laborat\u00f3rio; chave para localiza\u00e7\u00e3o de anota\u00e7\u00f5es externas.</li> <li><code>video_id</code> (num\u00e9rica) \u2014 identificador \u00fanico do v\u00eddeo dentro do laborat\u00f3rio.</li> </ul> </li> <li><p>Atributos dos camundongos (at\u00e9 <code>mouse1</code>\u2013<code>mouse4</code>)</p> <ul> <li><code>mouse{n}_strain</code> (categ\u00f3rica) \u2014 linhagem declarada.</li> <li><code>mouse{n}_color</code> (categ\u00f3rica) \u2014 varia\u00e7\u00e3o de cor.</li> <li><code>mouse{n}_sex</code> (categ\u00f3rica) \u2014 sexo.</li> <li><code>mouse{n}_id</code> (num\u00e9rica) \u2014 identificador sequencial no estudo.</li> <li><code>mouse{n}_age</code> (categ\u00f3rica) \u2014 faixa et\u00e1ria aproximada.</li> <li><code>mouse{n}_condition</code> (categ\u00f3rica) \u2014 condi\u00e7\u00e3o experimental aplicada.</li> </ul> </li> <li><p>Atributos do v\u00eddeo/arena</p> <ul> <li><code>frames_per_second</code> (num\u00e9rica) \u2014 taxa de quadros.</li> <li><code>video_duration_sec</code> (num\u00e9rica) \u2014 dura\u00e7\u00e3o em segundos.</li> <li><code>pix_per_cm_approx</code> (num\u00e9rica) \u2014 aproxima\u00e7\u00e3o de pixel\u2192cent\u00edmetro.</li> <li><code>video_width_pix</code>, <code>video_height_pix</code> (num\u00e9ricas) \u2014 dimens\u00f5es em pixels.</li> <li><code>arena_width_cm</code>, <code>arena_height_cm</code> (num\u00e9ricas) \u2014 dimens\u00f5es da arena.</li> <li><code>arena_shape</code>, <code>arena_type</code> (categ\u00f3ricas) \u2014 morfologia e tipo de arena.</li> <li><code>body_parts_tracked</code>, <code>behaviors_labeled</code> (lista) \u2014 keypoints e comportamentos dispon\u00edveis.</li> <li><code>tracking_method</code> (categ\u00f3rica) \u2014 m\u00e9todo de captura de poses.</li> </ul> </li> </ul>"},{"location":"classification/model/#dataset-de-tracking-identificados-por-diretorios","title":"Dataset de Tracking (identificados por diret\u00f3rios)\u00b6","text":"<ul> <li><code>video_frame</code> - frame do v\u00eddeo em quest\u00e3o</li> <li><code>mouse_id</code> - id do rato analisado</li> <li><code>bodypart</code> - parte do corpo analisada</li> <li><code>x/y</code> - posi\u00e7\u00e3o da parte do corpo analisada</li> </ul>"},{"location":"classification/model/#dataset-de-anotacoes-identificados-por-diretorios","title":"Dataset de Anota\u00e7\u00f5es (identificados por diret\u00f3rios)\u00b6","text":"<ul> <li><code>agent_id</code> - id do rato que realiza a a\u00e7\u00e3o</li> <li><code>target_id</code> - id do rato que recebe a a\u00e7\u00e3o</li> <li><code>action</code> - a\u00e7\u00e3o realizada no intervalo definido</li> <li><code>[start/stop]_frame</code> - intervalo de frames em que ocorre a a\u00e7\u00e3o</li> </ul>"},{"location":"classification/model/#definicao-do-modelo-mlp-e-funcoes-uteis","title":"Defini\u00e7\u00e3o do Modelo MLP e Fun\u00e7\u00f5es \u00dateis\u00b6","text":"<p>Nesta etapa do projeto foi constru\u00edda a base para o modelo de classifica\u00e7\u00e3o: um Multi-Layer Perceptron (MLP) implementado do zero em Python com <code>NumPy</code>. O objetivo \u00e9 compreender todos os passos envolvidos no treinamento de uma rede neural, desde a prepara\u00e7\u00e3o dos dados at\u00e9 o c\u00e1lculo das m\u00e9tricas finais.</p>"},{"location":"classification/model/#preparacao-do-ambiente","title":"Prepara\u00e7\u00e3o do Ambiente\u00b6","text":"<p>Foram importadas bibliotecas fundamentais para an\u00e1lise e manipula\u00e7\u00e3o de dados (<code>numpy</code>, <code>pandas</code>), visualiza\u00e7\u00e3o (<code>matplotlib</code>, <code>seaborn</code>), al\u00e9m de configura\u00e7\u00f5es para melhorar a exibi\u00e7\u00e3o de tabelas no notebook.</p>"},{"location":"classification/model/#funcoes-auxiliares","title":"Fun\u00e7\u00f5es Auxiliares\u00b6","text":"<p>Para viabilizar o treinamento e avalia\u00e7\u00e3o do modelo, foram definidas fun\u00e7\u00f5es essenciais:</p> <ul> <li>Normaliza\u00e7\u00e3o dos dados: implementa\u00e7\u00e3o do escalamento de vari\u00e1veis para o intervalo [-1, 1], garantindo melhor estabilidade durante o treinamento da rede para <code>tanh</code>.</li> <li>Fun\u00e7\u00f5es de ativa\u00e7\u00e3o: <code>tanh</code> e <code>softmax</code>, al\u00e9m de suas derivadas, necess\u00e1rias para a propaga\u00e7\u00e3o direta e retropropaga\u00e7\u00e3o.</li> <li>Fun\u00e7\u00e3o de perda: Cross-Entropy Loss, apropriada para classifica\u00e7\u00e3o multiclasse, calculando o erro entre as probabilidades previstas e os r\u00f3tulos verdadeiros.</li> <li>M\u00e9tricas de avalia\u00e7\u00e3o: <code>accuracy_score</code>, <code>f1_score</code>, <code>precision</code>, <code>recall</code> e <code>confusion_matrix</code> para medir a taxa de acertos do modelo.</li> <li>Divis\u00e3o do dataset: fun\u00e7\u00e3o <code>train_test_split</code>, que embaralha os dados e separa em treino e teste, garantindo reprodutibilidade via <code>random_state</code>.</li> <li>Inicializa\u00e7\u00e3o de pesos: m\u00e9todo <code>xavier_init</code>, que favorece uma inicializa\u00e7\u00e3o de pesos para propaga\u00e7\u00e3o de gradiente mais est\u00e1vel em redes profundas.</li> <li>Codifica\u00e7\u00e3o de r\u00f3tulos: fun\u00e7\u00e3o <code>one_hot</code>, que converte classes inteiras em vetores one-hot para uso na fun\u00e7\u00e3o de perda.</li> </ul>"},{"location":"classification/model/#estrutura-do-mlp","title":"Estrutura do MLP\u00b6","text":"<p>A classe <code>MLP</code> re\u00fane todos os componentes do modelo:</p> <ul> <li>Hiperpar\u00e2metros configur\u00e1veis: dimens\u00f5es de entrada e sa\u00edda, n\u00famero e tamanho das camadas escondidas, taxa de aprendizado (<code>lr</code>), n\u00famero de \u00e9pocas, tamanho de lote (<code>batch_size</code>), regulariza\u00e7\u00e3o L2 e semente aleat\u00f3ria para reprodutibilidade.</li> <li>Inicializa\u00e7\u00e3o de par\u00e2metros: pesos e vieses s\u00e3o inicializados com o m\u00e9todo de Xavier, garantindo maior efici\u00eancia no in\u00edcio do treino.</li> <li>Forward pass: realiza a propaga\u00e7\u00e3o dos dados pelas camadas, aplicando <code>tanh</code> nas camadas escondidas e <code>softmax</code> na sa\u00edda para gerar probabilidades.</li> <li>Backward pass: implementa a retropropaga\u00e7\u00e3o do erro, atualizando gradientes para pesos e vieses, com suporte a regulariza\u00e7\u00e3o L2.</li> <li>Fun\u00e7\u00e3o de atualiza\u00e7\u00e3o: aplica descida do gradiente para refinar os par\u00e2metros a cada itera\u00e7\u00e3o.</li> <li>Treinamento (<code>fit</code>): organiza o loop de \u00e9pocas, realiza o embaralhamento dos dados, treino em mini-batches, c\u00e1lculo da fun\u00e7\u00e3o de perda e registro hist\u00f3rico de loss e accuracy.</li> <li>Predi\u00e7\u00e3o: m\u00e9todos para retornar probabilidades (<code>predict_proba</code>), scores lineares (<code>decision_function</code>) e r\u00f3tulos finais (<code>predict</code>).</li> </ul>"},{"location":"classification/model/#pre-processamento-de-features","title":"Pr\u00e9-processamento de Features\u00b6","text":"<p>Para alinhar corretamente os dados de treino e infer\u00eancia, foi criada a classe <code>MainFeaturesPreprocessor</code>. Ela garante consist\u00eancia no tratamento dos dados brutos de tracking e metadados, normalizando vari\u00e1veis num\u00e9ricas e codificando categorias.</p>"},{"location":"classification/model/#principais-funcionalidades","title":"Principais funcionalidades:\u00b6","text":"<ul> <li><p>Normaliza\u00e7\u00e3o num\u00e9rica</p> <ul> <li>C\u00e1lculo de estat\u00edsticas b\u00e1sicas (m\u00e9dia, m\u00ednimo, m\u00e1ximo) para cada coluna num\u00e9rica.</li> <li>Escalonamento para o intervalo [-1, 1], garantindo maior estabilidade ao treinamento da rede.</li> <li>Preenchimento de valores ausentes com a m\u00e9dia da coluna.</li> <li>Essa escolha foi feita porque a fun\u00e7\u00e3o de ativa\u00e7\u00e3o utilizada no MLP (<code>tanh</code>) tamb\u00e9m opera nesse mesmo intervalo, reduzindo riscos de satura\u00e7\u00e3o e acelerando a converg\u00eancia.</li> </ul> </li> <li><p>Codifica\u00e7\u00e3o categ\u00f3rica</p> <ul> <li>Identifica\u00e7\u00e3o dos n\u00edveis presentes em cada vari\u00e1vel categ\u00f3rica.</li> <li>Transforma\u00e7\u00e3o em vari\u00e1veis dummy (one-hot encoding) com nomes sanitizados, evitando problemas com espa\u00e7os ou caracteres especiais.</li> <li>Inclus\u00e3o expl\u00edcita de uma categoria <code>__missing__</code> para valores ausentes, assegurando que a aus\u00eancia seja tratada como informa\u00e7\u00e3o v\u00e1lida e n\u00e3o como erro.</li> <li>Essa decis\u00e3o evita perda de amostras e mant\u00e9m a consist\u00eancia em casos de infer\u00eancia com categorias ausentes no treino.</li> </ul> </li> <li><p>Constru\u00e7\u00e3o da matriz de features</p> <ul> <li>Montagem de um <code>DataFrame</code> consolidado com colunas-chave (<code>lab_id</code>, <code>video_id</code>), atributos num\u00e9ricos normalizados e categ\u00f3ricos codificados.</li> <li>Garantia de consist\u00eancia entre diferentes fases (treino, valida\u00e7\u00e3o e teste), mesmo quando h\u00e1 aus\u00eancia de determinadas colunas.</li> </ul> </li> <li><p>Tratamento de Colunas</p> <ul> <li>Colunas de <code>age</code> s\u00e3o tratadas separadamente atrav\u00e9s da m\u00e9dia do intervalo para serem tratadas como num\u00e9ricas.</li> <li>Colunas de <code>condition</code> removidas, por gerarem colunas excessivas em one hot e agregar pouca informa\u00e7\u00e3o.</li> <li>Colunas de <code>mouse_id</code>, <code>behaviours_labeled</code> e <code>body_parts_tracked</code> n\u00e3o utilizadas como features, pois n\u00e3o agregam informa\u00e7\u00e3o relevante, por\u00e9m s\u00e3o utilizadas na constru\u00e7\u00e3o de novas features e organiza\u00e7\u00e3o.</li> </ul> </li> <li><p>M\u00e9todos principais</p> <ul> <li><code>fit</code>: aprende estat\u00edsticas num\u00e9ricas e n\u00edveis categ\u00f3ricos a partir de um <code>DataFrame</code>.</li> <li><code>transform</code>: aplica a transforma\u00e7\u00e3o aprendida a novos dados, preservando as colunas de features.</li> <li><code>fit_transform</code>: combina\u00e7\u00e3o dos dois passos anteriores para conveni\u00eancia.</li> </ul> </li> </ul>"},{"location":"classification/model/#funcoes-auxiliares-para-treinamento","title":"Fun\u00e7\u00f5es Auxiliares para Treinamento\u00b6","text":"<ul> <li><p><code>to_numpy_array</code> Converte diferentes formatos de dados (<code>np.ndarray</code>, <code>pandas.DataFrame</code>, listas) para <code>numpy.array</code>, assegurando compatibilidade com o modelo.</p> </li> <li><p><code>train_mlp_classifier</code> Facilita o treinamento de um MLP, encapsulando a prepara\u00e7\u00e3o dos dados e a inicializa\u00e7\u00e3o do modelo. Permite especificar hiperpar\u00e2metros como n\u00famero de camadas escondidas, taxa de aprendizado, regulariza\u00e7\u00e3o L2 e tamanho de lote.</p> </li> </ul>"},{"location":"classification/model/#estrutura-de-diretorios-e-carregamento-dos-dados","title":"Estrutura de Diret\u00f3rios e Carregamento dos Dados\u00b6","text":"<p>Ao final, o c\u00f3digo define caminhos candidatos para o dataset e carrega os arquivos principais:</p> <ul> <li><code>train.csv</code>: metadados com r\u00f3tulos.</li> <li><code>test.csv</code>: metadados para submiss\u00e3o.</li> <li><code>train_tracking</code>: informa\u00e7\u00f5es frame a frame de movimentos.</li> <li><code>train_annotation</code>: anota\u00e7\u00f5es detalhadas dos v\u00eddeos.</li> </ul>"},{"location":"classification/model/#processamento-de-anotacoes-e-movimento","title":"Processamento de Anota\u00e7\u00f5es e Movimento\u00b6","text":"<p>Este m\u00f3dulo implementa o pipeline de pr\u00e9-processamento de anota\u00e7\u00f5es e c\u00e1lculo de m\u00e9tricas de movimento a partir de dados de tracking. Ele consolida informa\u00e7\u00f5es de m\u00faltiplos v\u00eddeos e laborat\u00f3rios, garante consist\u00eancia nas colunas, normaliza vari\u00e1veis de tempo (frames) e calcula features de deslocamento.</p>"},{"location":"classification/model/#load_annotation_eventsannotation_root-metadata_df-pddataframe","title":"<code>load_annotation_events(annotation_root, metadata_df) -&gt; pd.DataFrame</code>\u00b6","text":"<p>Carrega todos os arquivos <code>.parquet</code> de anota\u00e7\u00f5es presentes em <code>annotation_root</code>, conforme listados em <code>metadata_df</code>.</p> <p>Etapas:</p> <ul> <li>Procura <code>{annotation_root}/{lab_id}/{video_id}.parquet</code> para cada par (<code>lab_id</code>, <code>video_id</code>).</li> <li>Valida colunas obrigat\u00f3rias: <code>agent_id</code>, <code>target_id</code>, <code>action</code>, <code>start_frame</code>, <code>stop_frame</code>.</li> <li>Anexa colunas <code>lab_id</code> e <code>video_id</code>.</li> <li>Concatena os arquivos encontrados em um \u00fanico DataFrame.</li> </ul>"},{"location":"classification/model/#_scale_to_minus_one_plus_oneseries-pdseries","title":"<code>_scale_to_minus_one_plus_one(series) -&gt; pd.Series</code>\u00b6","text":"<p>Escalona uma s\u00e9rie num\u00e9rica para o intervalo [-1, 1].</p> <p>Comportamento:</p> <ul> <li>S\u00e9ries constantes ou nulas retornam zeros.</li> <li>Aplica min-max scaler em features num\u00e9ricas.</li> <li>Compat\u00edvel com fun\u00e7\u00f5es de ativa\u00e7\u00e3o <code>tanh</code>.</li> </ul>"},{"location":"classification/model/#preprocess_annotationsannotations_df-pddataframe","title":"<code>preprocess_annotations(annotations_df) -&gt; pd.DataFrame</code>\u00b6","text":"<p>Limpa e normaliza o conjunto de anota\u00e7\u00f5es carregado, preparando para utiliza\u00e7\u00e3o no modelo MLP.</p> <p>Etapas:</p> <ul> <li>Verifica colunas obrigat\u00f3rias.</li> <li>Remove <code>agent_id</code> e <code>target_id</code>.</li> <li>Aplica Scaler em var\u00edaveis num\u00e9ricas.</li> <li>Converte <code>action</code> para categ\u00f3rico.</li> </ul>"},{"location":"classification/model/#_load_frame_movement_featurestracking_root-lab_id-video_id-pddataframe-none","title":"<code>_load_frame_movement_features(tracking_root, lab_id, video_id) -&gt; pd.DataFrame | None</code>\u00b6","text":"<p>Calcula movimentos realizados no dataset de tracking por frame.</p> <p>Processo:</p> <ul> <li>L\u00ea <code>{tracking_root}/{lab_id}/{video_id}.parquet</code> com colunas <code>mouse_id</code>, <code>bodypart</code>, <code>video_frame</code>, <code>x</code>, <code>y</code>.</li> <li>Ordena frames e calcula deslocamentos (<code>dx</code>, <code>dy</code>).</li> <li>Calcula dist\u00e2ncias euclidianas e agrega:<ul> <li><code>movement_overall</code> \u2014 total por frame,</li> <li><code>movement_mouse{n}</code> \u2014 total por mouse,</li> <li><code>movement_mouse{n}_{junta}</code> \u2014 total por junta.</li> </ul> </li> <li>Retorna DataFrame indexado por <code>video_frame</code> com zeros onde ausente.</li> <li>Usa cache <code>_frame_movement_cache</code> para evitar reprocessamento.</li> </ul>"},{"location":"classification/model/#compute_segment_movement_totalsdf-tracking_root-start_colstart_frame_raw-stop_colstop_frame_raw-pddataframe","title":"<code>compute_segment_movement_totals(df, tracking_root, start_col='start_frame_raw', stop_col='stop_frame_raw') -&gt; pd.DataFrame</code>\u00b6","text":"<p>Soma os deslocamentos em cada segmento de frames correspondente a uma anota\u00e7\u00e3o.</p> <p>Etapas:</p> <ul> <li>Agrupa por (<code>lab_id</code>, <code>video_id</code>).</li> <li>Carrega o tracking e fatiamento <code>[start_col, stop_col]</code> por anota\u00e7\u00e3o.</li> <li>Soma valores das colunas <code>movement_*</code> dentro do intervalo.</li> <li>Retorna DataFrame alinhado ao \u00edndice original, com uma coluna por feature de movimento.</li> </ul>"},{"location":"classification/model/#analise-exploratoria","title":"An\u00e1lise Explorat\u00f3ria\u00b6","text":"<p>Nesta se\u00e7\u00e3o analisamos como se comportam os dados dos datasets utilizados, verificando balanceamento e valores faltantes, possibilitando adotar a melhor estrat\u00e9gia para otimizar o resultado do modelo.</p>"},{"location":"classification/model/#desbalanceamento","title":"Desbalanceamento\u00b6","text":"<p>A decis\u00e3o para tratar o desbalanceamento das bases foi a remo\u00e7\u00e3o aleat\u00f3ria de valores, limitando-os para um valor espec\u00edfico, uma vez que existem linhas suficientes no dataset para realiza\u00e7\u00e3o de um treino relevante mesmo com essa remo\u00e7\u00e3o. Essa decis\u00e3o foi tomada em rela\u00e7\u00e3o a duplica\u00e7\u00e3o de linhas, por exemplo, pelo tamanho da diferen\u00e7a que existia entre a quatidade de features, da feature menos expressiva a mais expressiva.</p>"},{"location":"classification/model/#valores-faltantes","title":"Valores Faltantes\u00b6","text":"<p>Algumas colunas tidas como pouco relevantes para o treino, como mouse_id e mouse_condition foram removidas e outras features que apresentavam valores faltantes expressivos tendiam a representar valores espec\u00edficos de algum dos mouses. Por acreditar que a remo\u00e7\u00e3o dessas colunas poderia prejudicar o contexto e informa\u00e7\u00f5es relevantes em casos espec\u00edficos os valores foram preenchidos pela m\u00e9dia aritm\u00e9tica da coluna.</p>"},{"location":"classification/model/#calculo-do-movimento-total-por-segmento","title":"C\u00e1lculo do Movimento Total por Segmento\u00b6","text":"<p>Esta etapa gera e integra as m\u00e9tricas de deslocamento total associadas a cada evento de anota\u00e7\u00e3o. Seu objetivo \u00e9 quantificar o movimento observado em cada segmento de frames e normalizar essas informa\u00e7\u00f5es para uso no modelo de MLP.</p>"},{"location":"classification/model/#calculo-inicial","title":"C\u00e1lculo Inicial\u00b6","text":"<p>As dist\u00e2ncias totais percorridas em cada anota\u00e7\u00e3o s\u00e3o obtidas a partir dos dados de tracking. Cada linha do conjunto de anota\u00e7\u00f5es recebe o somat\u00f3rio dos deslocamentos (<code>movement_*</code>) ocorridos entre os frames de in\u00edcio e t\u00e9rmino (<code>start_frame_raw</code> e <code>stop_frame_raw</code>). Esses valores representam o movimento absoluto dentro do intervalo correspondente \u00e0 a\u00e7\u00e3o.</p>"},{"location":"classification/model/#extracao-de-estatisticas","title":"Extra\u00e7\u00e3o de Estat\u00edsticas\u00b6","text":"<p>Ap\u00f3s o c\u00e1lculo, s\u00e3o determinadas estat\u00edsticas por feature de movimento, incluindo:</p> <ul> <li><code>fill</code>: m\u00e9dia utilizada para preencher valores ausentes;</li> <li><code>min</code> e <code>max</code>: limites observados de cada m\u00e9trica.</li> </ul> <p>Essas estat\u00edsticas s\u00e3o fundamentais para padronizar a escala dos dados e garantir comparabilidade entre v\u00eddeos e laborat\u00f3rios diferentes.</p>"},{"location":"classification/model/#escalonamento-e-integracao-das-features","title":"Escalonamento e Integra\u00e7\u00e3o das Features\u00b6","text":"<p>As m\u00e9tricas de movimento s\u00e3o normalizadas para o intervalo [-1, 1], gerando vers\u00f5es escaladas (<code>segment_total_scaled_*</code>) e mantendo as originais (<code>segment_total_raw_*</code>). As novas colunas s\u00e3o adicionadas ao conjunto de anota\u00e7\u00f5es processadas, permitindo an\u00e1lises consistentes e compar\u00e1veis entre segmentos.</p> <p>O resultado final \u00e9 um conjunto que combina:</p> <ul> <li>Identificadores de v\u00eddeo e frames;</li> <li>M\u00e9tricas de deslocamento bruto e escalado;</li> <li>Estat\u00edsticas globais por tipo de movimento.</li> </ul>"},{"location":"classification/model/#combinacao-com-dataset-geral","title":"Combina\u00e7\u00e3o com Dataset Geral\u00b6","text":"<p>O conjunto enriquecido de anota\u00e7\u00f5es \u00e9 posteriormente unido \u00e0s features globais do v\u00eddeo do v\u00eddeo correspondente. Esse processo garante que cada evento possua tanto as m\u00e9tricas locais de movimento (por segmento) quanto as estat\u00edsticas gerais do v\u00eddeo.</p>"},{"location":"classification/model/#resultado-final","title":"Resultado Final\u00b6","text":"<p>O produto final \u00e9 um dataset completo e contextualizado, no qual cada a\u00e7\u00e3o anotada cont\u00e9m:</p> <ul> <li>Informa\u00e7\u00f5es temporais precisas;</li> <li>Dist\u00e2ncias percorridas durante o evento;</li> <li>Features normalizadas de movimento;</li> <li>Dados complementares de tracking.</li> </ul>"},{"location":"classification/model/#preparacao-do-conjunto-de-treino-e-mlp","title":"Prepara\u00e7\u00e3o do Conjunto de Treino e MLP\u00b6","text":""},{"location":"classification/model/#1-preparacao-do-conjunto-de-treino","title":"1) Prepara\u00e7\u00e3o do Conjunto de Treino\u00b6","text":"<p>Cria o conjunto de dados usado para treinar o classificador MLP.</p> <p>Etapas:</p> <ul> <li>Converte a coluna <code>action</code> em c\u00f3digos num\u00e9ricos (<code>action_id</code>).</li> <li>Seleciona apenas colunas num\u00e9ricas \u00fateis:<ul> <li>Segmento: <code>segment_total_scaled_*</code></li> <li>Metadados: vari\u00e1veis num\u00e9ricas, exceto chaves e colunas brutas.</li> </ul> </li> <li>Remove colunas duplicadas e valores faltantes.</li> <li>Transforma os dados em matrizes <code>X</code> (features) e <code>y</code> (r\u00f3tulos).</li> <li>Divide o dataset em treino, valida\u00e7\u00e3o e teste com propor\u00e7\u00f5es fixas e reprodutibilidade.</li> </ul>"},{"location":"classification/model/#2-treinamento-e-avaliacao-do-mlp","title":"2) Treinamento e Avalia\u00e7\u00e3o do MLP\u00b6","text":"<p>Treina um modelo Multilayer Perceptron (MLP) para classificar a\u00e7\u00f5es com base nas features preparadas.</p> <p>Configura\u00e7\u00e3o:</p> <ul> <li>Camadas ocultas: 128 \u2192 64 \u2192 32.</li> <li>lr=0.02,</li> <li>max_epochs=3000,</li> <li>batch_size=1024,</li> <li>random_state=42,</li> <li>l2=1e-4,</li> </ul> <p>Justificativa de Par\u00e2metros</p> <ul> <li>Par\u00e2metros foram testados em fun\u00e7\u00e3o da maximiza\u00e7\u00e3o de seus resultados mantendo performance e velocidade de treino para facilitar o desenvolvimento e publica\u00e7\u00e3o do notebook no kaggle, o mesmo vale pela escolha da predi\u00e7\u00e3o em mini-batches.</li> </ul> <p>Avalia\u00e7\u00e3o:</p> <ul> <li>Mede acur\u00e1cia, precis\u00e3o, recall e F1-score por classe.</li> <li>Gera matriz de confus\u00e3o para analisar erros.</li> <li>Exibe curvas de loss e accuracy por \u00e9poca.</li> </ul>"},{"location":"classification/model/#processamento-de-anotacoes-com-agent_and_target","title":"Processamento de Anota\u00e7\u00f5es com <code>agent_and_target</code>\u00b6","text":""},{"location":"classification/model/#1-enriquecimento-das-anotacoes","title":"1) Enriquecimento das Anota\u00e7\u00f5es\u00b6","text":"<p>Adiciona \u00e0s anota\u00e7\u00f5es as colunas de agente, alvo e uma identifica\u00e7\u00e3o combinada (<code>agent_and_target</code>).</p> <p>Etapas:</p> <ul> <li>Recupera <code>agent_id</code> e <code>target_id</code> do conjunto bruto e alinha pelos frames originais.</li> <li>Converte para inteiros e trata ausentes como \u201cmissing\u201d.</li> <li>Cria uma coluna categ\u00f3rica <code>agent_and_target</code> unindo os dois IDs.</li> <li>Reorganiza as colunas para destacar identificadores e frames.</li> </ul> <p>Resultado: Anota\u00e7\u00f5es com <code>agent_id</code>, <code>target_id</code> e <code>agent_and_target</code> consolidados para cada a\u00e7\u00e3o.</p>"},{"location":"classification/model/#2-integracao-com-features-de-tracking","title":"2) Integra\u00e7\u00e3o com Features de Tracking\u00b6","text":"<p>Combina as anota\u00e7\u00f5es com features de tracking por v\u00eddeo e adiciona one-hot encoding da a\u00e7\u00e3o.</p> <p>Etapas:</p> <ul> <li>Faz merge com as features agregadas por v\u00eddeo.</li> <li>Gera colunas <code>action_*</code> (uma por tipo de a\u00e7\u00e3o).</li> <li>Garante que todas as anota\u00e7\u00f5es possuam as features correspondentes.</li> </ul> <p>Resultado: Dataset completo com frames, tracking, a\u00e7\u00e3o codificada e par agente\u2013alvo.</p>"},{"location":"classification/model/#3-preparacao-para-o-mlp-de-agent_and_target","title":"3) Prepara\u00e7\u00e3o para o MLP de <code>agent_and_target</code>\u00b6","text":"<p>Prepara o dataset para o modelo que prev\u00ea o par agente\u2013alvo.</p> <p>Etapas:</p> <ul> <li>Seleciona colunas num\u00e9ricas relevantes (metadados e movimento escalado).</li> <li>Define <code>agent_target_id</code> como r\u00f3tulo num\u00e9rico de <code>agent_and_target</code>.</li> <li>Remove colunas irrelevantes e valida aus\u00eancia de valores faltantes.</li> <li>Divide em treino, valida\u00e7\u00e3o e teste com reprodutibilidade garantida.</li> </ul> <p>Resultado: Matriz de features e r\u00f3tulos pronta para treinar o MLP de predi\u00e7\u00e3o do par agente\u2013alvo.</p>"},{"location":"classification/model/#treinamento-e-avaliacao-do-mlp","title":"Treinamento e Avalia\u00e7\u00e3o do MLP\u00b6","text":"<p>Treina um modelo Multilayer Perceptron (MLP) para classificar agent-target com base nas features preparadas.</p> <p>Configura\u00e7\u00e3o:</p> <ul> <li>Camadas ocultas: 128 \u2192 64 \u2192 32.</li> <li>lr=0.02,</li> <li>max_epochs=3000,</li> <li>batch_size=1024,</li> <li>random_state=42,</li> <li>l2=1e-4,</li> </ul> <p>Justificativa de Par\u00e2metros</p> <ul> <li>Par\u00e2metros foram testados em fun\u00e7\u00e3o da maximiza\u00e7\u00e3o de seus resultados mantendo performance e velocidade de treino para facilitar o desenvolvimento e publica\u00e7\u00e3o do notebook no kaggle, o mesmo vale pela escolha da predi\u00e7\u00e3o em mini-batches.</li> </ul> <p>Avalia\u00e7\u00e3o:</p> <ul> <li>Mede acur\u00e1cia, precis\u00e3o, recall e F1-score por classe.</li> <li>Gera matriz de confus\u00e3o para analisar erros.</li> <li>Exibe curvas de loss e accuracy por \u00e9poca.</li> </ul>"},{"location":"classification/model/#pipeline-de-inferencia-e-geracao-de-submissioncsv","title":"Pipeline de Infer\u00eancia e Gera\u00e7\u00e3o de <code>submission.csv</code>\u00b6","text":""},{"location":"classification/model/#1-features-do-conjunto-de-teste","title":"1) Features do Conjunto de Teste\u00b6","text":"<p>Aplica o <code>preprocessor</code> ao conjunto de teste para gerar features de tracking e metadados por v\u00eddeo. Verifica e reporta poss\u00edveis valores ausentes.</p>"},{"location":"classification/model/#2-criacao-dos-segmentos","title":"2) Cria\u00e7\u00e3o dos Segmentos\u00b6","text":"<p>Divide cada v\u00eddeo em janelas fixas de frames (<code>FRAME_WINDOW</code>) com base na dura\u00e7\u00e3o estimada. Normaliza os frames de in\u00edcio e fim para o intervalo [-1, 1] por v\u00eddeo.</p>"},{"location":"classification/model/#3-calculo-do-movimento","title":"3) C\u00e1lculo do Movimento\u00b6","text":"<p>Para cada segmento, soma o deslocamento das juntas (<code>movement_*</code>) entre os frames definidos. Normaliza os valores usando as estat\u00edsticas do treino e adiciona colunas brutas e escaladas ao dataset.</p>"},{"location":"classification/model/#4-montagem-das-features","title":"4) Montagem das Features\u00b6","text":"<p>Combina os segmentos com as features globais do v\u00eddeo. Seleciona colunas num\u00e9ricas \u00fateis e reordena para o formato esperado pelo MLP, preenchendo ausentes com 0.</p>"},{"location":"classification/model/#5-predicao-de-acao","title":"5) Predi\u00e7\u00e3o de A\u00e7\u00e3o\u00b6","text":"<p>Usa o modelo MLP de a\u00e7\u00e3o para prever <code>action_id</code> e converter para o r\u00f3tulo correspondente. Gera colunas <code>action_*</code> em formato one-hot para entrada no modelo seguinte.</p>"},{"location":"classification/model/#6-predicao-de-agente-e-alvo","title":"6) Predi\u00e7\u00e3o de Agente e Alvo\u00b6","text":"<p>Utiliza o segundo MLP para prever o par <code>agent_and_target</code>. Converte o resultado em <code>agent_id</code> e <code>target_id</code>, tratando valores ausentes ou inv\u00e1lidos como <code>mouse0</code>.</p>"},{"location":"classification/model/#7-pos-processamento","title":"7) P\u00f3s-processamento\u00b6","text":"<p>Ordena por v\u00eddeo e junta segmentos consecutivos com a mesma a\u00e7\u00e3o e par agente\u2013alvo. Gera identificador sequencial (<code>row_id</code>) para cada linha.</p>"},{"location":"classification/model/#8-geracao-do-arquivo-final","title":"8) Gera\u00e7\u00e3o do Arquivo Final\u00b6","text":"<p>Cria o arquivo <code>submission.csv</code> com colunas: <code>row_id</code>, <code>video_id</code>, <code>agent_id</code>, <code>target_id</code>, <code>action</code>, <code>start_frame</code>, <code>stop_frame</code>. Salva o arquivo final e exibe uma pr\u00e9via para confer\u00eancia.</p>"},{"location":"classification/model/#consideracoes-finais","title":"Considera\u00e7\u00f5es Finais\u00b6","text":"<p>O dataset escolhido e problema proposto pela competi\u00e7\u00e3o exigiu uma pipeline complexa e diversos tratamentos dos dados para conseguir chegar a um resultado vi\u00e1vel e plaus\u00edvel de modelo para a competi\u00e7\u00e3o, por\u00e9m existe muito que pode ser melhorado e trabalhado para evolu\u00e7\u00e3o desse modelo, sem contar implementa\u00e7\u00f5es diretas na arquitetura MLP.</p> <ul> <li>Rela\u00e7\u00e3o Temporal</li> </ul> <p>O modelo feito define valores arbitrarios para todos os frames de um v\u00eddeo e prev\u00ea uma a\u00e7\u00e3o espec\u00edfica para cada intervalo de frames definido, por\u00e9m na estrutura dos datasets existem casos com mais de uma a\u00e7\u00e3o no mesmo frame envolvendo diferentes agentes e casos com nenhuma a\u00e7\u00e3o em um frame.</p> <ul> <li>Predi\u00e7\u00e3o de A\u00e7\u00e3o Nula</li> </ul> <p>Essa implementa\u00e7\u00e3o poderia ser realizada de maneira mais simples, adicionando como feature de a\u00e7\u00e3o poss\u00edvel a a\u00e7\u00e3o nula para frames que n\u00e3o possuem uma a\u00e7\u00e3o vinculada, permitindo que essas fossem tamb\u00e9m preditas pelo modelo e os resultados do modelo, por conseguinte, seriam tamb\u00e9m mais coerentes.</p> <ul> <li>Melhoria dos Modelos Base</li> </ul> <p>Existe muito espa\u00e7o para melhora no modelo padr\u00e3o de predi\u00e7\u00e3o de a\u00e7\u00e3o por frame, o que poderia incluir desde melhoria de hiperpar\u00e2metros at\u00e9 tratamento de dados e gera\u00e7\u00e3o de novas features, como c\u00e1lculo de dist\u00e2ncia de juntas espec\u00edficas no intervalo de frames. Uma melhor forma de lidar com o desbalanceamento da base sem perder tantos dados tamb\u00e9m poderia ser crucial na realiza\u00e7\u00e3o de um modelo superior.</p>"},{"location":"exercicio1/main/","title":"Exercicio 1","text":""},{"location":"exercicio1/main/#deep-learning-data","title":"Deep Learning \u2014 Data","text":"<p>Autor: Caio Ortega Boa Disciplina: Deep Learning Per\u00edodo: 2025.1 Link do Reposit\u00f3rio</p>"},{"location":"exercicio1/main/#sumario","title":"Sum\u00e1rio","text":"<ul> <li>Exerc\u00edcio 1: Separabilidade em 2D (dados sint\u00e9ticos gaussianos)  </li> <li>Exerc\u00edcio 2: N\u00e3o-linearidade em 5D e proje\u00e7\u00e3o PCA \u2192 2D  </li> <li>Exerc\u00edcio 3: Pr\u00e9-processamento do Spaceship Titanic (Kaggle) para MLP com <code>tanh</code></li> </ul>"},{"location":"exercicio1/main/#exercicio-1-class-separability-em-2d","title":"Exerc\u00edcio 1 \u2014 Class Separability em 2D","text":"<p>Objetivo. Explorar como a distribui\u00e7\u00e3o de quatro classes em 2D influencia a complexidade das fronteiras de decis\u00e3o que uma rede neural precisaria aprender.</p>"},{"location":"exercicio1/main/#parametros-utilizados","title":"Par\u00e2metros utilizados","text":"<ul> <li>M\u00e9dias (\u03bcx, \u03bcy): (2,3), (5,6), (8,1), (15,4)</li> <li>Desvios (\u03c3x, \u03c3y): (0,8; 2,5), (1,2; 1,9), (0,9; 0,9), (0,5; 2,0) </li> </ul>"},{"location":"exercicio1/main/#visualizacao","title":"Visualiza\u00e7\u00e3o","text":""},{"location":"exercicio1/main/#analise-e-respostas","title":"An\u00e1lise e respostas","text":"<ul> <li>Distribui\u00e7\u00e3o e overlap: Classes 0 e 1 apresentam sobreposi\u00e7\u00e3o consider\u00e1vel enquanto as classes 1 e 2 apresentam leve sobreposi\u00e7\u00e3o; a Classe 3 est\u00e1 deslocada \u00e0 direita sem nenhuma sobreposi\u00e7\u00e3o.  </li> <li>Uma fronteira linear simples separa tudo? N\u00e3o. Com uma \u00fanica fronteira linear n\u00e3o \u00e9 poss\u00edvel separar todas as classes corretamente.  </li> <li>\u201cSketch\u201d das fronteiras que a rede aprenderia: Para separar de maneira eficiente todas as classes seriam necess\u00e1rias pelo menos 3 fronteiras lineares.</li> </ul>"},{"location":"exercicio1/main/#codigo","title":"C\u00f3digo","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\n# Garante reprodutibilidade dos n\u00fameros aleat\u00f3rios\nnp.random.seed(42)\n\ndef draw_line(ax, point1, point2, style='--', color='k', lw=2):\n    \"\"\"\n    Desenha uma linha entre dois pontos no gr\u00e1fico.\n\n    Par\u00e2metros:\n    - ax: objeto matplotlib.axes onde a linha ser\u00e1 desenhada.\n    - point1: tupla (x1, y1) do primeiro ponto.\n    - point2: tupla (x2, y2) do segundo ponto.\n    - style: estilo da linha (default='--' tracejada).\n    - color: cor da linha (default='k' preto).\n    - lw: espessura da linha.\n    - label: legenda opcional para a linha.\n    \"\"\"\n    x_vals = [point1[0], point2[0]]\n    y_vals = [point1[1], point2[1]]\n    ax.plot(x_vals, y_vals, style, color=color, lw=lw)\n\n# Par\u00e2metros das distribui\u00e7\u00f5es gaussianas:\n# means = lista de tuplas (\u03bcx, \u03bcy) = m\u00e9dias em cada eixo\n# stds = lista de tuplas (\u03c3x, \u03c3y) = desvios em cada eixo\nmeans = [(2,3), (5,6), (8,1), (15,4)]\nstds = [(0.8,2.5), (1.2,1.9), (0.9,0.9), (0.5,2.0)]\n\n# Listas para acumular pontos (X) e r\u00f3tulos (y)\nX = []\ny = []\n\n# Para cada classe (0,1,2,3) gera 100 pontos 2D\n# np.random.normal aceita tuplas em loc/scale\n# loc=(\u03bcx, \u03bcy) =&gt; m\u00e9dia por eixo\n# scale=(\u03c3x, \u03c3y) =&gt; desvio por eixo\n# Isso equivale a gaussianas 2D com covari\u00e2ncia diagonal\nfor i, (mean, std) in enumerate(zip(means, stds)):\n    points = np.random.normal(loc=mean, scale=std, size=(100,2))\n    X.append(points)               # pontos da classe i\n    y.append(np.full(100, i))      # vetor [i, i, ..., i] (100 vezes)\n\n# Empilha todas as classes em um \u00fanico array\nX = np.vstack(X)  # shape (400, 2)\ny = np.hstack(y)  # shape (400,)\n\n# Cria o gr\u00e1fico de dispers\u00e3o\nfig, ax = plt.subplots(figsize=(8,6))\nfor i in range(4):\n    # Plota os pontos da classe i\n    ax.scatter(X[y==i,0], X[y==i,1], label=f'Class {i}', alpha=0.7)\n\n#Desenhando linhas arbitrarias de separa\u00e7\u00e3o\ndraw_line(ax, (5,-3), (2,15), style='-', color='purple')\ndraw_line(ax, (4.5,1.5), (12.5,5), style='-', color='purple')\ndraw_line(ax, (12.5,-3), (12.5,15), style='-', color='purple')\n\nax.legend()\nax.set_title(\"Synthetic 2D Gaussian Dataset\")\nax.set_xlabel(\"X1\")\nax.set_ylabel(\"X2\")\nplt.show()\n</code></pre>"},{"location":"exercicio1/main/#exercicio-2-nao-linearidade-em-5d-pca-5d-2d","title":"Exerc\u00edcio 2 \u2014 N\u00e3o-linearidade em 5D + PCA (5D \u2192 2D)","text":"<p>Objetivo. Criar dois grupos 5D com m\u00e9dias/covari\u00e2ncias especificadas e visualizar em 2D via PCA.</p>"},{"location":"exercicio1/main/#configuracao","title":"Configura\u00e7\u00e3o","text":"<ul> <li>Classe A: vetor de m\u00e9dia nulo; covari\u00e2ncias positivas entre algumas dimens\u00f5es.  </li> <li>Classe B: vetor de m\u00e9dia transladado (1,5 em todas as componentes); covari\u00e2ncias com sinais distintos, alterando forma e orienta\u00e7\u00e3o do grupo.</li> </ul>"},{"location":"exercicio1/main/#visualizacao_1","title":"Visualiza\u00e7\u00e3o","text":""},{"location":"exercicio1/main/#analise-e-respostas_1","title":"An\u00e1lise e respostas","text":"<ul> <li>Rela\u00e7\u00e3o entre as classes (proje\u00e7\u00e3o 2D): Observa-se mistura parcial, embora possa se identificar certa separa\u00e7\u00e3o entre as nuvens.  </li> <li>Separabilidade linear: Embora possa ser observado uma distribui\u00e7\u00e3o com certa separa\u00e7\u00e3o na proje\u00e7\u00e3o 2d dos dados, uma separa\u00e7\u00e3o linear seria muito ineficiente para o caso proposto. Por haverem m\u00faltiplas dimens\u00f5es nos dados a separabilidade linear tenderia a perder muita informa\u00e7\u00e3o, por n\u00e3o haver um hiperplano perfeito capaz de separar as duas classes.</li> </ul>"},{"location":"exercicio1/main/#codigo_1","title":"C\u00f3digo","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n\n# Reprodutibilidade\nnp.random.seed(42)\n\n# -----------------------------\n# 1) Define par\u00e2metros 5D\n# -----------------------------\n# Classe A\nmu_A = np.array([0.0, 0.0, 0.0, 0.0, 0.0])\nSigma_A = np.array([\n    [1.0, 0.8, 0.1, 0.0, 0.0],\n    [0.8, 1.0, 0.3, 0.0, 0.0],\n    [0.1, 0.3, 1.0, 0.5, 0.0],\n    [0.0, 0.3, 0.5, 1.0, 0.2],\n    [0.0, 0.0, 0.0, 0.2, 1.0],\n], dtype=float)\n\n# Classe B\nmu_B = np.array([1.5, 1.5, 1.5, 1.5, 1.5])\nSigma_B = np.array([\n    [ 1.5, -0.7,  0.2,  0.0, 0.0],\n    [-0.7,  1.5,  0.4,  0.0, 0.0],\n    [ 0.2,  0.4,  1.5,  0.6, 0.0],\n    [ 0.0,  0.0,  0.6,  1.5, 0.3],\n    [ 0.0,  0.0,  0.0,  0.3, 1.5],\n], dtype=float)\n\n# -----------------------------\n# 2) Gera\u00e7\u00e3o dos dados (5D)\n# -----------------------------\nnA, nB = 500, 500\nXA = np.random.multivariate_normal(mean=mu_A, cov=Sigma_A, size=nA)\nXB = np.random.multivariate_normal(mean=mu_B, cov=Sigma_B, size=nB)\n\n# Empilha dados e r\u00f3tulos\nX_5d = np.vstack([XA, XB])         # (1000, 5)\ny    = np.array([0]*nA + [1]*nB)  # 0 = Classe A, 1 = Classe B\n\n# -----------------------------\n# 3) Redu\u00e7\u00e3o de dimensionalidade (PCA \u2192 2D)\n# -----------------------------\npca = PCA(n_components=2, random_state=42)\nX_2d = pca.fit_transform(X_5d)     # (1000, 2)\n\n# -----------------------------\n# 4) Visualiza\u00e7\u00e3o (apenas pontos)\n# -----------------------------\nplt.figure(figsize=(8, 6))\nplt.scatter(X_2d[y==0, 0], X_2d[y==0, 1], alpha=0.6, s=18, label=\"Class A\")\nplt.scatter(X_2d[y==1, 0], X_2d[y==1, 1], alpha=0.6, s=18, label=\"Class B\")\nplt.xlabel(\"PC1\")\nplt.ylabel(\"PC2\")\nplt.title(\"Exercise 2 \u2014 PCA (5D \u2192 2D) scatter\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"exercicio1/main/#exercicio-3-spaceship-titanic-kaggle-pre-processamento-para-tanh","title":"Exerc\u00edcio 3 \u2014 Spaceship Titanic (Kaggle): Pr\u00e9-processamento para <code>tanh</code>","text":"<p>Objetivo. Preparar dados reais para uma MLP com <code>tanh</code>, assegurando entradas est\u00e1veis.</p>"},{"location":"exercicio1/main/#descricao-do-dataset","title":"Descri\u00e7\u00e3o do dataset","text":"<ul> <li>Objetivo do Dataset O Dataset simula um \"Titanic espacial\", que estaria lotado de passageiros e colidiu com uma anomalia espacial que trasnportou diversos passageiros para outra dimens\u00e3o. O objetivo do dataset \u00e9 descobrir quais passageiros teriam sido transportados para essa dimens\u00e3o alternativa baseado em seus dados.</li> <li>Alvo: <code>Transported</code> \u2014 indica se o passageiro foi transportado para outra dimens\u00e3o (bin\u00e1rio).  </li> <li>Num\u00e9ricas: <code>Age</code>, <code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>, <code>CabinNum</code>, <code>Group</code>, <code>PaxInGroup</code>, <code>TotalSpend</code>.  </li> <li>Categ\u00f3ricas: <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Destination</code>, <code>VIP</code>, <code>CabinDeck</code>, <code>CabinSide</code>.  </li> <li>Engenharia aplicada: A feature <code>Cabin</code> foi decomposta em <code>CabinDeck</code>, <code>CabinNum</code> e <code>CabinSide</code>;  <code>PassengerId</code> foi decomposto em <code>Group</code> e <code>PaxInGroup</code>; <code>Transported</code> foi convertido para 0/1.</li> </ul>"},{"location":"exercicio1/main/#faltantes","title":"Faltantes","text":"<ul> <li>Investiga\u00e7\u00e3o Todas as colunas, fora <code>PassengerId</code> e <code>Transported</code> possuiam dados faltantes.</li> <li>Num\u00e9ricas: imputa\u00e7\u00e3o pela mediana (robusta a outliers; preserva a posi\u00e7\u00e3o central).  </li> <li>Categ\u00f3ricas: imputa\u00e7\u00e3o pela moda (mant\u00e9m r\u00f3tulos conhecidos; evita categorias artificiais).  </li> </ul>"},{"location":"exercicio1/main/#tratamento-das-features","title":"Tratamento das Features","text":"<ul> <li>One-Hot Encoding Utilizado para tratamento de features categ\u00f3ricas.</li> <li>Normaliza\u00e7\u00e3o para <code>[-1, 1]</code>: Utilizado para tratamento de features num\u00e9ricas, de modo a acomodar os dados corretamente para a utiliza\u00e7\u00e3o da fun\u00e7\u00e3o de ativa\u00e7\u00e3o <code>tanh</code>. Se trata de uma boa pr\u00e1tica pois possibilita padroniza a escala das features e possibilita que a maior parte dos dados esteja na parte central da curva, otimizando o treinamento.</li> </ul>"},{"location":"exercicio1/main/#visualizacoes","title":"Visualiza\u00e7\u00f5es","text":"<p>Antes da transforma\u00e7\u00e3o </p> <p>Depois da transforma\u00e7\u00e3o </p>"},{"location":"exercicio1/main/#codigo_2","title":"C\u00f3digo","text":"<pre><code>#Imports e leitura\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\n\n#Configs visuais\nplt.rcParams[\"figure.figsize\"] = (8, 5)\nplt.rcParams[\"axes.grid\"] = True\n\n#Reprodutibilidade\nnp.random.seed(42)\n\n#Caminho do arquivo\nCSV_PATH = \"spaceship.csv\"\n\ndf = pd.read_csv(CSV_PATH)\nprint(df.shape)\ndf.head()\n</code></pre> <pre><code>#Vis\u00e3o geral: tipos e faltantes\nprint(\"\\n=== info() ===\")\ndf.info()\n\nprint(\"\\n=== Missing values por coluna ===\")\nmissing_abs = df.isna().sum().sort_values(ascending=False)\nmissing_pct = (df.isna().mean()*100).sort_values(ascending=False)\ndisplay(pd.DataFrame({\"missing\": missing_abs, \"missing_%\": missing_pct.round(2)}))\n</code></pre> <pre><code>#Quebra Cabin em deck/num/side\ncabin = df[\"Cabin\"].astype(\"string\")\nparts = cabin.str.split(\"/\", expand=True)\ndf[\"CabinDeck\"] = parts[0]\ndf[\"CabinNum\"]  = pd.to_numeric(parts[1], errors=\"coerce\")\ndf[\"CabinSide\"] = parts[2]\n\n#Quebra PassengerId em grupo e \u00edndice no grupo\npid = df[\"PassengerId\"].astype(\"string\")\ngrp_pp = pid.str.split(\"_\", expand=True)\ndf[\"Group\"] = pd.to_numeric(grp_pp[0], errors=\"coerce\")  \ndf[\"PaxInGroup\"] = pd.to_numeric(grp_pp[1], errors=\"coerce\")\n\n#Transported -&gt; 0/1\ndf[\"Transported\"] = df[\"Transported\"].map({True:1, False:0, \"True\":1, \"False\":0}).astype(int)\n\n#Colunas que n\u00e3o vamos usar como features\ndrop_cols = [\"PassengerId\", \"Name\", \"Cabin\"] \n\n#Colunas num\u00e9ricas e categ\u00f3ricas\nnumeric_features = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"Group\", \"CabinNum\", \"PaxInGroup\"]\ncategorical_features = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"CabinDeck\", \"CabinSide\"]\n\nprint(\"numeric_features:\", numeric_features)\nprint(\"categorical_features:\", categorical_features)\n\ndf_pre = df.drop(columns=drop_cols).copy()\ndf_pre.head()\n</code></pre> <pre><code>#Separa\u00e7\u00e3o X, y\ntarget = \"Transported\"\nX = df_pre.drop(columns=[target])\ny = df_pre[target].values\n</code></pre> <pre><code>#Sanitiza\u00e7\u00e3o (Corre\u00e7\u00e3o de erros no processamento)\nX = X.copy()\n\n#Booleans para strings\nfor col in [\"CryoSleep\", \"VIP\"]:\n    if col in X.columns:\n        X[col] = X[col].map({True: \"True\", False: \"False\"}).astype(\"object\")\n\n#CATEG\u00d3RICAS como 'object' e remover pd.NA\nfor c in categorical_features:\n    if c in X.columns:\n        X[c] = X[c].astype(\"object\")\n        mask = pd.isna(X[c])\n        if mask.any():\n            X.loc[mask, c] = np.nan\n\n#NUM\u00c9RICAS realmente num\u00e9ricas\nfor c in numeric_features:\n    if c in X.columns:\n        X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n</code></pre> <pre><code># Num\u00e9ricas: imputar mediana + scaler (-1, 1)\nnum_pipe = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\",  MinMaxScaler(feature_range=(-1, 1))),\n])\n\n# Categ\u00f3ricas: imputar moda + OneHot\ncat_pipe = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"onehot\",  OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", num_pipe, numeric_features),\n        (\"cat\", cat_pipe, categorical_features),\n    ],\n    remainder=\"drop\",\n)\n\nX_proc = preprocessor.fit_transform(X)\n\nprint(\"X_proc shape:\", X_proc.shape)\n</code></pre> <pre><code>#Checagem de colunas ap\u00f3s OHE\nnum_names = numeric_features\ncat_names = preprocessor.named_transformers_[\"cat\"][\"onehot\"].get_feature_names_out(categorical_features).tolist()\nfinal_feature_names = num_names + cat_names\n\nprint(\"Total de colunas ap\u00f3s OHE:\", len(final_feature_names))\n</code></pre> <pre><code>#Plotagem dos histogramas\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# Antes\nX[\"Age\"].hist(ax=axes[0], bins=30, alpha=0.8)\naxes[0].set_title(\"Age \u2014 antes da escala\")\naxes[0].set_xlabel(\"Age\")\n\nX[\"FoodCourt\"].hist(ax=axes[1], bins=30, alpha=0.8)\naxes[1].set_title(\"FoodCourt \u2014 antes da escala\")\naxes[1].set_xlabel(\"FoodCourt\")\nplt.tight_layout()\nplt.show()\n\n# Depois\nage_idx = numeric_features.index(\"Age\")\nfood_idx = numeric_features.index(\"FoodCourt\")\n\nage_scaled   = X_proc[:, age_idx]\nfood_scaled  = X_proc[:, food_idx]\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\naxes[0].hist(age_scaled, bins=30, alpha=0.8)\naxes[0].set_title(\"Age \u2014 depois (StandardScaler)\")\naxes[0].set_xlabel(\"z-score\")\n\naxes[1].hist(food_scaled, bins=30, alpha=0.8)\naxes[1].set_title(\"FoodCourt \u2014 depois (StandardScaler)\")\naxes[1].set_xlabel(\"z-score\")\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"exercicio2/main/","title":"Exercicio 2","text":""},{"location":"exercicio2/main/#deep-learning-perceptron","title":"Deep Learning \u2014 Perceptron","text":"<p>Autor: Caio Ortega Boa Disciplina: Deep Learning Per\u00edodo: 2025.1 Link do Reposit\u00f3rio</p>"},{"location":"exercicio2/main/#sumario","title":"Sum\u00e1rio","text":"<ul> <li>Perceptron Implementa\u00e7\u00e3o de um Perceptron</li> <li>Exerc\u00edcio 1: Treinamento de Perceptron com Converg\u00eancia </li> <li>Exerc\u00edcio 2: Treinamento de Perceptron sem Converg\u00eancia</li> </ul>"},{"location":"exercicio2/main/#perceptron-implementacao-de-um-perceptron","title":"Perceptron \u2014 Implementa\u00e7\u00e3o de um Perceptron","text":"<p>Objetivo. Implementa\u00e7\u00e3o de um Perceptron sem utiliza\u00e7\u00e3o de bibliotecas auxiliares e modelos prontos, apenas Numpy para c\u00e1lculos matriciais.</p>"},{"location":"exercicio2/main/#codigo","title":"C\u00f3digo","text":"<pre><code>import numpy as np\n\nclass Perceptron:\n    \"\"\"\n    Single-layer Perceptron implemented from scratch.\n    \"\"\"\n    def __init__(\n        self,\n        lr: float = 0.1,\n        max_epochs: int = 100,\n        random_state: int | None = None,\n        track_history: bool = True,\n    ):\n        self.lr = lr\n        self.max_epochs = max_epochs\n        self.random_state = random_state\n        self.track_history = track_history\n\n        self.w = None\n        self.b = 0.0\n        self.accuracy_history_ = []\n\n    def decision_function(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Compute raw scores (w\u00b7x + b).\n        X: shape (n_samples, n_features)\n        \"\"\"\n        if self.w is None:\n            raise ValueError(\"Model is not fitted yet.\")\n        return X @ self.w + self.b\n\n    def predict(self, X: np.ndarray) -&gt; np.ndarray:\n        \"\"\"\n        Predict labels in {-1, +1} using sign(w\u00b7x + b).\n        \"\"\"\n        scores = self.decision_function(X)\n        return np.where(scores &gt;= 0, 1, -1)\n\n    def fit(self, X: np.ndarray, y: np.ndarray) -&gt; dict:\n        \"\"\"\n        Fit the perceptron on labels in {-1, +1}.\n        Stops early if an epoch completes with zero updates.\n        Records accuracy after each epoch.\n        Returns a training log with 'epochs_run' and 'converged' keys.\n        \"\"\"\n        rng = np.random.default_rng(self.random_state)\n        n_samples, n_features = X.shape\n\n        # Initialize parameters\n        self.w = np.zeros(n_features, dtype=float)\n        self.b = 0.0\n        self.accuracy_history_ = []\n\n        indices = np.arange(n_samples)\n\n        converged = False\n        epochs_run = 0\n\n        for epoch in range(self.max_epochs):\n            epochs_run += 1\n            # Shuffle each epoch for robustness\n            rng.shuffle(indices)\n            updates = 0\n\n            for idx in indices:\n                x_i = X[idx]\n                y_i = y[idx]  # must be -1 or +1\n                margin = y_i * (np.dot(self.w, x_i) + self.b)\n                if margin &lt;= 0:\n                    # Misclassified -&gt; update\n                    self.w = self.w + self.lr * y_i * x_i\n                    self.b = self.b + self.lr * y_i\n                    updates += 1\n\n            # Accuracy after epoch\n            y_pred = self.predict(X)\n            acc = np.mean(y_pred == y)\n            self.accuracy_history_.append(acc)\n\n            if updates == 0:\n                converged = True\n                break\n\n        return {\"epochs_run\": epochs_run, \"converged\": converged}\n</code></pre>"},{"location":"exercicio2/main/#exercicio-1-treinamento-de-perceptron-com-convergencia","title":"Exerc\u00edcio 1 \u2014 Treinamento de Perceptron com Converg\u00eancia","text":"<p>Objetivo. Gerar um dataset 2d com clara distin\u00e7\u00e3o entre classes para realiza\u00e7\u00e3o do treinamento de um perceptron.</p>"},{"location":"exercicio2/main/#parametros-utilizados","title":"Par\u00e2metros utilizados","text":"<ul> <li>M\u00e9dias (\u03bcx, \u03bcy): (1.5,1.5), (5,5)</li> <li>Desvios (\u03c3x, \u03c3y): (0.5; 0), (0; 0.5)</li> </ul>"},{"location":"exercicio2/main/#visualizacao","title":"Visualiza\u00e7\u00e3o","text":""},{"location":"exercicio2/main/#resultados","title":"Resultados","text":"<ul> <li>Final Weights [0.304 , 0.199]</li> <li>Final Bias -1.6</li> <li>Epochs 2</li> <li>Fina Accuracy 1.0</li> </ul>"},{"location":"exercicio2/main/#analise-dos-resultados","title":"An\u00e1lise dos Resultados","text":"<ul> <li>Alta Separabilidade A alta separabilidade dos dados gerados, apresentando classes extremamente bem definidas por uma \u00fanica linha de decis\u00e3o, s\u00e3o respons\u00e1veis pelo baixo n\u00famero de \u00e9pocas necess\u00e1rio para a convers\u00e3o. Isso se deve pois, conforme o treinamento ocorre e a linha se enviesa para os dados, o modelo passa a classificar todos os dados corretamente, ocasionando em sua converg\u00eancia.</li> </ul>"},{"location":"exercicio2/main/#codigo_1","title":"C\u00f3digo","text":"<pre><code>mean0 = np.array([1.5, 1.5])\ncov0  = np.array([[0.5, 0.0],[0.0, 0.5]])\n\nmean1 = np.array([5.0, 5.0])\ncov1  = np.array([[0.5, 0.0],[0.0, 0.5]])\n\nn_per_class = 1000\n\nX0 = rng.multivariate_normal(mean0, cov0, size=n_per_class)\nX1 = rng.multivariate_normal(mean1, cov1, size=n_per_class)\n\nX = np.vstack([X0, X1])\ny01 = np.hstack([np.zeros(n_per_class, dtype=int), np.ones(n_per_class, dtype=int)])\ny = np.where(y01 == 1, 1, -1)\n\nplt.figure()\nplt.scatter(X0[:, 0], X0[:, 1], label=\"Class 0\")\nplt.scatter(X1[:, 0], X1[:, 1], label=\"Class 1\")\nplt.title(\"Exercise 1: Generated Data\")\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.legend()\nplt.show()\n</code></pre> <pre><code># Train perceptron\nclf = Perceptron(lr=0.1, max_epochs=100, random_state=42)\nlog = clf.fit(X, y)\n\n# Evaluate\ny_pred = clf.predict(X)\nacc = np.mean(y_pred == y)\nprint(\"Epochs run:\", log[\"epochs_run\"])\nprint(\"Converged:\", log[\"converged\"])\nprint(\"Final weights:\", clf.w)\nprint(\"Final bias:\", clf.b)\nprint(\"Final accuracy:\", acc)\n</code></pre>"},{"location":"exercicio2/main/#exercicio-2-treinamento-de-perceptron-sem-convergencia","title":"Exerc\u00edcio 2 \u2014 Treinamento de Perceptron sem Converg\u00eancia","text":"<p>Objetivo. Gerar um dataset 2d com baixa distin\u00e7\u00e3o entre classes para realiza\u00e7\u00e3o do treinamento de um perceptron.</p>"},{"location":"exercicio2/main/#parametros-utilizados_1","title":"Par\u00e2metros utilizados","text":"<ul> <li>M\u00e9dias (\u03bcx, \u03bcy): (3.0,3.0), (4.0,4.0)</li> <li>Desvios (\u03c3x, \u03c3y): (1.5; 0), (0; 1.5)</li> </ul>"},{"location":"exercicio2/main/#visualizacao_1","title":"Visualiza\u00e7\u00e3o","text":""},{"location":"exercicio2/main/#resultados_1","title":"Resultados","text":"<ul> <li>Final Weights [-0.140 , 0.955]</li> <li>Final Bias -4.5</li> <li>Epochs 100</li> <li>Fina Accuracy 0.558</li> </ul>"},{"location":"exercicio2/main/#analise-dos-resultados_1","title":"An\u00e1lise dos Resultados","text":"<ul> <li>Baixa Separabilidade No seguinte dataset, havendo baixa separabilidade de dados, o modelo do perceptron n\u00e3o conseguiu convergir. Isso se deve a mistura e sobreposi\u00e7\u00e3o de dados que existe no dataset, impossibilitando que todas as classes sejam devidamente identificadas por uma \u00fanica linha de decis\u00e3o linear. Por conta disso o perceptron nunca ir\u00e1 encontrar os pesos ideais para o treinamento, n\u00e3o permitindo sua converg\u00eancia.</li> </ul>"},{"location":"exercicio2/main/#codigo_2","title":"C\u00f3digo","text":"<pre><code>mean0 = np.array([3.0, 3.0])\ncov0  = np.array([[1.5, 0.0],[0.0, 1.5]])\n\nmean1 = np.array([4.0, 4.0])\ncov1  = np.array([[1.5, 0.0],[0.0, 1.5]])\n\nn_per_class = 1000\n\nX0 = rng.multivariate_normal(mean0, cov0, size=n_per_class)\nX1 = rng.multivariate_normal(mean1, cov1, size=n_per_class)\n\nX = np.vstack([X0, X1])\ny01 = np.hstack([np.zeros(n_per_class, dtype=int), np.ones(n_per_class, dtype=int)])\ny = np.where(y01 == 1, 1, -1)\n\nplt.figure()\nplt.scatter(X0[:, 0], X0[:, 1], label=\"Class 0\")\nplt.scatter(X1[:, 0], X1[:, 1], label=\"Class 1\")\nplt.title(\"Exercise 2: Generated Data\")\nplt.xlabel(\"x1\")\nplt.ylabel(\"x2\")\nplt.legend()\nplt.show()\n</code></pre> <pre><code>clf = Perceptron(lr=0.1, max_epochs=100, random_state=123)\nlog = clf.fit(X, y)\n\ny_pred = clf.predict(X)\nacc = np.mean(y_pred == y)\n\nprint(\"Epochs run:\", log[\"epochs_run\"])\nprint(\"Converged:\", log[\"converged\"])\nprint(\"Final weights:\", clf.w)\nprint(\"Final bias:\", clf.b)\nprint(\"Final accuracy:\", acc)\n</code></pre>"},{"location":"exercicio3/main/","title":"Exercicio 3","text":""},{"location":"exercicio3/main/#deep-learning-multi-layer-perceptron-mlp","title":"Deep Learning \u2014 Multi-Layer Perceptron (MLP)","text":"<p>Autor: Caio Ortega Boa Disciplina: Deep Learning Per\u00edodo: 2025.1 Link do Reposit\u00f3rio</p>"},{"location":"exercicio3/main/#sumario","title":"Sum\u00e1rio","text":"<ul> <li>Exerc\u00edcio 1 C\u00e1lculo Manual de uma MLP</li> <li>MLP: rede com camadas ocultas <code>tanh</code> e sa\u00edda <code>softmax</code> </li> <li>Exerc\u00edcio 2: Classifica\u00e7\u00e3o bin\u00e1ria  </li> <li>Exerc\u00edcio 3: Classifica\u00e7\u00e3o multiclasse </li> <li>Exerc\u00edcio 4: Classifica\u00e7\u00e3o multiclasse (+ camadas ocultas)</li> </ul>"},{"location":"exercicio3/main/#exercicio-1-calculo-manual-de-uma-mlp","title":"Exerc\u00edcio 1 \u2014 C\u00e1lculo Manual de uma MLP","text":"<p>Descri\u00e7\u00e3o do modelo. MLP com 2 entradas, 1 camada oculta (2 neur\u00f4nios) e 1 neur\u00f4nio de sa\u00edda. Ativa\u00e7\u00f5es: <code>tanh</code> na oculta e na sa\u00edda. Loss: MSE.</p>"},{"location":"exercicio3/main/#1-dados-do-problema-preencher","title":"1) Dados do problema (preencher)","text":"<ul> <li>Entrada (vetor coluna): x = [ 0.5 , 0,2]</li> <li>Sa\u00edda desejada: y = 1.0 </li> <li>Pesos da camada oculta W1 = [[0.3 , -0.1][0.2, 0.4]]</li> <li>Vieses da camada oculta b1 = [0.1 , -0.2]</li> <li>Pesos da sa\u00edda W2 = [0.5, -0.3]</li> <li>Vi\u00e9s da sa\u00edda b2 = 0.2 </li> <li>Taxa de aprendizado: eta = 0.3</li> </ul>"},{"location":"exercicio3/main/#2-forward-pass","title":"2) Forward pass","text":"<ul> <li>Pr\u00e9-ativa\u00e7\u00f5es na oculta: z1 = W1 @ x + b1 = [0.27, -0.18]</li> <li>Ativa\u00e7\u00f5es na oculta: a1 = tanh(z1) = [0.2636, -0.1780]</li> <li>Pr\u00e9-ativa\u00e7\u00e3o na sa\u00edda: z2 = W2 @ a1 + b2 = 0.3852  </li> <li>Sa\u00edda da rede: y^ = tanh(z2) = 0.3672</li> </ul>"},{"location":"exercicio3/main/#3-loss-mse","title":"3) Loss (MSE)","text":"<ul> <li>L = (y - y<sup>)</sup>2 = 0.4003</li> </ul>"},{"location":"exercicio3/main/#4-backward-pass","title":"4) Backward pass","text":"<ul> <li>dl/dy^ = -2*(y - y^) = -1.2655  </li> <li>dy^/dz2 = 1 - tanh(z2)^2 = 0.8651</li> <li>dl/dz2 = -1.0948</li> <li>dL/dW2 = dl/dz2 * a1^T = [-0.2886, 0.1949]</li> <li>dL/db2 = dl/dz2 = -1.0948</li> <li>dL/da1 = W2^T * dl/dz2 = [-0.5474, 0.3180]</li> <li>da1/dz1 = 1 - tanh(z1)^2 = [0.9305, 0.9682]</li> <li>dL/dz1 = (W2^T*dl/dz2) * (1 - tanh(z1)^2) = [-0.5093, 0.3180]</li> <li>dL/dW1 = dL/dz1 * x^T = [[-0.2546, 0.1018][0.1590, -0.0636]]</li> <li>dL/db1 = dL/dz1 = [-0.5093, 0.3180]</li> </ul>"},{"location":"exercicio3/main/#5-atualizacao-dos-parametros-gradient-descent","title":"5) Atualiza\u00e7\u00e3o dos par\u00e2metros (Gradient Descent)","text":"<ul> <li>W2 = W2 - eta * dL/dW2 = [0.5865, -0.3584]</li> <li>b2 = b2 - eta * dL/db2 = 0.5284</li> <li>W1 = W1 - eta * dl/dW1 = [[0.3764, -0.1305][0.1522, 0.4190]]</li> <li>b1 = b1 - eta * dL/db1 = [0.2528, -0.2954]  </li> </ul>"},{"location":"exercicio3/main/#mlp","title":"MLP","text":"<p>Objetivo. Implementar uma MLP modular em NumPy, suportando: - Entrada gen\u00e9rica (<code>input_dim = n_features</code>); - N camadas ocultas (lista de larguras), ativa\u00e7\u00e3o <code>tanh</code> em todas as ocultas; - Camada de sa\u00edda <code>softmax</code> com <code>output_dim = n_classes</code>; - Loss: categorical cross-entropy; - Otimiza\u00e7\u00e3o: Gradient Descent;.</p> <p>Fluxo do treino. 1. Inicializa\u00e7\u00e3o dos par\u00e2metros; 2. Forward; 3. Loss; 4. Backward; 5. Gradient Descent;  </p> <pre><code># mlp.py\nfrom __future__ import annotations\nfrom typing import List, Optional\nimport numpy as np\n\nfrom utils import (\n    tanh, dtanh_from_a,\n    softmax, one_hot, cross_entropy, accuracy_score,\n    xavier_init,\n)\n\nclass MLP:\n    def __init__(\n        self,\n        input_dim: int,\n        hidden_layers: List[int] = [16, 16],\n        output_dim: int = 2,        \n        lr: float = 0.05,\n        max_epochs: int = 500,\n        batch_size: Optional[int] = None,\n        random_state: Optional[int] = 42,\n        track_history: bool = True,\n    ):\n        self.input_dim = input_dim\n        self.hidden_layers = hidden_layers\n        self.output_dim = output_dim\n        self.lr = lr\n        self.max_epochs = max_epochs\n        self.batch_size = batch_size\n        self.random_state = random_state\n        self.track_history = track_history\n\n        self.params_ = None\n        self.loss_history_: List[float] = []\n        self.acc_history_: List[float] = []\n\n    # ---------- initialization ----------\n    def _init_params(self, rng: np.random.Generator) -&gt; None:\n        layer_sizes = [self.input_dim] + self.hidden_layers + [self.output_dim]\n        W, b = [], []\n        for l in range(1, len(layer_sizes)):\n            fan_in = layer_sizes[l-1]\n            fan_out = layer_sizes[l]\n            W_l = xavier_init(fan_in, fan_out, rng)\n            b_l = np.zeros((fan_out, 1))\n            W.append(W_l)\n            b.append(b_l)\n        self.params_ = {\"W\": W, \"b\": b}\n\n    # ---------- forward ----------\n    def _forward(self, X: np.ndarray):\n        W, B = self.params_[\"W\"], self.params_[\"b\"]\n        A = X.T  \n        caches = [{\"A\": A}]  \n\n        # hidden layers\n        for l in range(len(self.hidden_layers)):\n            Z = W[l] @ A + B[l]\n            A = tanh(Z)\n            caches.append({\"Z\": Z, \"A\": A})\n\n        # output layer (softmax)\n        ZL = W[-1] @ A + B[-1]\n        P = softmax(ZL, axis=0)\n        caches.append({\"Z\": ZL, \"A\": P})\n        return caches, P.T\n\n    # ---------- backward ----------\n    def _backward(self, caches, y: np.ndarray):\n        W = self.params_[\"W\"]\n        L = len(W)\n        m = y.shape[0]\n\n        A0 = caches[0][\"A\"]\n        A_list = [A0] + [c[\"A\"] for c in caches[1:]]\n\n        Y = one_hot(y.reshape(-1), self.output_dim).T\n        P = A_list[-1]\n\n        dZ = (P - Y) / m\n        dW = [None] * L\n        dB = [None] * L\n\n        # \u00faltima camada\n        A_prev = A_list[-2]\n        dW[L-1] = dZ @ A_prev.T\n        dB[L-1] = np.sum(dZ, axis=1, keepdims=True)\n\n        # ocultas\n        for l in reversed(range(L-1)):\n            dA = W[l+1].T @ dZ\n            A_l = A_list[l+1]\n            dZ = dA * dtanh_from_a(A_l)\n\n            A_prev = A_list[l]\n            dW[l] = dZ @ A_prev.T\n            dB[l] = np.sum(dZ, axis=1, keepdims=True)\n\n        return dW, dB\n\n    # ---------- update ----------\n    def _update(self, dW, dB, lr: float) -&gt; None:\n        for l in range(len(self.params_[\"W\"])):\n            self.params_[\"W\"][l] -= lr * dW[l]\n            self.params_[\"b\"][l] -= lr * dB[l]\n\n    # ---------- fit ----------\n    def fit(self, X: np.ndarray, y: np.ndarray):\n        rng = np.random.default_rng(self.random_state)\n        self._init_params(rng)\n\n        m = X.shape[0]\n        batch_size = self.batch_size or m\n\n        for epoch in range(1, self.max_epochs + 1):\n            idx = rng.permutation(m)\n            X_shuf = X[idx]\n            y_shuf = y[idx]\n\n            for start in range(0, m, batch_size):\n                end = min(start + batch_size, m)\n                Xb = X_shuf[start:end]\n                yb = y_shuf[start:end]\n\n                caches, _ = self._forward(Xb)\n                dW, dB = self._backward(caches, yb)\n                self._update(dW, dB, self.lr)\n\n            if self.track_history:\n                P_full = self.predict_proba(X)\n                Y_full = one_hot(y, self.output_dim)\n                loss = cross_entropy(Y_full, P_full)\n                y_pred = np.argmax(P_full, axis=1)\n                acc = accuracy_score(y, y_pred)\n                self.loss_history_.append(loss)\n                self.acc_history_.append(acc)\n\n        return {\"epochs_run\": self.max_epochs}\n\n    def predict_proba(self, X: np.ndarray) -&gt; np.ndarray:\n        _, P = self._forward(X)\n        return P\n\n    def decision_function(self, X: np.ndarray) -&gt; np.ndarray:\n        W, B = self.params_[\"W\"], self.params_[\"b\"]\n        A = X.T\n        for l in range(len(self.hidden_layers)):\n            A = tanh(W[l] @ A + B[l])\n        ZL = W[-1] @ A + B[-1]\n        return ZL.T\n\n    def predict(self, X: np.ndarray) -&gt; np.ndarray:\n        P = self.predict_proba(X)\n        return np.argmax(P, axis=1)\n</code></pre> <p>Fun\u00e7\u00f5es Aux\u00edliares </p><pre><code># utils.py\nfrom __future__ import annotations\nimport numpy as np\n\n# -----------------------------\n# Ativa\u00e7\u00f5es e derivadas\n# -----------------------------\ndef tanh(z: np.ndarray) -&gt; np.ndarray:\n    return np.tanh(z)\n\ndef dtanh_from_a(a: np.ndarray) -&gt; np.ndarray:\n    return 1.0 - a**2\n\ndef softmax(Z: np.ndarray, axis: int = 0) -&gt; np.ndarray:\n    \"\"\"\n    Z: (K, m) -&gt; aplica softmax por coluna (axis=0).\n    Retorna prob. por classe, colunas somam 1.\n    \"\"\"\n    Z_shift = Z - np.max(Z, axis=axis, keepdims=True)\n    e = np.exp(Z_shift)\n    return e / np.sum(e, axis=axis, keepdims=True)\n\n# -----------------------------\n# Loss e m\u00e9tricas\n# -----------------------------\ndef bce_loss(y_true: np.ndarray, y_prob: np.ndarray, eps: float = 1e-12) -&gt; float:\n    y_prob = np.clip(y_prob, eps, 1.0 - eps)\n    return float(-np.mean(y_true * np.log(y_prob) + (1 - y_true) * np.log(1 - y_prob)))\n\ndef cross_entropy(y_true_oh: np.ndarray, y_prob: np.ndarray, eps: float = 1e-12) -&gt; float:\n    \"\"\"\n    y_true_oh: (m, K) one-hot\n    y_prob   : (m, K) probabilidades (softmax)\n    \"\"\"\n    y_prob = np.clip(y_prob, eps, 1.0 - eps)\n    return float(-np.mean(np.sum(y_true_oh * np.log(y_prob), axis=1)))\n\ndef accuracy_score(y_true: np.ndarray, y_pred_labels: np.ndarray) -&gt; float:\n    return float(np.mean(y_true == y_pred_labels))\n\n# -----------------------------\n# Split 80/20\n# -----------------------------\ndef train_test_split(X: np.ndarray, y: np.ndarray, test_size: float = 0.2, random_state: int = 42):\n    rng = np.random.default_rng(random_state)\n    m = X.shape[0]\n    idx = rng.permutation(m)\n    m_test = int(np.floor(test_size * m))\n    test_idx = idx[:m_test]\n    train_idx = idx[m_test:]\n    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n\n# -----------------------------\n# Inicializa\u00e7\u00f5es\n# -----------------------------\ndef xavier_init(fan_in: int, fan_out: int, rng: np.random.Generator) -&gt; np.ndarray:\n    std = np.sqrt(2.0 / (fan_in + fan_out))\n    return rng.normal(0.0, std, size=(fan_out, fan_in))\n\n# -----------------------------\n# Helpers\n# -----------------------------\ndef one_hot(y: np.ndarray, K: int) -&gt; np.ndarray:\n    \"\"\"\n    y: (m,) com r\u00f3tulos inteiros [0..K-1]\n    retorna: (m, K) one-hot\n    \"\"\"\n    m = y.shape[0]\n    Y = np.zeros((m, K), dtype=float)\n    Y[np.arange(m), y.astype(int)] = 1.0\n    return Y\n</code></pre><p></p> <p>Pr\u00e9-processamento. - MinMax [-1, 1] nos atributos, para combinar com ativa\u00e7\u00e3o tanh nas ocultas.</p> <pre><code>from __future__ import annotations\nimport numpy as np\n\nclass MinMaxScaler:\n    \"\"\"\n    Escala os dados para o intervalo [-1, 1].\n    \"\"\"\n    def __init__(self):\n        self.min_: np.ndarray | None = None\n        self.max_: np.ndarray | None = None\n\n    def fit(self, X: np.ndarray) -&gt; \"MinMaxScaler\":\n        self.min_ = X.min(axis=0)\n        self.max_ = X.max(axis=0)\n        return self\n\n    def transform(self, X: np.ndarray) -&gt; np.ndarray:\n        if self.min_ is None or self.max_ is None:\n            raise RuntimeError(\"Scaler n\u00e3o ajustado. Chame fit() antes de transform().\")\n\n        # normaliza para [0, 1]\n        X_norm = (X - self.min_) / (self.max_ - self.min_ + 1e-12)\n        # reescala para [-1, 1]\n        return 2.0 * X_norm - 1.0\n\n    def fit_transform(self, X: np.ndarray) -&gt; np.ndarray:\n        return self.fit(X).transform(X)\n</code></pre> <p>Gera\u00e7\u00e3o de Dados </p><pre><code>from __future__ import annotations\nimport numpy as np\nfrom sklearn.datasets import make_classification\nimport matplotlib.pyplot as plt\n\ndef make_varying_classification(\n    n_samples: int,\n    n_classes: int,\n    n_features: int,\n    clusters_per_class,\n    class_sep: float = 1.2,           \n    flip_y: float = 0.2,\n    random_state: int = 42,\n    shuffle: bool = False,\n):\n    \"\"\"\n    Gera dados sint\u00e9ticos com n\u00ba de clusters vari\u00e1vel por classe,\n    usando make_classification de forma simplificada.\n\n    - Divide amostras de forma uniforme entre as classes\n    - n_informative = n_features\n    - n_redundant = 0\n    - class_sep e flip_y ajust\u00e1veis\n    \"\"\"\n    clusters_per_class = list(clusters_per_class)\n    if n_classes &lt; 2 or len(clusters_per_class) != n_classes:\n        raise ValueError(\"clusters_per_class deve ter n_classes elementos e n_classes &gt;= 2.\")\n\n    # Divide amostras uniformemente\n    base = n_samples // n_classes\n    counts = [base] * n_classes\n    for i in range(n_samples - base * n_classes):\n        counts[i] += 1\n\n    X_parts, y_parts = [], []\n    for c, m_c in enumerate(counts):\n        seed_c = (random_state + 10007 * (c + 1)) % (2**31 - 1)\n        X_c, _ = make_classification(\n            n_samples=m_c,\n            n_features=n_features,\n            n_informative=n_features,\n            n_redundant=0,\n            n_repeated=0,\n            n_classes=2,               \n            n_clusters_per_class=clusters_per_class[c],\n            weights=[1.0, 0.0],        \n            class_sep=class_sep,\n            flip_y=flip_y,\n            shuffle=True,\n            random_state=seed_c,\n        )\n        X_parts.append(X_c)\n        y_parts.append(np.full(m_c, c, dtype=int))\n\n    X = np.vstack(X_parts)\n    y = np.concatenate(y_parts)\n\n    if shuffle:\n        rng = np.random.default_rng(random_state)\n        idx = rng.permutation(X.shape[0])\n        X, y = X[idx], y[idx]\n\n    return X, y\n\ndef plot_classification_data(X: np.ndarray, y: np.ndarray, title: str = \"Synthetic Data\"):\n    \"\"\"\n    Plota os dados 2D gerados por make_varying_classification.\n\n    Par\u00e2metros:\n      X : np.ndarray (n_samples, 2) -&gt; features\n      y : np.ndarray (n_samples,)   -&gt; r\u00f3tulos (0, 1, ..., n_classes-1)\n      title : t\u00edtulo opcional do gr\u00e1fico\n    \"\"\"\n    if X.shape[1] != 2:\n        raise ValueError(\"O plot s\u00f3 funciona para n_features=2.\")\n\n    plt.figure(figsize=(6, 6))\n    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"tab10\", edgecolor=\"k\", s=40, alpha=0.8)\n    plt.xlabel(\"Feature 1\")\n    plt.ylabel(\"Feature 2\")\n    plt.title(title)\n    plt.legend(*scatter.legend_elements(), title=\"Classes\")\n    plt.grid(True, linestyle=\"--\", alpha=0.6)\n    plt.show()\n</code></pre><p></p>"},{"location":"exercicio3/main/#exercicio-2-classificacao-binaria","title":"Exerc\u00edcio 2 \u2014 Classifica\u00e7\u00e3o Bin\u00e1ria","text":"<p>Objetivo. Treinar uma MLP em um conjunto de dados bin\u00e1rios, com clusters assim\u00e9tricos e 2 features.</p>"},{"location":"exercicio3/main/#especificacao-dos-dados","title":"Especifica\u00e7\u00e3o dos Dados","text":"<ul> <li>Amostras: 1000  </li> <li>Classes: 2  </li> <li>Features: 2 </li> <li>Clusters por classe: <code>[2, 1]</code></li> </ul>"},{"location":"exercicio3/main/#resultados","title":"Resultados","text":"<p>Foram realizados testes com 1 camada oculta de profundidade 1, 1 camada oculta de profundidade 16 e 2 camadas ocultas de profundidade 16 para 500 \u00e9pocas.</p> <ul> <li>Train Loss: 0.4671, 0.4634, 0.2879  </li> <li>Train Accuracy: 0.7750, 0.7738, 0.8538  </li> <li>Test Loss: 0.4553, 0.4509, 0.2763</li> <li>Test Accuracy: 0.8000, 0.8050, 0.8500</li> </ul> <p> </p>"},{"location":"exercicio3/main/#exercicio-3-4-classificacao-multiclasse","title":"Exerc\u00edcio 3 / 4 \u2014 Classifica\u00e7\u00e3o Multiclasse","text":"<p>Objetivo. Treinar uma MLP em um conjunto de dados com 3 classes distintas, clusters assim\u00e9tricos e 4 features.</p>"},{"location":"exercicio3/main/#especificacao-dos-dados_1","title":"Especifica\u00e7\u00e3o dos Dados","text":"<ul> <li>Amostras: 1500  </li> <li>Classes: 3  </li> <li>Features: 4  </li> <li>Clusters por classe: <code>[2, 3, 4]</code> </li> </ul>"},{"location":"exercicio3/main/#resultados_1","title":"Resultados","text":"<p>Foram realizados testes com 1 camada oculta de profundidade 16, 2 camada oculta de profundidade 16 e 3 camadas ocultas de profundidade 16 para 500 \u00e9pocas.</p> <ul> <li>Train Loss: 0.7644, 0.5351, 0.4725  </li> <li>Train Accuracy: 0.6142, 0.7625, 0.7817  </li> <li>Test Loss: 0.7889, 0.6355, 0.5803</li> <li>Test Accuracy: 0.5933, 0.6767, 0.7200</li> </ul> <p> </p>"}]}